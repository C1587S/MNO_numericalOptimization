{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de los métodos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este notebook se plantea la solución del problema utilizando los siguiente métodos: Newton, Broyden-Fletcher-Goldfarb-Shanno  (BFGS) y el gradiente descendente estocástico (SGD). El presente notebook es autocontenido, sin embargo, la implementación principal se realiza con un enfoque modular.\n",
    "\n",
    "A continuación, se describe el conjunto de datos que se emplearán y se define el planteamiento del problema. Una explicación más detallada se realiza en el informe (en formato PDF) de este proyecto.\n",
    "\n",
    "**Nota:** Esta implementación se basa en material y actividades impartidas por los profesores de los cursos de [Métodos Numéricos y optimización](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/IV.optimizacion_convexa_y_machine_learning/4.3.Regresion_logistica_R.ipynb) (2010-I) (Prof. Erick Palacios Moreno) y Aprendizaje de Máquina (2019-II) (Prof. Rodrigo Mendoza Smith).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por la restricciones de uso de la base de datos de entrenamiento original (además de una serie de requerimientos protocolares como contar con la aprobación de un Comité de Ética Independiente), optamos por trabajar con una de las dos bases de datos que los autores emplearon para validar sus modelos: KGH. La base de datos en mención, consta de $106$ casos positivos  de  pacientes  con  ébola  y  un  case fatality rate global por encima del setenta por ciento.  Originalmente,  previo  al tratamiento de los datos, la base tenía únicamente $44$ registros de triaje, $58$ registros de carga viral, con un total de 78 valores faltantes en todo el data set. Para  harmonizar  los  datos,  los  autores  transformaron  la  carga  viral  en  CT,  conforme  con  la curva estándar qPCR:\n",
    "\n",
    "$$log_{(carga \\; viral)} = m*CT + c_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosotros, para fines del presente trabajo, empleamos una de las versiones imputadas de esta base de datos, dispuesta en el siguiente sitio: [ebola-imc-public](https://github.com/dapivei/ebola-imc-public/blob/master/data/kenema/test/pres-kgh/imputation-50.csv), misma que cuenta con $11$ variables: la variable output, $y_{i}$ asociada a la supervivencia o no del paciente ${i}$ con virus del ébola, y ${j}$ variables explicativas asociadas, $x_{i,j}$. Los regresores escogidos son aquellos que, conforme con nuestra principal referencia, son buenos predictores de la probabilidad de muerte o no de un paciente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Tipo| Nombre|Descripción|\n",
    "|---| --- | --- |\n",
    "|Variable Numérica| CT |El cycle threshold (CT) es una variable que se calcula a partir de una relación médica bien conocida (qPCR) y la carga viral (una expresión númerica de la cantidad de virus dado un volúmen de fluido que normalmente se correlaciona con la severidad de una infección viral activa).|\n",
    "|Variable Numérica|TEMP|Temperatura corporal del paciente. Toma valores de 1 a 73.|\n",
    "|Variable Numérica|_AGE_ |Edad del paciente. Toma valores de $1$ a $73$.|\n",
    "|Variable Categórica |_HEADCH_ | Presencia o no dolores de cabeza. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no dolores de cabeza.|\n",
    "|Variable Categórica |  _BLEED_ | Presencia o no de sangrado. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no sangrado. |\n",
    "|Variable Categórica |  _DIARR_ | Presencia o no de diarrea. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no diarrea.|\n",
    "|Variable Categórica | _VOMIT_ | Dificultad para comer, conocido como disfagia, término técnico para describir el síntoma consistente en dificultad para la deglución (problemaspara  tragar).   Esta  dificultad  suele  ir  acompañada  de  dolores,  a  veces lancinantes (disfagia dolorosa u odinofagia .  Toma valores valores $1$ o $0$, dependiendo de si el paciente presenta o no de disfacia\n",
    "|Variable Categórica | _PABD_ | Presencia o no de PADB.\n",
    "|Variable Categórica |_WEAK_ | Presencia o no de debilidad o fatiga general.|\n",
    "|Variable Categórica |_JAUN_ |Condición  en la cuál la piel, los ojos y los miembros mucosos que vuelven amarillos debido a altos niveles de bilirubina. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no ictericia.|\n",
    "|Variable Categórica |_OUT_| Muerte o no muerte del paciente.  Toma valores $1$ o $0$.  Dependiendo desi el paciente muere o no muere.|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problema de regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matemáticamente, este conjunto se define de la siguiente manera: \n",
    "\n",
    "$$\\mathcal{D}=\\left\\{ \\left(x_{i},y_{i}\\right)\\in\\mathbb{R}^{p}\\times\\left\\{ 0,1\\right\\} :i\\in\\left[m\\right]\\right\\} $$.\n",
    "\n",
    "El método de _regresión logística_ asume que $Pr\\left[y_{i}\\mid x_{i},\\beta\\right]\\sim Bernoulli\\left(\\mu_{i}\\right)$\n",
    "con los siguientes supuestos sobre la media, $\\mu_{i}$:\n",
    "\n",
    "$$\n",
    "\\mu_{i}=\\sigma\\left(\\beta^{T}x_{i}\\right) \\label{eq-3.1} \\tag{1}\n",
    "$$\n",
    "$$\n",
    "\\sigma(z)=\\left(1+\\exp\\left(-z\\right)\\right)^{-1} \\label{eq-3.2} \\tag{2}\n",
    "$$\n",
    "\n",
    "donde $\\beta\\in\\mathbb{R}^{p}$. \n",
    "\n",
    "\n",
    "Dado lo anterior, nuestro problema es encontrar un modelo tal que $\\hat{\\beta}\\in\\mathbb{R}^{p}$ explica de la mejor manera posible a $\\mathcal{D}$. \n",
    "\n",
    "Para lograr lo anterior, debemos estimar el conjunto de parámetros $\\hat{\\beta}$ para modelar $Pr\\left[y\\mid x,\\hat{\\beta}\\right]$ y predecir la etiqueta $\\hat{y}\\in\\left\\{ 0,1\\right\\} $ de un nuevo\n",
    "dato $x$ por medio de:\n",
    "\n",
    "$$\n",
    "\\hat{y}=\\begin{cases}\n",
    "1 & si\\,\\sigma\\left(\\hat{\\beta}^{T}x\\right)\\geq0.5\\\\\n",
    "0 & si\\,\\sigma\\left(\\hat{\\beta}^{T}x\\right)<0.5\n",
    "\\end{cases}\\label{eq-3.3} \\tag{3}\n",
    "$$\n",
    "\n",
    "la función de pérdida que queremos minimizar en este problema corresponde a la _log-verosimilitud negativa_ , que está dada por:\n",
    "\n",
    "$$\n",
    "F(\\beta):=LVN(\\beta)=-\\sum_{i=1}^{m}\\left[y_{i}log\\mu_{i}+(1-y_{i})log(1-\\mu_{i})\\right]\\label{eq-3.4} \\tag{4}\n",
    "$$\n",
    "\n",
    "\n",
    "Una vez planteado lo anterior, queremos encontrar $\\hat{\\beta}$ por medio de métodos numéricos de optimización de tal forma que se minimize ([4](#mjx-eqn-eq1)) para el conjunto de datos dado.\n",
    "\n",
    "\n",
    "_En los siguientes fragmentos de código se realiza el planteamiento del problema, desde la importación de datos hasta el proceso de entrenamiento del modelo utilizando distintos algoritmos de optimización que se explican con brevedad._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación y exploración del conjunto de datos\n",
    "\n",
    "En esta sección se importa y transforma los datos, con el fin de obtener el conjunto $\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/afcarl/ebola-imc-public/master/data/kenema/test/pres-kgh/imputation-50.csv\"\n",
    "df_raw=pd.read_csv(url,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>JAUN</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28.652450</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25.736016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20.747653</td>\n",
       "      <td>65.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>22.736993</td>\n",
       "      <td>44.0</td>\n",
       "      <td>38.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OUT         CT   AGE  TEMP  HEADCH  BLEED  DIARR  JAUN  VOMIT  PABD  WEAK\n",
       "0    1  28.652450  42.0  36.3       0      0      1     0      0     1     1\n",
       "1    1  25.736016  45.0  36.5       1      0      1     0      0     1     1\n",
       "2    1  20.747653  65.0  38.0       1      0      0     0      0     0     0\n",
       "3    1  22.736993  44.0  38.6       1      0      0     0      0     0     1\n",
       "4    1  20.846284  11.0  38.4       1      0      0     0      1     0     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()\n",
    "# df[df.isnull().any(axis=1)] - no hay NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT         int64\n",
       "CT        float64\n",
       "AGE       float64\n",
       "TEMP      float64\n",
       "HEADCH      int64\n",
       "BLEED       int64\n",
       "DIARR       int64\n",
       "JAUN        int64\n",
       "VOMIT       int64\n",
       "PABD        int64\n",
       "WEAK        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificar tipo de variables \n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>JAUN</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764151</td>\n",
       "      <td>25.720411</td>\n",
       "      <td>34.102170</td>\n",
       "      <td>37.256604</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.405660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.426545</td>\n",
       "      <td>5.869164</td>\n",
       "      <td>17.382844</td>\n",
       "      <td>1.030767</td>\n",
       "      <td>0.491436</td>\n",
       "      <td>0.249528</td>\n",
       "      <td>0.493352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407477</td>\n",
       "      <td>0.447916</td>\n",
       "      <td>0.502375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.149857</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.236301</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.680924</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>38.225000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.799999</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>39.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OUT          CT         AGE        TEMP      HEADCH       BLEED  \\\n",
       "count  106.000000  106.000000  106.000000  106.000000  106.000000  106.000000   \n",
       "mean     0.764151   25.720411   34.102170   37.256604    0.603774    0.066038   \n",
       "std      0.426545    5.869164   17.382844    1.030767    0.491436    0.249528   \n",
       "min      0.000000   12.100000    0.830000   36.000000    0.000000    0.000000   \n",
       "25%      1.000000   22.149857   22.000000   36.300000    0.000000    0.000000   \n",
       "50%      1.000000   25.236301   35.500000   37.250000    1.000000    0.000000   \n",
       "75%      1.000000   28.680924   45.000000   38.225000    1.000000    0.000000   \n",
       "max      1.000000   39.799999   80.000000   39.900000    1.000000    1.000000   \n",
       "\n",
       "            DIARR   JAUN       VOMIT        PABD        WEAK  \n",
       "count  106.000000  106.0  106.000000  106.000000  106.000000  \n",
       "mean     0.405660    0.0    0.207547    0.273585    0.500000  \n",
       "std      0.493352    0.0    0.407477    0.447916    0.502375  \n",
       "min      0.000000    0.0    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.0    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.0    0.000000    0.000000    0.500000  \n",
       "75%      1.000000    0.0    0.000000    1.000000    1.000000  \n",
       "max      1.000000    0.0    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resumen de las variables\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT       category\n",
       "CT         float64\n",
       "AGE        float64\n",
       "TEMP       float64\n",
       "HEADCH    category\n",
       "BLEED     category\n",
       "DIARR     category\n",
       "JAUN      category\n",
       "VOMIT     category\n",
       "PABD      category\n",
       "WEAK      category\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_cat = df_raw.copy()\n",
    "\n",
    "cat_vars = ['OUT', 'HEADCH', 'BLEED', 'DIARR', 'JAUN', 'VOMIT',\n",
    "       'PABD', 'WEAK']\n",
    "for var in cat_vars:\n",
    "    df_raw_cat[var] = df_raw_cat[var].astype('category')\n",
    "df_raw_cat.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.720411</td>\n",
       "      <td>34.102170</td>\n",
       "      <td>37.256604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.869164</td>\n",
       "      <td>17.382844</td>\n",
       "      <td>1.030767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.149857</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.236301</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>37.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.680924</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>38.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.799999</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>39.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CT         AGE        TEMP\n",
       "count  106.000000  106.000000  106.000000\n",
       "mean    25.720411   34.102170   37.256604\n",
       "std      5.869164   17.382844    1.030767\n",
       "min     12.100000    0.830000   36.000000\n",
       "25%     22.149857   22.000000   36.300000\n",
       "50%     25.236301   35.500000   37.250000\n",
       "75%     28.680924   45.000000   38.225000\n",
       "max     39.799999   80.000000   39.900000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>JAUN</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>99</td>\n",
       "      <td>63</td>\n",
       "      <td>106</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        OUT  HEADCH  BLEED  DIARR  JAUN  VOMIT  PABD  WEAK\n",
       "count   106     106    106    106   106    106   106   106\n",
       "unique    2       2      2      2     1      2     2     2\n",
       "top       1       1      0      0     0      0     0     1\n",
       "freq     81      64     99     63   106     84    77    53"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe categorical data\n",
    "df_proc_cat = df_raw_cat.select_dtypes(include=['category']).copy()\n",
    "df_proc_cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2YAAADQCAYAAABsrnILAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAPs0lEQVR4nO3dfaxlVXkH4N8rI1q0KOAEhYFChNpgW78maEtiWmjrNLViDRqwVVQa2kQtYmtFW6tpYqLxgxJpTWgRwViRigpNDMZQaGrSooMlUaDUKSIf4WOwWj8aRPTtH/dQr8MAZ5jZd917z/MkN3P22nud/c5fb35n7bNOdXcAAAAY51GjCwAAAFh0ghkAAMBgghkAAMBgghkAAMBgghkAAMBgghkAAMBgghkMUlWbquqSqvpqVf1XVZ1VVXvPzr2qqs7e4forq2pzVV1VVddU1c1VtX32+pqqOmw363lLVW2rqhuq6gW7814ArH6rqQ9V1QFVdUVVfXfH+8KiEMxggKqqJJ9M8unuPjLJzyZ5fJJ3Ptzc7n5udz8zyV8k+Xh3P3P2d9Nu1HNUkhOTPD3JliR/U1V7PdL3A2B1W219KMk9Sd6W5E924z1gTRPMYIxjk9zT3eclSXf/MMnpSV5TVfsMqOf4JBd29/e7+2tJtiU5ekAdAKyMVdWHuvt73f35LAU0WEgbRhcAC+rpSa5ePtDd366qm5McsSduUFVnJvnVnZy6sLvftcPYwUn+bdnxrbMxANan1daHYOEJZrA69S6OP/DC7tP3UC0ALB59CFaYYAZjXJfkhOUDVbVvkkOz9BjhoUn222HO/knunvcGu/hJ5W1JDll2vGk2BsD6tNr6ECw8wQzGuDzJu6rqld19wWyjjfcl+XB3/29VfTHJ2VX15O6+o6o2J3lMklvmvcEuflJ5aZK/r6r3JzkoyZFJvrAL8wFYW1ZbH4KFJ5jBAN3dVfU7Wdr98G1Z2ojnM0neOjt/Z1WdluQzVfWoJN9NclJ3/2iieq6tqouy9AnqfUleO/siOADr0GrrQ0lSVTcl2TfJ3lX14iS/0d3XTXU/WG2qe+5HhQEAAJiA7fIBAAAGE8wAAAAGE8wAAAAGE8wAAAAGWxO7Mm7ZsqUvu+yy0WUAsPbVI5mkDwGwB+20F62JFbO77577twwBYI/ThwCY2poIZgAAAOuZYAYAADCYYAYAADCYYAYAADDYpMGsqk6vqmur6itV9bGqemxVHV5VV1XVtqr6eFXtPWUNAAAAq91kwayqDk7yR0k2d/fPJ9kryYlJ3p3kzO4+Isk3k5wyVQ0AAABrwdS/Y7YhyU9V1Q+S7JPk9iTHJnn57Pz5Sd6R5IMT1wEA69pz3nTB6BIAhrv6Pa8cXcIjNtmKWXffluS9SW7OUiD7nyRXJ/lWd983u+zWJAfvbH5VnVpVW6tq6/bt26cqEwB2Sh8CYCVN+SjjfkmOT3J4koOSPC7Jlnnnd/c53b25uzdv3LhxoioBYOf0IQBW0pSbf/xakq919/bu/kGSTyY5JskTq+r+Ryg3JbltwhoAAABWvSmD2c1JnldV+1RVJTkuyXVJrkhywuyak5NcMmENAAAAq96U3zG7KsknknwpyZdn9zonyZuTvLGqtiU5IMm5U9UAAACwFky6K2N3vz3J23cYvjHJ0VPeFwAAYC2Z9AemAQAAeHiCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCCGQAAwGCTBrOqemJVfaKq/qOqrq+qX6qq/avqc1X11dm/+01ZAwAAwGo39YrZWUku6+6fS/KMJNcnOSPJ5d19ZJLLZ8cAAAALa7JgVlVPSPL8JOcmSXff293fSnJ8kvNnl52f5MVT1QAAALAWTLlidniS7UnOq6p/r6q/q6rHJTmwu2+fXXNHkgN3NrmqTq2qrVW1dfv27ROWCQAPpA8BsJKmDGYbkjw7yQe7+1lJvpcdHlvs7k7SO5vc3ed09+bu3rxx48YJywSAB9KHAFhJUwazW5Pc2t1XzY4/kaWgdmdVPSVJZv/eNWENAAAAq95kway770hyS1U9bTZ0XJLrklya5OTZ2MlJLpmqBgAAgLVgw8Tv//okH62qvZPcmOTVWQqDF1XVKUm+nuRlE9cAAACwqk0azLr7miSbd3LquCnvCwAAsJZM/TtmAAAAPAzBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYLC5gllVXT7PGAAAALtuw0OdrKrHJtknyZOqar8kNTu1b5KDJ64NAABgITxkMEvyB0nekOSgJFfnx8Hs20nOnrAuAACAhfGQway7z0pyVlW9vrs/sEI1AQAALJSHWzFLknT3B6rql5MctnxOd18wUV0AAAALY65gVlUfSfLUJNck+eFsuJMIZgAAALtprmCWZHOSo7q7pywGAABgEc37O2ZfSfLkKQsBAABYVPOumD0pyXVV9YUk379/sLtfNElVAAAAC2TeYPaOKYsAAABYZPPuyvjPUxcCAACwqObdlfE7WdqFMUn2TvLoJN/r7n2nKgwAAGBRzLti9tP3v66qSnJ8kufNM7eq9kqyNclt3f3Cqjo8yYVJDkhydZJXdPe9u1o4AADAejHvroz/r5d8OskL5pxyWpLrlx2/O8mZ3X1Ekm8mOWVXawAAAFhP5n2U8SXLDh+Vpd81u2eOeZuS/FaSdyZ542y17dgkL59dcn6WNhb54PwlAwAArC/z7sr428te35fkpiw9zvhw/irJnya5/1HIA5J8q7vvmx3fmuTgOWsAAABYl+b9jtmrd/WNq+qFSe7q7qur6lcewfxTk5yaJIceeuiuTgeA3aIPAbCS5vqOWVVtqqpPVdVds7+LZ48pPpRjkryoqm7K0mYfxyY5K8kTq+r+QLgpyW07m9zd53T35u7evHHjxrn+MwCwp+hDAKykeTf/OC/JpUkOmv3942zsQXX3W7p7U3cfluTEJP/U3b+b5IokJ8wuOznJJY+gbgAAgHVj3mC2sbvP6+77Zn8fTvJIPz58c5Y2AtmWpe+cnfsI3wcAAGBdmHfzj29U1e8l+djs+KQk35j3Jt19ZZIrZ69vTHL0/CUCAACsb/OumL0mycuS3JHk9iw9iviqiWoCAABYKPOumP1lkpO7+5tJUlX7J3lvlgIbAAAAu2HeFbNfvD+UJUl3/3eSZ01TEgAAwGKZN5g9qqr2u/9gtmI272obAAAAD2HecPW+JP9aVf8wO35pkndOUxIAAMBimSuYdfcFVbU1Sz8SnSQv6e7rpisLAABgccz9OOIsiAljAAAAe9i83zEDAABgIoIZAADAYIIZAADAYIIZAADAYIIZAADAYIIZAADAYIIZAADAYIIZAADAYIIZAADAYIIZAADAYIIZAADAYIIZAADAYIIZAADAYIIZAADAYBtGF7AePOdNF4wuAWBVuPo9rxxdAgCsSVbMAAAABhPMAAAABhPMAAAABhPMAAAABpssmFXVIVV1RVVdV1XXVtVps/H9q+pzVfXV2b/7TVUDAADAWjDlitl9Sf64u49K8rwkr62qo5KckeTy7j4yyeWzYwAAgIU1WTDr7tu7+0uz199Jcn2Sg5Mcn+T82WXnJ3nxVDUAAACsBSvyHbOqOizJs5JcleTA7r59duqOJAeuRA0AAACr1eTBrKoen+TiJG/o7m8vP9fdnaQfZN6pVbW1qrZu37596jIB4CfoQwCspEmDWVU9Okuh7KPd/cnZ8J1V9ZTZ+ackuWtnc7v7nO7e3N2bN27cOGWZAPAA+hAAK2nKXRkryblJru/u9y87dWmSk2evT05yyVQ1AAAArAUbJnzvY5K8IsmXq+qa2dhbk7wryUVVdUqSryd52YQ1AAAArHqTBbPu/nySepDTx011XwAAgLVmRXZlBAAA4MEJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMJZgAAAIMNCWZVtaWqbqiqbVV1xogaAAAAVosVD2ZVtVeSv07ym0mOSnJSVR210nUAAACsFiNWzI5Osq27b+zue5NcmOT4AXUAAACsCtXdK3vDqhOSbOnu358dvyLJc7v7dTtcd2qSU2eHT0tyw4oWCmvPk5LcPboIWOXu7u4t81yoD8Eu04dgPjvtRRtGVDKP7j4nyTmj64C1oqq2dvfm0XXAeqEPwa7Rh2D3jHiU8bYkhyw73jQbAwAAWEgjgtkXkxxZVYdX1d5JTkxy6YA6AAAAVoUVf5Sxu++rqtcl+WySvZJ8qLuvXek6YB3yyBUAI+lDsBtWfPMPAAAAftKQH5gGAADgxwQzAACAwQQzWOOqaktV3VBV26rqjNH1ALB49CLYfb5jBmtYVe2V5D+T/HqSW7O06+lJ3X3d0MIAWBh6EewZVsxgbTs6ybbuvrG7701yYZLjB9cEwGLRi2APEMxgbTs4yS3Ljm+djQHAStGLYA8QzAAAAAYTzGBtuy3JIcuON83GAGCl6EWwBwhmsLZ9McmRVXV4Ve2d5MQklw6uCYDFohfBHrBhdAHAI9fd91XV65J8NsleST7U3dcOLguABaIXwZ5hu3wAAIDBPMoIAAAwmGAGAAAwmGAGAAAwmGAGAAAwmGAGAAAwmGAGq1hVfXfZ6zdU1T1V9YRlY6+qqrN3mHNlVW2evb6pqi5edu6EqvrwCpQOwDqhF8HKEMxg7TgpSz/i+ZJdnPecqjpqgnoAWDx6EUxEMIM1oKqemuTxSf48S01xV7wvyZ/t8aIAWCh6EUxLMIO14cQkFyb5lyRPq6oDd2HuRUmeXVVHTFIZAItCL4IJCWawNpyU5MLu/lGSi5O8dDbeD3L98vEfJnlPkrdMVx4AC0AvggkJZrDKVdUvJDkyyeeq6qYsfWJ5/yMk30iy3w5T9k9y9w5jH0ny/CSHTFcpAOuVXgTTE8xg9TspyTu6+7DZ30FJDqqqn8nSF7CPqaonJ8lsB6zHJLll+Rt09w+SnJnk9JUtHYB1Qi+CiQlmsEpV1YYk38/Sp5Kf2uH0p5Kc2N13JjktyWeq6pokf5XkpNljJjs6N8mGCUsGYJ3Ri2DlVPeDPRYMjFRVz0jyt9199OhaAFhMehGsHCtmsApV1R8m+ViWtiQGgBWnF8HKsmIGAAAwmBUzAACAwQQzAACAwQQzAACAwQQzAACAwQQzAACAwf4PCX888f2VIt4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_vars = cat_vars[1:]\n",
    "\n",
    "for i, col_val in enumerate(cat_vars):\n",
    "    sns.catplot(x = col_val, y = None, hue= None, col=\"OUT\",\n",
    "                data=df_proc_cat, kind=\"count\",\n",
    "                height=3, aspect=2);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algunas observaciones sobre los datos**\n",
    "\n",
    "- El case fatality rate (OUT) de nuestra base de datos se sitúa en 76 por ciento. Es decir, del total de pacientes con ébola, 81 murieron.\n",
    "\n",
    "- Para este conjunto de datos la variable `JAUN` no tiene variabilidad, por lo tanto no es una variable, y se omite.\n",
    "\n",
    "\n",
    "Dado lo anterior, se ajusta el set de datos:\n",
    "\n",
    "- Se crean 3 grupos de edades, utilizando el percetil 25 (22 años), percentil 50 (36 años) y percentil 75 (45 años).\n",
    "\n",
    "- Se elimina la columna `JAUN`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones al conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT            int64\n",
       "CT           float64\n",
       "AGE          float64\n",
       "TEMP         float64\n",
       "HEADCH         int64\n",
       "BLEED          int64\n",
       "DIARR          int64\n",
       "JAUN           int64\n",
       "VOMIT          int64\n",
       "PABD           int64\n",
       "WEAK           int64\n",
       "INTER_AGE     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ajustes en df_raw \n",
    "df_proc = df_raw\n",
    "df_proc['INTER_AGE'] = \"NA\"\n",
    "\n",
    "df_proc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT             int64\n",
       "CT            float64\n",
       "TEMP          float64\n",
       "HEADCH          int64\n",
       "BLEED           int64\n",
       "DIARR           int64\n",
       "VOMIT           int64\n",
       "PABD            int64\n",
       "WEAK            int64\n",
       "hasta22       float64\n",
       "entre23y36    float64\n",
       "entre37y45    float64\n",
       "mayor45       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ajustes en df_raw \n",
    "df_proc = df_raw\n",
    "\n",
    "# para la variable edad se crean cuatro categorías\n",
    "age_p25 = math.ceil(df_proc['AGE'].quantile(.25))\n",
    "age_p50 = math.ceil(df_proc['AGE'].quantile(.50))\n",
    "age_p75 = math.ceil(df_proc['AGE'].quantile(.75))\n",
    "\n",
    "df_proc['INTER_AGE'] = \"NA\"\n",
    "df_proc.loc[(df_proc['AGE'] <= age_p25), 'INTER_AGE'] = 1\n",
    "df_proc.loc[(df_proc['AGE'] > age_p25) & (df_proc['AGE'] <= age_p50), 'INTER_AGE'] = 2\n",
    "df_proc.loc[(df_proc['AGE'] > age_p50) & (df_proc['AGE'] <= age_p75), 'INTER_AGE'] = 3\n",
    "df_proc.loc[(df_proc['AGE'] > age_p75), 'INTER_AGE'] = 4\n",
    "\n",
    "## one hot encoding\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(df_proc[['INTER_AGE']]).toarray())\n",
    "enc_df = enc_df.rename(columns={0: f\"hasta{age_p25}\", 1: f\"entre{age_p25+1}y{age_p50}\", 2: f\"entre{age_p50+1}y{age_p75}\", 3:f\"mayor{age_p75}\"})\n",
    "# merge with main df bridge_df on key values\n",
    "df_proc = df_proc.join(enc_df)\n",
    "\n",
    "# se asignan como categoricas a las binarias, incluido el output\n",
    "#bin_vars = ['OUT', 'HEADCH', 'BLEED', 'DIARR', 'JAUN', 'VOMIT',\n",
    "#       'PABD', 'WEAK', 'INTER_AGE', f\"hasta{age_p25}\", f\"entre{age_p25+1}y{age_p50}\", f\"entre{age_p50+1}y{age_p75}\", f\"mayor{age_p75}\"]\n",
    "\n",
    "#esta asignacion hace que genera problemas al evaluar el sigmoide\n",
    "#for var in bin_vars:\n",
    "#    df_proc[var] = df_proc[var].astype('category')\n",
    "    \n",
    "# se omiten las variables JAUN, AGE, INTER_AGE\n",
    "del_vars = [\"JAUN\", \"AGE\", \"INTER_AGE\"]\n",
    "for var in del_vars:\n",
    "    df_proc = df_proc.drop(var, axis=1)    \n",
    "    \n",
    "# se comprueban los tipos de variable\n",
    "df_proc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "      <th>hasta22</th>\n",
       "      <th>entre23y36</th>\n",
       "      <th>entre37y45</th>\n",
       "      <th>mayor45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28.652450</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25.736016</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20.747653</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>22.736993</td>\n",
       "      <td>38.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>38.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>24.191797</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>38.816561</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>21.960294</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>26.221948</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OUT         CT  TEMP  HEADCH  BLEED  DIARR  VOMIT  PABD  WEAK  hasta22  \\\n",
       "0      1  28.652450  36.3       0      0      1      0     1     1      0.0   \n",
       "1      1  25.736016  36.5       1      0      1      0     1     1      0.0   \n",
       "2      1  20.747653  38.0       1      0      0      0     0     0      0.0   \n",
       "3      1  22.736993  38.6       1      0      0      0     0     1      0.0   \n",
       "4      1  20.846284  38.4       1      0      0      1     0     1      1.0   \n",
       "..   ...        ...   ...     ...    ...    ...    ...   ...   ...      ...   \n",
       "101    1  24.191797  36.4       0      0      1      1     1     1      0.0   \n",
       "102    1  20.846284  38.4       0      0      0      1     0     1      0.0   \n",
       "103    0  38.816561  36.0       0      0      0      0     0     0      1.0   \n",
       "104    1  21.960294  36.4       0      0      0      0     0     0      0.0   \n",
       "105    0  26.221948  36.5       1      0      0      0     0     0      0.0   \n",
       "\n",
       "     entre23y36  entre37y45  mayor45  \n",
       "0           0.0         1.0      0.0  \n",
       "1           0.0         1.0      0.0  \n",
       "2           0.0         0.0      1.0  \n",
       "3           0.0         1.0      0.0  \n",
       "4           0.0         0.0      0.0  \n",
       "..          ...         ...      ...  \n",
       "101         0.0         1.0      0.0  \n",
       "102         1.0         0.0      0.0  \n",
       "103         0.0         0.0      0.0  \n",
       "104         1.0         0.0      0.0  \n",
       "105         0.0         1.0      0.0  \n",
       "\n",
       "[106 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planteamiento del problema de regresión\n",
    "\n",
    "A continuación se plantea el código que computa las ecuaciones ([1](#mjx-eqn-eq1)), ([2](#mjx-eqn-eq1)) y ([4](#mjx-eqn-eq1)), planteadas inicialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(z):\n",
    "    '''\n",
    "    \n",
    "    Función que devuelve el sigmoide de un vector\n",
    "    \n",
    "        - Parámetros:\n",
    "        \n",
    "            -- z (vec): vector numérico de m entradas\n",
    "        \n",
    "        - Salidas\n",
    "        \n",
    "            -- sig (vec): vector númerico de m entradas, cada entrada tiene \n",
    "        \n",
    "                         un valor entre -1 y 1\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    if type(z) is not np.ndarray:\n",
    "        sys.exit('Error: la entrada debe ser de tipo numpy.ndarray')\n",
    "        \n",
    "    sig = 1/(1+ np.exp(-z))\n",
    "    \n",
    "    return sig\n",
    "    \n",
    "def calc_mu(X,beta):\n",
    "    '''\n",
    "    \n",
    "    Función que calcula la media para una variable aleatoria con distribución bernoulli.\n",
    "    \n",
    "        - Parámetros:\n",
    "        \n",
    "            -- X (mat): matriz de mxp entradas\n",
    "            \n",
    "            -- beta (vec): vector con p entradas\n",
    "            \n",
    "        - Salidas\n",
    "        \n",
    "            -- mu (vec): vector de m entradas\n",
    "    '''\n",
    "    a = np.matmul(beta,np.transpose(X))\n",
    "    mu = sigmoide(a)\n",
    "\n",
    "    return mu\n",
    "    \n",
    "def f(X,y,beta):\n",
    "    '''\n",
    "    \n",
    "    Función que computa la log-verosimilitud negativa\n",
    "    \n",
    "        - Parámetros:\n",
    "    \n",
    "            -- X (mat): matriz de mxp entradas\n",
    "\n",
    "            -- y (vec): vector de de m entradas de la variable output\n",
    "\n",
    "            -- beta (vec): vector de p entradas\n",
    "\n",
    "        - Salidas\n",
    "    \n",
    "            -- lvn (int): log-verosimilitud negativa\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "    if beta.shape[0]!= p:\n",
    "        sys.exit('Error:  El número de columnas de X debe ser igual al número de entradas del vector beta.')\n",
    "\n",
    "    prob = calc_mu(X,beta)\n",
    "    # Log-verosimilitud negativa \n",
    "    lvn = -sum(y*np.log(prob)+(1-y)*(np.log(1-prob)))\n",
    "    return lvn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reescribiendo la ecuación de la función de pérdida ([4](#mjx-eqn-eq1)), tenemos:\n",
    "\n",
    "$$F(\\beta)=- \\sum_{i=1}^{m}[y_i log\\mu_i + (1-y_i)log(1-\\mu_i)]$$\n",
    "\n",
    "Las expresiones correspondientes al gradiente y a la matriz hessiana asociados a este problema, se plantean a continuación:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla F(\\beta) & =\\frac{d}{d\\beta}F(\\beta)\\nonumber \\\\\n",
    " & =\\sum_{i}\\left(\\mu_{i}-y_{i}\\right)x_{i}\\nonumber \\\\\n",
    " & =\\boldsymbol{X}^{T}\\left(\\boldsymbol{\\mu}-\\boldsymbol{y}\\right)\\label{eq:gradient}\n",
    "\\end{align}\n",
    "\n",
    "Por otro lado, la ecuación que describe la matrix Hessiana es la siguiente:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla^{2}F(\\beta) & =\\frac{d}{d\\beta}\\nabla F\\left(\\beta\\right)^{T}\\nonumber \\\\\n",
    " & =\\sum_{i}\\left(\\nabla_{\\beta}\\mu_{i}\\right)x_{i}^{T}\\nonumber \\\\\n",
    " & =\\sum_{i}\\mu_{i}\\left(1-\\mu_{i}\\right)x_{i}x_{i}^{T}\\nonumber \\\\\n",
    " & =\\boldsymbol{X^{T}SX}\\label{eq:hessian}\n",
    "\\end{align}\n",
    "\n",
    "donde $\\boldsymbol{S}\\triangleq diag\\left(\\mu_{i}\\left(1-\\mu_{i}\\right)\\right)$.\n",
    "Como es resaltado por Murphy (2012), es definida positiva, lo que implica que ([4](#mjx-eqn-eq1)) es convexa\n",
    "y tiene un mínimo global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_f(X,y,beta):\n",
    "    '''\n",
    "    \n",
    "    Función que calcula el gradiente asociado la log-verosimilitud negativa del \n",
    "    \n",
    "    problema de regresión logística\n",
    "    \n",
    "        ** Parámetros:\n",
    "        \n",
    "            - X (mat): matriz de mxp entradas\n",
    "            \n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            \n",
    "            - beta (vec): vector de p entradas\n",
    "        \n",
    "        ** Salidas\n",
    "        \n",
    "            - grad (vec): vector de m entradas\n",
    "    '''\n",
    "        \n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "    if beta.shape[0]!= p:\n",
    "        sys.exit('Error:  El número de columnas de X debe ser igual al número de entradas del vector beta.')\n",
    "\n",
    "    mu = calc_mu(X,beta)    \n",
    "    grad = np.matmul(np.transpose(X), mu-y)    \n",
    "    return grad\n",
    "\n",
    "\n",
    "def hessiana_f(X,y,beta):\n",
    "    '''\n",
    "    \n",
    "    Función que calcula la matriz Hessiana asociada a la log-verosimilitud negativa del \n",
    "    \n",
    "    problema de regresión logística\n",
    "    \n",
    "        ** Parámetros:\n",
    "        \n",
    "            - X (mat): matriz de mxp entradas\n",
    "            \n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            \n",
    "            - beta (vec): vector de p entradas\n",
    "        \n",
    "        ** Salidas\n",
    "        \n",
    "            - hes (vec): vector de m entradas\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "    if beta.shape[0]!= p:\n",
    "        sys.exit('Error:  El número de columnas de X debe ser igual al número de entradas del vector beta.')\n",
    "\n",
    "    mu = calc_mu(X,beta)\n",
    "    S = np.diag(mu*(1-mu))\n",
    "    hes = np.matmul(np.transpose(X),np.matmul(S,X))\n",
    "    return hes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    '''\n",
    "    \n",
    "    Función que normaliza un vector\n",
    "    \n",
    "        ** Parametros:\n",
    "    \n",
    "            - x: vector a normalizar\n",
    "    \n",
    "        ** Salidas:\n",
    "    \n",
    "            - norm : vector x normalizado\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    if type(x) is not np.ndarray:\n",
    "        sys.exit('Error: la entrada debe ser de tipo numpy.ndarray')\n",
    "         \n",
    "    norm = x/np.sqrt(sum(x*x))\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasifica(X, beta_hat,limit=0.5):\n",
    "    '''\n",
    "    \n",
    "    Función que clasifica la ocurrencia de probabilidades en dos grupos.\n",
    "    \n",
    "    Emplea el parámetro límite para delimitar si se clasifica en el grupo 0 o 1.\n",
    "    \n",
    "        ** Parámetros:\n",
    "        \n",
    "            - X (mat): matriz de mxp entradas\n",
    "            \n",
    "            - beta_hat (array): optimized parameter\n",
    "            \n",
    "            - limit (float64): 0<limit<1: Threshold for each classification\n",
    "            \n",
    "        \n",
    "        ** Salidas:\n",
    "        \n",
    "            - yhat: array of classifed data\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    if type(X) is not np.ndarray or type (beta_hat) is not np.ndarray:\n",
    "        sys.exit('Error: X y beta_hat deben ser de tipo numpy.ndarray')\n",
    "    if limit > 1 or limit < 0:\n",
    "        sys.exit('Error:  limit es un paramétro que debe estar entre 0 y 1')       \n",
    "    \n",
    "    mu = calc_mu(X,beta_hat)\n",
    "    yhat = mu\n",
    "    yhat[mu<limit] = 0\n",
    "    yhat[mu>=limit] = 1\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent_direction(X, y, beta, method=\"max\",H=None):\n",
    "    '''\n",
    "    \n",
    "    Función que devuelve vector normalizado (px1) que apunta en la direccion de decenso\n",
    "    \n",
    "        ** Parámetros:\n",
    "        \n",
    "            - X (mat): matriz de mxp entradas\n",
    "\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "\n",
    "            - beta (vec float64): vector de entradas a optimizar\n",
    "\n",
    "            - method (str): método que determina la dirección de descenso\n",
    "    \n",
    "                    --Opciones:\n",
    "    \n",
    "                            --- max: método de descenso\n",
    "                            \n",
    "                            --- newton: método de Newton\n",
    "                            \n",
    "                            --- bfsg: metodo bfsg\n",
    "                            \n",
    "            - H (mat pxp): Parámetro para la dirección de decenso del metodo bfgs\n",
    "    \n",
    "        ** Salidas\n",
    "    \n",
    "            - pk (vec): vector normalizado con la direccion del paso\n",
    "    '''\n",
    "    if(method == \"max\"):\n",
    "        pk = gradiente_f(X,y,beta)\n",
    "    \n",
    "    elif(method == \"newton\"):\n",
    "        grad = gradiente_f(X,y,beta)\n",
    "        hess = hessiana_f(X,y,beta)\n",
    "        pk = np.linalg.solve(hess,grad)\n",
    "        \n",
    "    elif(method==\"bfsg\"):\n",
    "        # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "        if type(H) is not np.ndarray:\n",
    "            sys.exit('Error: H debe ser de tipo numpy.ndarray')\n",
    "        pk = np.matmul(H,gradiente_f(X,y,beta))\n",
    "                              \n",
    "    return - normalize(pk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_H(X,y,beta,beta_new=None,H=None):\n",
    "    '''\n",
    "    \n",
    "    Función que actualiza los valores de la matriz H del metodo bfgs para cada iteracion\n",
    "    \n",
    "        ** Parametros:\n",
    "        \n",
    "            - X (mat): matriz de mxp entradas\n",
    "\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "        \n",
    "            - beta (array) - valor de cantidad a optimizar en la iteracion actual\n",
    "            \n",
    "            - beta_new (array)- valore de la cantidad a optimizar despues de la actualizacion\n",
    "            \n",
    "            - H (mat)- valor de la matriz H en la iteracion anterior\n",
    "        \n",
    "        \n",
    "        \n",
    "        ** Salidas:\n",
    "        \n",
    "            - H (mat): valor de la matriz para la siguiente iteracion       \n",
    "    '''\n",
    "    \n",
    "    w = gradiente_f(X,y,beta_new)- gradiente_f(X,y,beta)\n",
    "    z = beta_new-beta\n",
    "    Hz = np.matmul(H,z)\n",
    "    dotwz = np.dot(w,z)\n",
    "    dotzhz = np.dot(Hz,z)\n",
    "    H = H+(np.outer(w,w)/dotwz)-(np.outer(Hz,Hz)/dotzhz)\n",
    "   \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lr(X, y, beta, lr, pk, c1=10**(-4), tao=0.5, reset_lr=False):\n",
    "    '''\n",
    "    \n",
    "    Función que calcula el tamaño del paso para cada iteración utilizando la condicion de armijo.\n",
    "    \n",
    "    La tasa de aprendizaje minima es la que tenia en el paso anterior.\n",
    "    \n",
    "        ** Parámetros:\n",
    "        \n",
    "            - X (mat): matriz de mxp entradas\n",
    "            \n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            \n",
    "            - lr (float64): tasa de aprendizaje\n",
    "            \n",
    "            - pk (array px1 float64): direccion de decenso\n",
    "            \n",
    "            - c1 (float64) 0<c1<1: parametro de control\n",
    "            \n",
    "            - tao (float64) 0<tao<1: parametro de decrecimiento de lr\n",
    "            \n",
    "        ** Salidas\n",
    "        \n",
    "            - lr (float64): tamaño de paso\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad    \n",
    "    if tao > 1 or tao < 0:\n",
    "        sys.exit('Error:  tao es un parámetro que debe estar entre 0 y 1')  \n",
    "    if c1 > 1 or c1 < 0:\n",
    "        sys.exit('Error:  c1 es un paramétro que debe estar entre 0 y 1') \n",
    "\n",
    "    # Inicializamos \n",
    "    tao = 0.9\n",
    "    max_iter = 100\n",
    "    iter = 0\n",
    "    \n",
    "    # Inicializa lr\n",
    "    if reset_lr==True: lr = 1\n",
    "\n",
    "    # Evaluaciones periódicas\n",
    "    grad = gradiente_f(X,y,beta)\n",
    "    eval_f = f(X,y, beta)\n",
    "    \n",
    "    # Primera iteracion\n",
    "    f_x =  f(X,y, beta + lr*pk) #en nocedal es phi(alpha)\n",
    "    f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) # en nocedal es l(alhpa)\n",
    "    \n",
    "    while ((f_x > f_x1) & (iter < max_iter)):\n",
    "        lr = lr*tao\n",
    "        f_x =  f(X,y, beta + lr*pk) \n",
    "        f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) \n",
    "        iter+=1\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba\n",
    "# prueba\n",
    "# No esta funcionando bien\n",
    "# Longitud de paso con condiciones completas de wolf\n",
    "\n",
    "def calc_lr_wolf(X, y, beta, lr, pk, c1=10**(-4), c2=0.9, tao=0.5, reset_lr=False):\n",
    "    '''\n",
    "    \n",
    "    Función que calcula el tamaño del paso para cada iteración utilizando la condicion de armijo.\n",
    "    \n",
    "    La tasa de aprendizaje minima es la que tenía en el paso anterior.\n",
    "    \n",
    "        ** Parámetros:\n",
    "        \n",
    "            - X (mat): matriz de mxp entradas\n",
    "            \n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            \n",
    "            - lr (float64): tasa de aprendizaje\n",
    "            \n",
    "            - pk (array px1 float64): direccion de decenso\n",
    "            \n",
    "            - c1 (float64) 0<c1<1: parametro de control\n",
    "            \n",
    "            - tao (float64) 0<tao<1: parametro de decrecimiento de lr\n",
    "        \n",
    "        \n",
    "        \n",
    "        ** Salidas\n",
    "        \n",
    "            - lr (float64): tamaño de paso\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    if tao > 1 or tao < 0:\n",
    "        sys.exit('Error:  tao es un parámetro que debe estar entre 0 y 1')  \n",
    "    if c1 > 1 or c1 < 0:\n",
    "        sys.exit('Error:  c1 es un paramétro que debe estar entre 0 y 1') \n",
    "    #if pk >= 0 :\n",
    "    #    sys.exit('Error: pk debe ser negativo')\n",
    "        \n",
    "    # Inicializamos \n",
    "    tao = 0.5\n",
    "    max_iter = 50\n",
    "    iter = 0\n",
    "    \n",
    "    # Inicializa lr\n",
    "    if reset_lr==True: lr=1\n",
    "\n",
    "    # Evalauciones periodicas\n",
    "    grad = gradiente_f(X,y,beta)\n",
    "    eval_f = f(X,y, beta)\n",
    "    \n",
    "    # Primera iteracion\n",
    "    f_x =  f(X,y, beta + lr*pk) #en nocedal es phi(alpha)\n",
    "    f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) # en nocedal es l(alhpa)\n",
    "    \n",
    "    gf_x = np.dot(gradiente_f(X,y, beta+lr*pk) , pk)\n",
    "    gf_x1 = c2* np.dot(grad, pk)\n",
    "    \n",
    "    while ((f_x>f_x1) & (gf_x<gf_x1) & (iter<max_iter)):\n",
    "        lr =lr*tao\n",
    "        f_x =  f(X,y, beta + lr*pk) \n",
    "        f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) \n",
    "        \n",
    "        gf_x = np.dot(gradiente_f(X,y, beta+lr*pk) , pk)\n",
    "        #gf_x1 = c2* np.dot(grad, pk)\n",
    "    \n",
    "        \n",
    "        iter+=1\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, lr=1, tol=10**(-7), max_iter=10**5, method=\"max\", reset_lr=False, verbose_n=1000):\n",
    "    '''\n",
    "    \n",
    "    Función que devuelve vector de parámetros beta (px1) resultante del proceso\n",
    "    \n",
    "    de optimización por descenso de gradiente\n",
    "    \n",
    "        ** Parámetros:\n",
    "        \n",
    "            - X (mat): matriz de mxp entradas\n",
    "            \n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            \n",
    "            - lr (float64): valor inicial de la tasa de aprendizaje\n",
    "            \n",
    "            - tol (float64): criterio de convergencia\n",
    "            \n",
    "            - max_iter (int): número máximo de iteraciones\n",
    "            \n",
    "            - method (str): método que determina la dirección de descenso\n",
    "            \n",
    "                Opciones:\n",
    "                \n",
    "                    -- max: método de descenso\n",
    "                    \n",
    "                    -- newton: método de Newton\n",
    "                    \n",
    "                    -- bfsg\n",
    "        \n",
    "        ** Salidas\n",
    "        \n",
    "            - beta_new (vec): vector de p entradas con parámetros que minimizan la función de pérdida\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "\n",
    "    \n",
    "    # Inicializa\n",
    "    iteraciones=0\n",
    "    H = None\n",
    "    dims = X.shape[1]\n",
    "    tol = tol*dims\n",
    "    \n",
    "    # Inicializamos beta aleatoria\n",
    "    beta = np.random.normal(1,3,dims)\n",
    "    if method ==\"bfsg\": H = np.identity(dims)\n",
    "    \n",
    "    # Primera iteracion\n",
    "    pk =  descent_direction(X, y, beta, method,H)\n",
    "    beta_new = beta + lr*pk\n",
    "    if method == \"bfsg\": H=calc_H(X,y,beta,beta_new,H) \n",
    "    \n",
    "    # Condición de paro.\n",
    "    while ((np.linalg.norm(gradiente_f(X,y,beta_new)) > tol) & (iteraciones < max_iter)):\n",
    "        iteraciones+=1 #contador de ciclo\n",
    "        \n",
    "        beta = beta_new\n",
    "        pk =  descent_direction(X,y,beta,method,H)\n",
    "        lr = calc_lr(X, y, beta, lr, pk, reset_lr = reset_lr)\n",
    "        \n",
    "        beta_new = beta + lr*pk\n",
    "        \n",
    "        if method == \"bfsg\": H=calc_H(X,y,beta,beta_new,H)\n",
    "            \n",
    "        # Imprime\n",
    "\n",
    "        if iteraciones % verbose_n == 0:\n",
    "            print(\"************************************************************************\")\n",
    "            grad=np.linalg.norm(gradiente_f(X,y,beta_new))\n",
    "            print(f'GRADIENTE: {grad:.7E}, LEARNING RATE: {lr:.4E}, Nº ITERACIONES: {iteraciones}')\n",
    "            \n",
    "\n",
    "    print(\"*========================================================================*\")    \n",
    "    if iteraciones == max_iter:print(\"Alcanzó el número máximo de iteraciones\")\n",
    "\n",
    "    print(\"ITERACIONES: \",iteraciones)\n",
    "    print(\"GRADIENTE DE F: \",np.linalg.norm(gradiente_f(X,y,beta_new)))\n",
    "    print(\"*========================================================================*\")\n",
    "    \n",
    "    return beta_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data =df_proc.to_numpy()\n",
    "y = data[:,0]\n",
    "X = data[:,1:]\n",
    "x_train, x_test, y_train, y_test=train_test_split(X,y,test_size=.2)\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "GRADIENTE: 1.8444854E-03, LEARNING RATE: 7.7355E-04, Nº ITERACIONES: 100000\n",
      "************************************************************************\n",
      "GRADIENTE: 5.2093201E-04, LEARNING RATE: 2.1847E-04, Nº ITERACIONES: 200000\n",
      "************************************************************************\n",
      "GRADIENTE: 5.2093029E-04, LEARNING RATE: 2.1847E-04, Nº ITERACIONES: 300000\n",
      "************************************************************************\n",
      "GRADIENTE: 5.2092943E-04, LEARNING RATE: 2.1847E-04, Nº ITERACIONES: 400000\n",
      "************************************************************************\n",
      "GRADIENTE: 5.2092891E-04, LEARNING RATE: 2.1847E-04, Nº ITERACIONES: 500000\n",
      "************************************************************************\n",
      "GRADIENTE: 5.2092857E-04, LEARNING RATE: 2.1847E-04, Nº ITERACIONES: 600000\n",
      "************************************************************************\n",
      "GRADIENTE: 1.4712555E-04, LEARNING RATE: 6.1704E-05, Nº ITERACIONES: 700000\n",
      "************************************************************************\n",
      "GRADIENTE: 1.4712549E-04, LEARNING RATE: 6.1704E-05, Nº ITERACIONES: 800000\n",
      "************************************************************************\n",
      "GRADIENTE: 1.4712545E-04, LEARNING RATE: 6.1704E-05, Nº ITERACIONES: 900000\n",
      "************************************************************************\n",
      "GRADIENTE: 1.4712542E-04, LEARNING RATE: 6.1704E-05, Nº ITERACIONES: 1000000\n",
      "*========================================================================*\n",
      "Alcanzó el número máximo de iteraciones\n",
      "ITERACIONES:  1000000\n",
      "GRADIENTE DE F:  0.0001471254204235103\n",
      "*========================================================================*\n",
      "BETA_HAT:  [-9.70636367 15.34062713 -5.80109006  9.38322928  1.64483459 16.62333641\n",
      "  0.53395588  3.89000786  2.84739821  4.61236103  5.0398715   4.9696349 ]\n",
      "ERROR DE CLASIFICACIÓN:  18.18 %\n",
      "*========================================================================*\n",
      "CPU times: user 4min 46s, sys: 666 ms, total: 4min 47s\n",
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time \n",
    "\n",
    "beta_hat = gradient_descent(x_train,y_train,max_iter=10**6,reset_lr=False,verbose_n=100000)\n",
    "yhat = clasifica(x_test,beta_hat)\n",
    "\n",
    "print(\"BETA_HAT: \", beta_hat)\n",
    "print(\"ERROR DE CLASIFICACIÓN: \",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")\n",
    "print(\"*========================================================================*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "GRADIENTE: 5.9664923E+00, LEARNING RATE: 1.0000E+00, Nº ITERACIONES: 10\n",
      "************************************************************************\n",
      "GRADIENTE: 4.9669549E-01, LEARNING RATE: 1.0000E+00, Nº ITERACIONES: 20\n",
      "************************************************************************\n",
      "GRADIENTE: 1.3981306E-03, LEARNING RATE: 1.0000E+00, Nº ITERACIONES: 30\n",
      "************************************************************************\n",
      "GRADIENTE: 1.1753876E-06, LEARNING RATE: 1.0000E+00, Nº ITERACIONES: 40\n",
      "*========================================================================*\n",
      "ITERACIONES:  40\n",
      "GRADIENTE DE F:  1.1753875969730942e-06\n",
      "*========================================================================*\n",
      "BETA_HAT:  [-9.7063437  15.34064205 -5.80107833 13.3216858   1.64484345 18.090213\n",
      "  0.53395169  3.89002152  2.84740552  4.61236333  5.03987498  4.96963699]\n",
      "ERROR DE CLASIFICACIÓN:  18.18 %\n",
      "*========================================================================*\n",
      "CPU times: user 28 ms, sys: 3.97 ms, total: 32 ms\n",
      "Wall time: 58.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Método de Newton\n",
    "beta_hat = gradient_descent(x_train,y_train, method=\"newton\",max_iter = 10**5,verbose_n = 10)\n",
    "yhat = clasifica(x_test,beta_hat)\n",
    "\n",
    "print(\"BETA_HAT: \", beta_hat)\n",
    "print(\"ERROR DE CLASIFICACIÓN: \",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")\n",
    "print(\"*========================================================================*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielapintoveizaga/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:72: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/danielapintoveizaga/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "GRADIENTE: 6.7604013E-04, LEARNING RATE: 1.8530E-01, Nº ITERACIONES: 100000\n",
      "************************************************************************\n",
      "GRADIENTE: 1.8246751E-06, LEARNING RATE: 1.8530E-01, Nº ITERACIONES: 200000\n",
      "*========================================================================*\n",
      "ITERACIONES:  207214\n",
      "GRADIENTE DE F:  1.1997522410752398e-06\n",
      "*========================================================================*\n",
      "BETA_HAT:  [-1.92597509e+02  5.62066406e+02 -7.16006035e+01 -9.05363951e-02\n",
      "  2.33935569e+01  1.11631145e+02 -5.46857075e+01  8.48952910e+01\n",
      "  2.35974039e+01  2.56294180e+01  6.29470910e+01  6.70883012e+01]\n",
      "ERROR DE CLASIFICACIÓN:  13.64 %\n",
      "*========================================================================*\n",
      "CPU times: user 38.1 s, sys: 225 ms, total: 38.3 s\n",
      "Wall time: 38.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Método BFSG\n",
    "\n",
    "beta_hat = gradient_descent(x_train,y_train, method = \"bfsg\",max_iter = 10**6,lr=1,verbose_n = 100000)\n",
    "yhat = clasifica(x_test,beta_hat)\n",
    "\n",
    "print(\"BETA_HAT: \", beta_hat)\n",
    "print(\"ERROR DE CLASIFICACIÓN: \",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")\n",
    "print(\"*========================================================================*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso del gradiente estocastico\n",
    "\n",
    "Calculamos la función de riesgo empírico como la esperanza de la funcion de perdida evaluada sobre todos los puntos del dominio.\n",
    "\n",
    "$$L_{emp}=\\frac{1}{m} \\sum^{m}_{i=1} y_i log(\\mu_i) + (1-y_i) log(1-\\mu_i)$$  \n",
    "<br>\n",
    "$$ \\mu_i = (1+e^{-\\beta^T x_i})^{-1}= \\sigma(\\beta^T x_i)$$\n",
    "\n",
    "Y el gradiente de la función de riesgo esta dado por:\n",
    "\n",
    "$$\\nabla L=\\frac{dL}{d\\mu_i} =\\frac{1}{m} \\sum^{m}_{i=1} x_i(\\mu_i-y_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def riesgo_empirico(X,y,beta):\n",
    "    \n",
    "    '''\n",
    "    Función que calcular el riesgo empírico como la esperanza de la función de pérdida\n",
    "    \n",
    "    evaluada sobre todos los puntos del dominio.\n",
    "    \n",
    "        - Parámetros:\n",
    "            -- X (mat): matriz de mxp entradas\n",
    "    \n",
    "            -- y (vec): vector de de m entradas de la variable output\n",
    "            \n",
    "            -- beta (vec): vector con p entradas\n",
    "\n",
    "        - Salidas\n",
    "            \n",
    "            -- loss (float64): riesgo empírico\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "    if beta.shape[0]!= p:\n",
    "        sys.exit('Error:  El número de columnas de X debe ser igual al número de entradas del vector beta.')\n",
    "\n",
    "\n",
    "    mu=calc_mu(X,beta)\n",
    "    loss=-sum(y*np.log(mu)+(1-y)*np.log(1-mu))\n",
    "    return loss\n",
    "\n",
    "def gradiente_riesgo_empirico(X,y,beta):\n",
    "    \n",
    "    '''\n",
    "    Función que calcular el gradiente de la función de riesgo.\n",
    "    \n",
    "        - Parámetros:\n",
    "        \n",
    "            -- X (mat): matriz de mxp entradas.\n",
    "            \n",
    "            -- y (vec): vector de de m entradas de la variable output.\n",
    "            \n",
    "            -- beta (vec): vector con p entradas.\n",
    "\n",
    "        - Salidas\n",
    "            \n",
    "            -- grad_riesgo_emp (vec): vector de p entradas\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "    if beta.shape[0]!= p:\n",
    "        sys.exit('Error:  El número de columnas de X debe ser igual al número de entradas del vector beta.')\n",
    "\n",
    "    m = X.shape[0]\n",
    "    mu = calc_mu(X,beta)\n",
    "    grad_riesgo_emp = np.matmul(np.transpose(X),mu-y)/m\n",
    "    return grad_riesgo_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def batch(m,q=10):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    index=np.random.randint(low=0,high=m,size=q)\n",
    "    return index\n",
    "\n",
    "def error_train(X,y,beta):\n",
    "    prediction=clasifica(X,beta)\n",
    "    err=round(100*sum(abs(y-prediction))/len(prediction),2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SGD(X,y,batch_size,verbose_n=100,max_iter=10**5):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "     # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "\n",
    "\n",
    "    # Inicializa\n",
    "    m=X.shape[0]\n",
    "    epsilon = 10**(-6)\n",
    "    beta = np.random.normal(0,1,X.shape[1])    \n",
    "    step_size=.01\n",
    "    iteraciones = 0\n",
    "    epoca=0\n",
    "    ipe=int(m/batch_size)#iteraciones por epoca\n",
    "    \n",
    "    # Primera iteracion\n",
    "    index=batch(m,batch_size)\n",
    "    x_lote=X[index,:]\n",
    "    y_lote = y[index]\n",
    "    beta_new = beta - step_size * gradiente_riesgo_empirico(x_lote,y_lote,beta) \n",
    "    \n",
    "\n",
    "    perdida=riesgo_empirico(X,y,beta)\n",
    "    error=error_train(X,y,beta)\n",
    "    \n",
    "    # while ((np.linalg.norm(gradiente_f(X,y,beta_new)) > epsilon) & (iteraciones < max_iter)):\n",
    "    # while abs(f(X,y,beta) - f(X,y,beta_new)) > epsilon:\n",
    "    while iteraciones<max_iter:\n",
    "        iteraciones +=1\n",
    "        #print(\"iteraciones1=\",iteraciones)\n",
    "        beta = beta_new\n",
    "        #x_lote,y_lote = mini_lotes(X,y,q)\n",
    "        index=batch(m,batch_size)\n",
    "        x_lote=X[index,:]\n",
    "        y_lote = y[index]\n",
    "        beta_new = beta - step_size * gradiente_riesgo_empirico(x_lote,y_lote,beta)\n",
    "        #print(\"iteraciones2=\",iteraciones)\n",
    "        if iteraciones%10000==0:\n",
    "            epoca+=1\n",
    "            loss=riesgo_empirico(X,y,beta)\n",
    "            perdida=np.append(perdida,loss)\n",
    "            err=error_train(X,y,beta)\n",
    "            error=np.append(error, error_train(x_test,y_test,beta_hat))\n",
    "            print(f'loss:{loss:.4}, epoca:{epoca}, iter:{iteraciones}')\n",
    "        #print(\"iteraciones3=\",iteraciones)\n",
    "    print(\"Nº DE INTERACIONES: \",iteraciones)\n",
    "    return beta_new,perdida,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graf_loss_err(loss,error,title):\n",
    "    '''\n",
    "    \n",
    "    Función para graficar la pérdida o riesgo emírico y el error\n",
    "    \n",
    "    de entrenamiento en cada iterazación.\n",
    "    \n",
    "        - Entradas:\n",
    "                    -- loss\n",
    "                    -- error\n",
    "                    ---title\n",
    "        \n",
    "        - Salidas:\n",
    "                    -- plot\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    x=np.arange(0,len(error))\n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "    axs[0].plot(x, error)\n",
    "    axs[0].set_xlabel('Iteraciones')\n",
    "    axs[0].set_ylabel('Train error %')\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    axs[1].plot(x, loss)\n",
    "    axs[1].set_xlabel('Iteraciones')\n",
    "    axs[1].set_ylabel('Perdida')\n",
    "    axs[1].grid(True)\n",
    "    axs[0].set_title(title, fontsize=14)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#graf_loss_err(loss[0,20],error[0:20],\"Batch size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*========================================================================*\n",
      "loss:23.66, epoca:1, iter:10000\n",
      "loss:19.63, epoca:2, iter:20000\n",
      "loss:17.91, epoca:3, iter:30000\n",
      "loss:16.92, epoca:4, iter:40000\n",
      "loss:16.23, epoca:5, iter:50000\n",
      "loss:15.73, epoca:6, iter:60000\n",
      "loss:15.34, epoca:7, iter:70000\n",
      "loss:15.04, epoca:8, iter:80000\n",
      "loss:14.79, epoca:9, iter:90000\n",
      "loss:14.59, epoca:10, iter:100000\n",
      "Nº DE INTERACIONES:  100000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_hat= [-4.68180667  9.509749   -3.35442423  1.19280859  1.1928756   4.27419549\n",
      "  0.78917096  2.27825098  1.09678643  2.04861855  1.91243402  2.21850039]\n",
      "Error de clasificacion= 13.64 %\n",
      "\n",
      "\n",
      "CPU times: user 14.7 s, sys: 1.95 s, total: 16.7 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Método de SGD\n",
    "for batch_size in range(9,10):\n",
    "    \n",
    "    \n",
    "    print(\"*========================================================================*\")\n",
    "    #print(\"Tamaño de minilote= \",batch_size)\n",
    "    beta_hat, loss, error = SGD(x_train, y_train, max_iter=10**5, batch_size=batch_size)\n",
    "    yhat = clasifica(x_test,beta_hat)\n",
    "    titulo=\"Batch size = \"+ str(batch_size)\n",
    "    graf_loss_err(loss,error,titulo)\n",
    "    print(\"beta_hat=\", beta_hat)\n",
    "    print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_batch(m):\n",
    "    index=np.arange(0,m)\n",
    "    np.random.shuffle(index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "from dask.distributed import Client, progress\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41343</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:34637/status' target='_blank'>http://127.0.0.1:34637/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>8.21 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:41343' processes=4 threads=8, memory=8.21 GB>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paso 1. Dividir el dominio en partes iguales\n",
    "cores = multiprocessing.cpu_count() # cpus disponibles\n",
    "#n_subint = int(density_p/p) # número de puntos o nodos en cada core o cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construye_indices(ids,m,cores):\n",
    "    '''\n",
    "    Argumentos:\n",
    "    ----------\n",
    "    * ids: Identificador del core dónde se está corriendo el task. \n",
    "    * m (array): Numero total de puntos de entrenamiento.\n",
    "    * cores (int) : Número de cores o cpus disponibles\n",
    "    \n",
    "    Salidas:\n",
    "    -------\n",
    "    * (index_from, index_to): Rango de indices que se seleccionan del verctor de permutaciones\n",
    "    '''\n",
    "    \n",
    "    tamano_int = int(m/cores) #tamaño de cada sub intervalo.\n",
    "    index_from = ids*tamano_int #construyen los subintervalo\n",
    "    index_to = index_from + tamano_int\n",
    "    if ids==(cores-1): index_to=m\n",
    "    return (index_from,index_to)\n",
    "\n",
    "\n",
    "def evalua_gradiente(intervalo,perm,X,y,beta):\n",
    "    \"\"\"\n",
    "    Función que evalúa el gradiente del riesgo empirico para cada conjunto de indices de permutaciones    \n",
    "    Argumentos:\n",
    "    ----------\n",
    "    * intervalo: Intervalo de indices del vector perm a utilizar\n",
    "    * perm: Vector de permutaciones \n",
    "    * X: Puntos de entrenamiento\n",
    "    * y: Etiquetas de los puntos de entrenamiento\n",
    "    * beta: Vector de parametros a optimizar\n",
    "    \n",
    "    Salidas:\n",
    "    * Evaluacion del gradiente del riesgo empirico para un mini lote\n",
    "    --------\n",
    "\n",
    "    \"\"\"   \n",
    "    index=perm[intervalo[0]:intervalo[1]]\n",
    "    x_lote = X[index,:]\n",
    "    y_lote = y[index]\n",
    "    gradiente=gradiente_riesgo_empirico(x_lote,y_lote,beta) \n",
    "    return gradiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_paralelo(X,y,verbose_n=100,max_iter=10**5):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "     # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "\n",
    "\n",
    "    # Inicializa\n",
    "    m=X.shape[0]\n",
    "    epsilon = 10**(-6)\n",
    "    beta = np.random.normal(0,1,X.shape[1])    \n",
    "    step_size=.01\n",
    "    iteraciones = 0\n",
    "    epoca=0\n",
    "    \n",
    "    # Primera iteracion\n",
    "    perm=n_batch(m)\n",
    "    #calcula los indices\n",
    "    indices = client.map(construye_indices,range(cores),\n",
    "                **{'m':m,'cores':cores})\n",
    "\n",
    "    #evalua el gradiente en cada batch en paralelo\n",
    "    grad_riesgo_empirico=client.map(evalua_gradiente,indices,\n",
    "                **{'perm':perm,'X':X,'y':y,'beta':beta})\n",
    "\n",
    "    results=client.gather(grad_riesgo_empirico)\n",
    "    actualiza=sum(results)\n",
    "    \n",
    "    beta_new = beta - step_size * actualiza  \n",
    "    #gradiente_riesgo_empirico(x_lote,y_lote,beta) \n",
    "    \n",
    "    perdida=riesgo_empirico(X,y,beta)\n",
    "    error=error_train(X,y,beta)\n",
    "    \n",
    "    # while ((np.linalg.norm(gradiente_f(X,y,beta_new)) > epsilon) & (iteraciones < max_iter)):\n",
    "    # while abs(f(X,y,beta) - f(X,y,beta_new)) > epsilon:\n",
    "    while iteraciones<max_iter:\n",
    "        iteraciones +=1\n",
    "        beta = beta_new\n",
    "        perm=n_batch(m)\n",
    "        #calcula los indices\n",
    "        indices = client.map(construye_indices,range(cores),**{'m':m,'cores':cores})\n",
    "        #evalua el gradiente en cada batch en paralelo\n",
    "        grad_riesgo_empirico=client.map(evalua_gradiente,indices,\n",
    "                     **{'perm':perm,'X':X,'y':y,'beta':beta})\n",
    "        #gather results\n",
    "        results=client.gather(grad_riesgo_empirico)\n",
    "        actualiza=sum(results)\n",
    "        \n",
    "        beta_new = beta - step_size * actualiza\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if iteraciones%100==0:\n",
    "            epoca+=1\n",
    "            loss=riesgo_empirico(X,y,beta)\n",
    "            perdida=np.append(perdida,loss)\n",
    "            err=error_train(X,y,beta)\n",
    "            error=np.append(error, error_train(x_test,y_test,beta_hat))\n",
    "            print(f'loss:{loss:.4}, epoca:{epoca}, iter:{iteraciones}')\n",
    "        #print(\"iteraciones3=\",iteraciones)\n",
    "    print(\"Nº DE INTERACIONES: \",iteraciones)\n",
    "    return beta_new,perdida,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*========================================================================*\n",
      "loss:40.94, epoca:1, iter:100\n",
      "loss:35.62, epoca:2, iter:200\n",
      "loss:32.19, epoca:3, iter:300\n",
      "loss:29.81, epoca:4, iter:400\n",
      "loss:28.05, epoca:5, iter:500\n",
      "loss:26.71, epoca:6, iter:600\n",
      "loss:25.63, epoca:7, iter:700\n",
      "loss:24.75, epoca:8, iter:800\n",
      "loss:24.0, epoca:9, iter:900\n",
      "loss:23.37, epoca:10, iter:1000\n",
      "loss:22.81, epoca:11, iter:1100\n",
      "loss:22.33, epoca:12, iter:1200\n",
      "loss:21.89, epoca:13, iter:1300\n",
      "loss:21.5, epoca:14, iter:1400\n",
      "loss:21.15, epoca:15, iter:1500\n",
      "loss:20.83, epoca:16, iter:1600\n",
      "loss:20.54, epoca:17, iter:1700\n",
      "loss:20.28, epoca:18, iter:1800\n",
      "loss:20.03, epoca:19, iter:1900\n",
      "loss:19.8, epoca:20, iter:2000\n",
      "loss:19.58, epoca:21, iter:2100\n",
      "loss:19.38, epoca:22, iter:2200\n",
      "loss:19.2, epoca:23, iter:2300\n",
      "loss:19.02, epoca:24, iter:2400\n",
      "loss:18.86, epoca:25, iter:2500\n",
      "loss:18.7, epoca:26, iter:2600\n",
      "loss:18.55, epoca:27, iter:2700\n",
      "loss:18.41, epoca:28, iter:2800\n",
      "loss:18.28, epoca:29, iter:2900\n",
      "loss:18.15, epoca:30, iter:3000\n",
      "loss:18.03, epoca:31, iter:3100\n",
      "loss:17.92, epoca:32, iter:3200\n",
      "loss:17.81, epoca:33, iter:3300\n",
      "loss:17.71, epoca:34, iter:3400\n",
      "loss:17.61, epoca:35, iter:3500\n",
      "loss:17.51, epoca:36, iter:3600\n",
      "loss:17.42, epoca:37, iter:3700\n",
      "loss:17.33, epoca:38, iter:3800\n",
      "loss:17.24, epoca:39, iter:3900\n",
      "loss:17.16, epoca:40, iter:4000\n",
      "loss:17.08, epoca:41, iter:4100\n",
      "loss:17.01, epoca:42, iter:4200\n",
      "loss:16.93, epoca:43, iter:4300\n",
      "loss:16.86, epoca:44, iter:4400\n",
      "loss:16.79, epoca:45, iter:4500\n",
      "loss:16.73, epoca:46, iter:4600\n",
      "loss:16.66, epoca:47, iter:4700\n",
      "loss:16.6, epoca:48, iter:4800\n",
      "loss:16.54, epoca:49, iter:4900\n",
      "loss:16.48, epoca:50, iter:5000\n",
      "loss:16.43, epoca:51, iter:5100\n",
      "loss:16.37, epoca:52, iter:5200\n",
      "loss:16.32, epoca:53, iter:5300\n",
      "loss:16.27, epoca:54, iter:5400\n",
      "loss:16.22, epoca:55, iter:5500\n",
      "loss:16.17, epoca:56, iter:5600\n",
      "loss:16.12, epoca:57, iter:5700\n",
      "loss:16.07, epoca:58, iter:5800\n",
      "loss:16.03, epoca:59, iter:5900\n",
      "loss:15.98, epoca:60, iter:6000\n",
      "loss:15.94, epoca:61, iter:6100\n",
      "loss:15.9, epoca:62, iter:6200\n",
      "loss:15.86, epoca:63, iter:6300\n",
      "loss:15.82, epoca:64, iter:6400\n",
      "loss:15.78, epoca:65, iter:6500\n",
      "loss:15.74, epoca:66, iter:6600\n",
      "loss:15.7, epoca:67, iter:6700\n",
      "loss:15.67, epoca:68, iter:6800\n",
      "loss:15.63, epoca:69, iter:6900\n",
      "loss:15.6, epoca:70, iter:7000\n",
      "loss:15.56, epoca:71, iter:7100\n",
      "loss:15.53, epoca:72, iter:7200\n",
      "loss:15.5, epoca:73, iter:7300\n",
      "loss:15.47, epoca:74, iter:7400\n",
      "loss:15.44, epoca:75, iter:7500\n",
      "loss:15.4, epoca:76, iter:7600\n",
      "loss:15.38, epoca:77, iter:7700\n",
      "loss:15.35, epoca:78, iter:7800\n",
      "loss:15.32, epoca:79, iter:7900\n",
      "loss:15.29, epoca:80, iter:8000\n",
      "loss:15.26, epoca:81, iter:8100\n",
      "loss:15.23, epoca:82, iter:8200\n",
      "loss:15.21, epoca:83, iter:8300\n",
      "loss:15.18, epoca:84, iter:8400\n",
      "loss:15.16, epoca:85, iter:8500\n",
      "loss:15.13, epoca:86, iter:8600\n",
      "loss:15.11, epoca:87, iter:8700\n",
      "loss:15.08, epoca:88, iter:8800\n",
      "loss:15.06, epoca:89, iter:8900\n",
      "loss:15.04, epoca:90, iter:9000\n",
      "loss:15.01, epoca:91, iter:9100\n",
      "loss:14.99, epoca:92, iter:9200\n",
      "loss:14.97, epoca:93, iter:9300\n",
      "loss:14.95, epoca:94, iter:9400\n",
      "loss:14.93, epoca:95, iter:9500\n",
      "loss:14.9, epoca:96, iter:9600\n",
      "loss:14.88, epoca:97, iter:9700\n",
      "loss:14.86, epoca:98, iter:9800\n",
      "loss:14.84, epoca:99, iter:9900\n",
      "loss:14.82, epoca:100, iter:10000\n",
      "Nº DE INTERACIONES:  10000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZxcZZn3/8+3qvfu7AltgEAihE1Ulog4IE/C5oa4DO46KDhRRscNR9F55lHHZdz3ZURhROVndAARUQFFWkBlSdghIhHCZkgCZOt00uv1++OcSqp6raS7uqpS3/frVa+qs9Q5V92c9MV9n/vctyICMzOzSpMpdwBmZmbDcYIyM7OK5ARlZmYVyQnKzMwqkhOUmZlVJCcoMzOrSE5QZhNA0lsldU7wMT8u6Z6JPKZZNXGCsj2GpB9IirzXk5KulHTILh6nUhLDF4H/U+4gRiOpPS33v0vqknSVpIXljsv2DE5Qtqf5HTA3fZ0KNAM/L2tEuykiOiPiqXLHMRJJAi4HFgKvBI4EHgZ+J6m1nLHZnsEJyvY03RHxRPq6DfgKcIik5twOkj4r6X5J2yStlvR5SU3ptrcCHwOelVcTe2u6bZqk70haI2m7pJWSXpd/ckknSbpH0lZJ10laMFqwkt4h6a/p8Z6UdLWkunTbjpqcpPmDaoe51+q8Yx0m6VeStkhaJ+knkp4xAWU6koXAscC/RMQtEXE/cA7J/xS8oYTntRrhBGV7LElTgNcBd0fEtrxNW4GzgEOBfwFeD/x7uu2nwJeA+9lZE/tpWlv4NUmT29uAw4APAD15x20EPpIe+wXAdOC/R4lvEfAt4BPAwcBJwFUj7P5oXjxzgYNIaisd6bHmAtcD9wDHACcDbcAvJI3471zSvZI6R3ndO9J3098LsD23IiIGgG7g+FG+Z1aUunIHYDbBXpzXWaGV5A/7S/N3iIhP5i2ulvQZ4IPAf0TEtvT7fRHxRG4nSaeQJJ1nRcTKdPWDg85dB7wrrUkg6YvAhZIUww96uR9JsrwiIraQJJw7h/tREdEPPJEeNwN8H1gDvDPd5Rzgzoj4cF7M/wQ8DSwCbhnuuCRlUz/CNoDeUbb9BXgE+IykfwY6gfcD+5IkUbNxcYKyPc31wNL08wySGtI1kp4fEY8CSDoDeB9wIEktI5u+RnMksCYvOQ2nO5ecUn8HGtI4nh5m/9+SJKWHJF0NXANcliar0XwOeA7wvIjI1V6OBk4YoSfhAYyQoCLi4THONaKI6JX0auAC4Cmgn+Qe4G8A7e5xzXLcxGd7mq6IWJW+bgXeDkwlTVqSjgWWAVcDLydJPP+X0WsRxeobtJyrNQ377yxNREcBryWpiXwE+IukvUc6gaQzSWpNL4+ItXmbMsCvgCMGvRYCV45yvPE08RERKyLiCJLmzLkR8WJgFkNrl2a7zDUo29MFMAC0pMvHAY/nN/NJ2n/Qd3oYWqO6HZgr6dAxalG7FlxEH/B74PeSPgasA04Dzh+8r6R/AL4DvCEiBjcF3kaS6B6OiNGa5QYbTxPfDhGxKY1xIUmT4n/sQgxmw3KCsj1NY17PtRnAu0ma8X6ZrvsrsI+kNwF/Bl7E0B5nq4H9JR1FUrPZAlwL3AxcKun96XEOBFoj4vLdCVTSaSTNb9eTNAEuAaYAQxJg+pt+DnwbuDnvN/ZHxHqSzhb/TNKh43PAeuCZJEnr3JGaDcfTxJfG9RrgSZKmymcDXwMuj4hrxnNcM3ATn+15TibpPLCGJKE8D3hNRHQARMQvgS8AXwXuAk4B/t+gY1xK0mPvWpI/9G9Ie6e9BPgj8GOSJPI1kntMu2sjyfNDvyPpcPBB4O0RccMw+x4C7AWcm/f71gC3pr/r7yS1wwGSnoD3kiSt7vRVKnOBH6bxfx34Ee5ibhNEnlHXzMwqkWtQZmZWkZygzMysIjlBmZlZRXKCMjOzilSybubp4JvXk4zXVQdcEhEfSwfPXEbyMN8K4C0R0TPykWD27Nkxf/78ccWzdetWWls9wHI+l0khl8dQLpNCLo9CE1UeK1aseDIi5gxeX8rnoLqBEyOiU1I9cKOk35AMsPmViFgm6b+Bs0kePhzR/PnzWb58+biC6ejoYPHixeM6xp7GZVLI5TGUy6SQy6PQRJWHpGGfxytZE18kcuOC1aevAE4ELknXX0TyHIiZmVmBkj4HJSlL0ox3IMlDg18AboqIA9Pt84DfRMThw3x3Ken4ae3t7UcvW7Zst+N4YEM/Gzq3ccy8tt0+xp6os7OTtjaXSY7LYyiXSSGXR6GJKo8lS5asiIhFg9eXdKijdIqAIyRNJxmmpeiptyPifNLxyBYtWhTjqUb+5EfLuffhbj70lt0/xp7IzRWFXB5DuUwKuTwKlbo8JqUXX0RsBK4jncQtN2Moybwxj5f6/C0NdXT3l/osZmY2kUqWoCTNSWtOpNNtn0Iyftl1wBnpbmcCvyhVDDnNDVm6+z2kk5lZNSllE99c4KL0PlQG+FlEXCnpPmCZpE+RTGFwQQljAKClPusalJlZlSlZgoqIu0gmgxu8/kHgmFKddzgtDVl6+iEikDzRp5lZNaiJkSSaGrIEsL13oNyhmJlZkWoiQbXUJ5OjdvUMnpHbzMwqVW0kqIakJbOrxzeizMyqRU0kqOaGpAa1rdcJysysWuxSgpLUIKmlVMGUSktDronPCcrMrFoUnaAkvQ34FXClpE+WLqSJ19zge1BmZtVmxAQl6aWDVr0oIk6JiBOB00sb1sTK3YPa5hqUmVnVGK0G9TxJP5eUG8j1XknflfQd4C+TENuEafE9KDOzqjPig7oR8QlJewOflNQL/D9gJtASEbdNVoATobne96DMzKrNWCNJbAD+BXgWcCHwJ+BLpQ5qou2oQTlBmZlVjdHuQX0CuBK4BjguIk4jadr7taQ3TlJ8E8LPQZmZVZ/R7kG9IiJOAhYDbwOIiMuAF5MMBFs1muozCNjmXnxmZlVjtCa+lZK+DbQAN+ZWRkQvVdbMJ4mGrGtQZmbVZLROEm+QdCTQGxH3TGJMJdGQhS734jMzqxqjdpKIiNsnK5BSa8zKnSTMzKpITYzFB9CY9UgSZmbVZNQEpcRudYiQNE/SdZLuk3SvpPem6z8u6XFJd6SvwSNWlERjVr4HZWZWRcZq4gtJvwUOH22/EfQB50bEbZKmACvSYwF8JSK+uBvH3G2NWT8HZWZWTYpp4rsj7SyxSyJiTW7EiYjYAqwE9tnV40yUBtegzMyqiiJi9B2ke4GDgb8BWwGRVK6OKvok0nzgepKa2AeAtwKbgeUktawNw3xnKbAUoL29/ehly5YVe7phfX15J493ZfjcCVU3W0jJdHZ20tbWVu4wKobLYyiXSSGXR6GJKo8lS5asiIhFg9cXk6AOGG59RPytmBNLagP+AHw6Ii6T1A48CQTwSWBuRJw12jEWLVoUy5cvL+Z0I3rLN67mgS113PTRk8Z1nD1JR0cHixcvLncYFcPlMZTLpJDLo9BElYekYRPUmE18aSJqAk5JX027kJzqgUuBi9NRKIiItRHRHxEDwPeAY4r/GbvPvfjMzKrLmAlK0ruB/wX2S18/k/QvRXxPwAXAyoj4ct76/F6BrwIm5SHgxqw83YaZWRUZazRzSO4DHRMRnQCSPkMyqvm3x/jeccBbgLsl3ZGu+yjwBklHkDTxrQbesRtx77LGOujtD3r7B6jP1szjX2ZmVauYBCWgJ2+5N103qoi4cYT9fl1caBOrMZuE0tXTz7RmJygzs0pXTIL6EXCzpEvT5VcBF5UupNJoTKaEYltPP9Oa68sbjJmZjWnMBBURn5fUARyfrnpnRNxa0qhKoGFHDcodJczMqsGoCUpSFrgrIp4F3DI5IZVGrgblh3XNzKrDqDdjIqIfeFBS2UaAmCg7mvjck8/MrCoUcw+qjWTywj+TjCQBQES8umRRlUB+JwkzM6t8xSSoT5U8iknQsKOThO9BmZlVg2LuQZ0XEadMUjwl4xqUmVl1KeYeVFbS1EmKp2TcScLMrLoU08S3CbhT0jUU3oP6QMmiKoFcDWq7O0mYmVWFYhLUlemrqrkGZWZWXYp5UPcCSQ3AfhGxahJiKolsRjRkM05QZmZVopjRzF8G3A38Nl0+QtLPSx1YKTQ3ZN2Lz8ysShQzaup/As8HNgJExB3AgaUMqlRaGrKuQZmZVYliElRvRGwctG70aXgrVHNDli53kjAzqwrFdJJYKem1QEbSAuA9wE2lDas0muuzbHMNysysKhRTg3o3cDQwAFwGdAPvK2VQpZI08fkelJlZNRgzQUXE1oj4cEQcmb7Oi4iusb4naZ6k6yTdJ+leSe9N18+U9FtJD6TvMybihxSjuaHONSgzsypRyqll+4BzI+Iw4FjgXZIOA84Dro2IhcC16fKkaKl3Jwkzs2pRsgQVEWsi4rb08xZgJbAP8Ap2zsh7EfDKUsUwmHvxmZlVD0WUvkOepPnA9cDhwCMRMT1dL2BDbnnQd5YCSwHa29uPXrZs2bhi6Ozs5NKH61n+RB/fOKl1XMfaU3R2dtLW1lbuMCqGy2Mol0khl0ehiSqPJUuWrIiIRYPXj9mLT9Js4Cxgfv7+EbG0mBNLagMuBd4XEZuTnLTjGCFp2AwZEecD5wMsWrQoFi9eXMzpRtTR0cGB8/fipiceYbzH2lN0dHS4LPK4PIZymRRyeRQqdXkU0838FyTdym8Edql9TFI9SXK6OCIuS1evlTQ3ItZImgus25VjjkdzQx3bevsZGAgyGY39BTMzK5tiElRrRJy7qwdOm+8uAFZGxJfzNl0BnAl8Nn3/xa4ee3e1pLMWbu/rp6WhmJ9uZmblUkwnid9IOnU3jn0c8BbgREl3pK+XkiSmUyQ9AJycLk+KXIJyRwkzs8pXTDXincCHJXUBPYBIbh/NHO1LEXFjuu9wTtqlKCdIc32SoPwslJlZ5SsmQc0ueRSTJNes5xqUmVnlGzFBSVoYEQ8Azxphl7tKE1Lp7Gzi83BHZmaVbrQa1HnA2cC3htkWwAkliaiEmtzEZ2ZWNUZMUBFxdvr+wskLp7TcScLMrHoU1dda0iHAYUBTbl1E/H+lCqpUdiQozwllZlbxihlJ4v8CpwKHAFcDLyJ5aLfqElRzQ66Jz/egzMwqXTHPQb0OWAKsiYi3AM8FqnIwO/fiMzOrHsUkqG0R0Q/0SZoCPAHsX9qwSsP3oMzMqkcx96BulzQduBBYDmwGbilpVCXSWJdBgu2+B2VmVvFGTVDpeHofj4iNwLckXQ1Mzc3zVG0kedJCM7MqMWqCSqfD+C3JPE5ExKpJiaqEmhvqnKDMzKpAMfeg7pB0ZMkjmSQtDVn34jMzqwKjDXVUFxF9wJHArZL+Bmxl52CxR01SjBPK076bmVWH0Zr4bgGOAk6fpFgmRXNDlm3uJGFmVvFGS1ACiIi/TVIsk6LZnSTMzKrCaAlqjqQPjLRx0Cy5VaOlIcuGrt5yh2FmZmMYrZNEFmgDpozwGpWkCyWtk3RP3rqPS3p80Ay7k6q5oc6dJMzMqsBoNag1EfGf4zj2D4BvAj8ctP4rEfHFcRx3XPwclJlZdRitBjXSdO1FiYjrgafHc4xSaG7Iej4oM7MqoIgYfoM0MyLGlWAkzQeujIjD0+WPA28lGS5pOXBuRGwY4btLgaUA7e3tRy9btmw8odDZ2UlbWxuX/LWHXz/UywWntpAMlFG7cmViCZfHUC6TQi6PQhNVHkuWLFkREYuGbIiIkr2A+cA9ecvtJPe2MsCngQuLOc7RRx8d43XddddFRMQ3rv1r7P/hK6O7t3/cx6x2uTKxhMtjKJdJIZdHoYkqD2B5DPO3v5iRJCZMRKyNiP6IGAC+BxwzmeeHpJMEeNp3M7NKN6kJStLcvMVXAfeMtG+p7JxV1z35zMwqWVFTvu8OST8BFgOzJT0GfAxYLOkIIIDVwDtKdf6ReE4oM7PqULIEFRFvGGb1BaU6X7Ga65MEtX5LN7PbGsscTXlt7Q02bfNDyzkuj6FcJoVcHoW29gZ9/QPUZUvTGFeyBFWppjTVA/D6828qcyQV4tpryh1BZXF5DOUyKeTyKHDJwo0smj+zJMeuuQS1aP4MPvvqZ7PVTXysWrWKAw88sNxhVAyXx1Auk0Iuj0KrVq1i3syWkh2/5hJUfTbD64/Zr9xhVISOvodZfPyCcodRMVweQ7lMCrk8CnX0PUz71KaSHX9Se/GZmZkVywnKzMwq0ohDHVUSSeuBh8d5mNnAkxMQzp7EZVLI5TGUy6SQy6PQRJXH/hExZ/DKqkhQE0HS8hhurKca5jIp5PIYymVSyOVRqNTl4SY+MzOrSE5QZmZWkWopQZ1f7gAqkMukkMtjKJdJIZdHoZKWR83cgzIzs+pSSzUoMzOrIk5QZmZWkWoiQUl6saT7Ja2SdF6545lskuZJuk7SfZLulfTedP1MSb+V9ED6PqPcsU4mSVlJt0u6Ml1eIOnm9Dr5qaSGcsc4mSRNl3SJpL9IWinpBbV8jUh6f/rv5R5JP5HUVGvXiKQLJa2TdE/eumGvCSW+npbNXZKOGu/59/gEJSkLfAt4CXAY8AZJh5U3qknXB5wbEYcBxwLvSsvgPODaiFgIXJsu15L3Aivzlj8HfCUiDgQ2AGeXJary+RpwVUQcAjyXpGxq8hqRtA/wHmBRRBwOZIHXU3vXyA+AFw9aN9I18RJgYfpaCnxnvCff4xMUybTyqyLiwYjoAZYBryhzTJMqItZExG3p5y0kf3j2ISmHi9LdLgJeWZ4IJ5+kfYGXAd9PlwWcCFyS7lJr5TENOIF0zraI6ImIjdTwNUIymHazpDqgBVhDjV0jEXE98PSg1SNdE68AfhiJm4Dpg2ZR32W1kKD2AR7NW34sXVeTJM0HjgRuBtojYk266QmgvUxhlcNXgQ8BA+nyLGBjRPSly7V2nSwA1gP/kzZ7fl9SKzV6jUTE48AXgUdIEtMmYAW1fY3kjHRNTPjf2lpIUJaS1AZcCrwvIjbnb4vkeYOaeOZA0mnAuohYUe5YKkgdcBTwnYg4EtjKoOa8GrtGZpDUCBYAewOtDG3qqnmlviZqIUE9DszLW943XVdTJNWTJKeLI+KydPXaXBU8fV9Xrvgm2XHA6ZJWkzT5nkhy/2V62pwDtXedPAY8FhE3p8uXkCSsWr1GTgYeioj1EdELXEZy3dTyNZIz0jUx4X9rayFB3QosTHvfNJDc6LyizDFNqvT+ygXAyoj4ct6mK4Az089nAr+Y7NjKISI+EhH7RsR8kuvh9xHxJuA64Ix0t5opD4CIeAJ4VNLB6aqTgPuo0WuEpGnvWEkt6b+fXHnU7DWSZ6Rr4grgn9LefMcCm/KaAndLTYwkIemlJPccssCFEfHpMoc0qSQdD9wA3M3Oey4fJbkP9TNgP5LpTF4bEYNviO7RJC0GPhgRp0l6JkmNaiZwO/DmiOguZ3yTSdIRJJ1GGoAHgbeR/E9sTV4jkj4BvI6kF+ztwNtJ7qnUzDUi6SfAYpJpNdYCHwMuZ5hrIk3k3yRpCu0C3hYRy8d1/lpIUGZmVn1qoYnPzMyqkBOUmZlVJCcoMzOrSE5QZmZWkZygzMysIjlBmRVJUmf6Pl/SGyfhfKfX4uj7ZjnuZm5WJEmdEdGW/+zULny3Lm8MNzMrgmtQZrvus8ALJd2RzhmUlfQFSbem8+C8A5KHgCXdIOkKklEIkHS5pBXpPENLcwdUMmfZbZLulHRtuu6tkr6Zfp4v6ffp8a+VtF+6/gfpHDx/kvSgpDPyjvlveTF9Il3XKulX6XnukfS6ySo0s11VN/YuZjbIeeTVoNJEsykiniepEfijpGvSfY8CDo+Ih9Lls9Kn7puBWyVdSvI/it8DToiIhyTNHOac3wAuioiLJJ0FfJ2d0xzMBY4HDiEZbuYSSaeSzMtzDCDgCkknAHOAv0fEy9LYp01YqZhNMCcos/E7FXhOXu1lGkly6AFuyUtOAO+R9Kr087x0vznA9bn9RhhK6AXAq9PPPwI+n7ft8ogYAO6TlJv64NT0dXu63Jae6wbgS5I+B1wZETfszg82mwxOUGbjJ+BfI+LqgpXJvaqtg5ZPBl4QEV2SOoCmCTh//lhwynv/r4j47pBgk6m4Xwp8StK1EfGfExCD2YTzPSizXbcFmJK3fDVwTjqlCZIOSif7G2wasCFNTocAx6brbwJOkLQg/f5wTXx/Ihl5HeBNJDWh0VwNnJXOAYakfSTtJWlvoCsifgx8gaQJ0qwiuQZltuvuAvol3Qn8gGQuqfnAbemIzusZfirwq4B3SloJ3E+SmIiI9el9rMskZUjm1zll0Hf/lWS2239Lj/+20QKMiGskHQr8OQmJTuDNwIHAFyQNAL3AObv2080mj7uZm5lZRXITn5mZVSQnKDMzq0hOUGZmVpGcoMzMrCI5QZmZWUVygjIzs4rkBGVmZhXJCcrMzCqSE5SZmVUkJygzM6tIVZGgJF1V7hjMzKw0RvobXxWDxU6dOvVFixYtGteggVu3bqW1dbgBpmuXy6SQy2Mol0khl0ehCSyPzcOtrIoEtXDhQpYvXz6uY3R0dLB48eKJCWgP4TIp5PIYymVSyOVRaKLKQ9IDw62viia+8Xroya08uLG/3GGYmdkuqIkE9elfreTCe7rH3tHMzCpGTSSo/We1sK4r8NxXZmbVoyYS1PxZLfQMwLotrkWZmVWLmkhQ+81Kepk8/FRXmSMxM7Ni1USC2n9mCwAPP7W1zJGYmVmxaiJB7TOjmYzgkaddgzIzqxY1kaDqsxlmNYnVbuIzM6saNZGgAPZqEY+4ic/MrGrUUILK8LCb+MzMqkZNJaiNXb1s2tZb7lDMzKwINZSgBMAjvg9lZlYVaihBJT91te9DmZlVhZpJUHOa0xqU70OZmVWFmklQTXVidlujH9Y1M6sSNZOgIBmTz8MdmZlVh5pKUPvNanETn5lZlaipBLX/zFbWbNrO9l5PXmhmVulqK0HNSgaNfdS1KDOzildTCWq/WblRzZ2gzMwqXU0lqB3TbrgGZWZW8WoqQc1sbWBKY527mpuZVYGaSlCS2M9dzc3MqkJNJShIOkq4q7mZWeWruQS138xWHtvQRf9AlDsUMzMbxS4lKEl7Sdov9yryO1lJt0u6Ml1eIOlmSask/VRSw+4Evrv2n9VCb3/w943bJvO0Zma2i4pKUJJOl/QA8BDwB2A18Jsiz/FeYGXe8ueAr0TEgcAG4Oyio50AB8xpA+C+NZsn87RmZraLiq1BfRI4FvhrRCwATgJuGutLkvYFXgZ8P10WcCJwSbrLRcArdzHmcTli3nSmNNbx+5XrJvO0Zma2i+qK3K83Ip6SlJGUiYjrJH21iO99FfgQMCVdngVsjIi+dPkxYJ/hvihpKbAUoL29nY6OjiJDHV5nZ+eOYxw6I/jNXY/xollPkZHGddxqll8m5vIYjsukkMujUKnLo9gEtVFSG3A9cLGkdcCoDxNJOg1YFxErJC3e1cAi4nzgfIBFixbF4sW7fIgCHR0d5I6xcdrjvO+ndzDjgCM4cr8Z4zpuNcsvE3N5DMdlUsjlUajU5VFsE98rgG3A+4GrgL8BLx/jO8cBp0taDSwjadr7GjBdUi4x7gs8vosxj9vig+eQzYjfrVw72ac2M7MiFZWgImJrRPRHRF9EXBQRX4+Ip8b4zkciYt+ImA+8Hvh9RLwJuA44I93tTOAX44h/t0xvaWDR/jO41vehzMwq1qgJStIWSZtHeu3mOT8MfEDSKpJ7Uhfs5nHG5ZTD2vnLE1s8srmZWYUaNUFFxJSImErSNHceSYeGfUmSTDGdJHLH6YiI09LPD0bEMRFxYES8JiK6dz/83XfSoe0AbuYzM6tQxd6DOj0ivh0RWyJic0R8h+S+VNVaMLuVA+a0upnPzKxCFZugtkp6UzoqREbSmxijF181OPmwdm568Ck2b+8tdyhmZjZIsQnqjcBrgbXp6zXpuqp2yqHt9A0Ef7h/fblDMTOzQYp6DioiVlPlTXrDOXK/GcxsbeDXd6/h5c/du9zhmJlZnlETlKQPRcTnJX0DGDL8d0S8p2SRTYJsRrxm0b587/oHWf3kVubPbi13SGZmlhqriS83yOtyYMUwr6p39nELqMtmOP+GB8sdipmZ5Rm1BhURv0zfL5qccCbfXlObOOPofblk+WO876SF7DW1qdwhmZkZYzfx/ZJhmvZyIuL0CY+oDJa+8Jksu+URLvjjQ3zkJYeWOxwzM2PsJr4vAl8imQdqG/C99NVJMh7fHmH+7FZe+uy5XHzTI2za5i7nZmaVYKyRJP4QEX8AjouI10XEL9PXG4EXTk6Ik+OcxQfQ2d3Hj296uNyhmJkZxT8H1SrpmbkFSQuAParL27P2nsb/OWgOF974EFv84K6ZWdkVm6DeD3RI6pD0B5IRyd9burDK4/2nHMSGrh4+/auVY+9sZmYlNeaDupIywGZgIXBIuvov5RrktZSOmDedpSccwH//4W+86PBnsOTgvcodkplZzRqzBhURA8C3IqI7Iu5MX3tccsp5/ykLOai9jQ9fchcbu3rKHY6ZWc0qtonvWkn/KEkljaYCNNZl+dJrjuDprT18/Ip7yx2OmVnNKjZBvQP4X6AnnaxwyzgmLKx4z953Gu8+8UAuv+PvXHHn38sdjplZTSp2sNgppQ6k0rxryYHc8MCTfPBndzK7tYF/OHB2uUMyM6spRdWglHizpP9Il+dJOqa0oZVXfTbDBWcuYsHsVv75h8u567GN5Q7JzKymFNvE923gBeycA6oT+FZJIqog01sa+OHZxzCjtYG3/s+t/G19Z7lDMjOrGcUmqOdHxLuA7QARsQFoKFlUFaR9ahM/Pvv5ZARv/N5N3PP4pnKHZGZWE4pNUL2SsqQDx0qaAwyULKoKM392Kxe//ViyEmf895/4zd1ryh2Smdker9gE9XXg58Bekj4N3Ah8pmRRVaCDnzGFX7z7eA6bO5VzLr6Nr/3uASJGHOjdzMzGqagEFREXAx8C/gtYA7wyIv63lIFVojlTGvnJ0mN59VH78JXf/ZV/uvAWHt+4rdxhmZntkcaaD6oJeCdwIHA38N2I6JuMwCpV8iDvczl6/xl8+lcredFXruffX1FRALQAABBYSURBVHYor3/ePGrgOWYzs0kzVg3qImARSXJ6Ccn8UDVPEm96/v5c/b4TeM6+0/jIZXfzxu/d7A4UZmYTaKwEdVhEvDkivgucAZwwCTFVjXkzW/jx2c/nU688nL88sZmXf/NGPvDTO9zsZ2Y2AcYaSWLHxEgR0ecmrKEyGfHmY/fn5c/dm+90/I0L//gQV969hn88ah/e/sJncsCctnKHaGZWlcZKUM/NG3NPQHO6LCAiYmpJo6si05rrOe8lh/CWF+zPt65bxSUrHmPZrY9yyqHtnHX8Ap6/YKbvUZmZ7YJRE1REZCcrkD3FPtOb+cyrns37Tz6IH/55NT/888Ncc99anjmnldc/bx7/eNS+zGprLHeYZmYVr6jBYm3XzZnSyLmnHsw5iw/gV3etYdmtj/KZX/+Fz191P8cvnM3Ln7M3pzyrnalN9eUO1cysIjlBlVhLQx2vWTSP1yyax1/XbuHSFY9x5V1rOPd/76Th5xmOO2AWJx/WzkmHtPOMaU3lDtfMrGI4QU2ig9qn8JGXHsp5LzmE2x/dyJV3ruF3K9dy3c/v4d+5h8PmTuWFC2dz/MLZPG/+TJrq3cJqZrXLCaoMJHHUfjM4ar8Z/Mdph7JqXSe/W7mOjvvXceEfH+K71z9IQ12GI+ZN5/kLZnLMgpkcud8M2hr9n8vMaof/4pWZJBa2T2Fh+xTOWXwAXT193PzQ0/zxgSe5ZfXTfLvjb3zj96vIKKmBHTFvOkfMm86z953GQe1TqM8WO5yimVl1KVmCkjQP+CHQTjIK+vkR8TVJM4GfAvOB1cBr0+k7jOSe1ZKD92LJwXsB0Nndx20Pb+C2RzZw+yMb+c09T7Ds1kcBaMhmOGTuFJ6191QOecZUDnnGFA55xlSmtbjjhZlVv1LWoPqAcyPiNklTgBWSfgu8Fbg2Ij4r6TzgPODDJYyjqrU11nHCQXM44aA5AEQEq5/q4u7HN3Hv45u4+/FNXHXPE/zklkd3fGevKY0sbG9j4V5TOGCvNg6Y3coz57TRPrXRz2KZWdUoWYKKiDUkI58TEVskrQT2AV4BLE53uwjowAmqaJJYMLuVBbNbOf25ewNJ0lq3pZuVazZz/xNbeGBdJw+s3cLPlj9KV0//ju+2NGTZf1YrC2a3MH9WK9vW99Kw6knmzWxh7rQm6txcaGYVRJMxp5Gk+cD1wOHAIxExPV0vYENuedB3lgJLAdrb249etmzZuGLo7Oykra22hh2KCDZ0B09sDdZsHeCJrQOs7QrWbR1g/bagP+8/fUYwo1HMbhazmzPMbBazmsTMJjGrKcOMJtFcxx5dA6vFa2QsLpNCLo9CE1UeS5YsWRERiwavL3mCktQG/AH4dERcJmljfkKStCEiZox2jEWLFsXy5cvHFUdHRweLFy8e1zH2JH39A1x+TQd7H/QcHnmqi8c2bOOxDV08vnEbj23YxtrN2xkYdGm0NGR5xrQm2qc08YxpTew1tZG9pjQxZ0oje01pZM6URma3NTK1qa4qE5mvkaFcJoVcHoUmqjwkDZugStqLT1I9cClwcURclq5eK2luRKyRNBdYV8oYbHh12QyzmzP8wwGz+YcDhm7v6x9g7ZZu/r5xG2s2bWftpu2s2bSdJzZvY+3mbm5d/TTrNnfT0z8w5LsNdRnmtDUyu62BWW2NzGptYGZbQ/Lemi6nr+kt9bQ1VmdCM7PSKmUvPgEXACsj4st5m64AzgQ+m77/olQx2O6ry2bYZ3oz+0xvHnGfiGDTtl7Wbelm3eZu1ndu58ktPazv7ObJLd08ubWHtZu3c+/fN/H01h56+4evrddnxfSWBma01O98b06S19TmeqY11zO9JXmf2pS8T2uuZ0pTne+bme3BSlmDOg54C3C3pDvSdR8lSUw/k3Q28DDw2hLGYCUkJYlleksDB7VPGXXfiGBLdx9Pd/bw1NYeNnb18PTW5LWhq5eNXT1s6Eo+r36yi43bNrKhq5eevqE1tHwtDVmmNiXJakpTHVOb65mSW25M1rU11tHWlNTUpjTV0dqYrmuso7UxS2tDHZmMa3BmlaaUvfhuJJmWYzgnleq8VpkkMbUpqQHNn91a9Pe29/azaVvvzldXL5u3J5+3bO9j87adn7d09/L01h4efqorWd7eS/cYCS6ntSFLvQaYsbyDloYkabU2ZmlprKO1IUtLbrmhjpaGLC0NWZob6mipz31OtjXX5z5naarPknXiM9ttHknCKlpTffKHvn3q7g2k29M3wNbuPjq7+3Ykra09yefO7r50Wz9bu/tYtfpRps6aRle6/1Nbe3jk6S62dvfT1dPH1p5++gf3HBlDQ10mSWD1yaspTWDJ5wyN9Ts/N9Ul25rqszTWZXb89ty2xvp0Xe5z+t5Yl6GxLvmOa4K2J3GCsj1aQ12GhroGZrQ2jLlvR8c6Fi8+csTtEUFP/wBd3f109fazraePrp5+unr62Za+d/X0sb23f8f67X07t23v7Wd77wDbe/vZ1tvPhq4etvX2s72nn+19O9ePp2NtfVY7klVjXZIAG+syNKTLDWkya8gWrsu9GrN5y9kMqx/tZf3yR3fsW5/dua0+fR+ynM1QXyfqsxnqMnIHGNttTlBmRZJyf/yzjPpcxDjkkuD23gG6cwmtrzC59fQN0J0mtO6+Abr7km3dfely+jl/v57+AXr6kuNu3taXbkv270lf3ek+Q9x7127/HokkqWUz1GeTpJVLcnWZdLkuQ0NW1GWGfq5P96nL7kx4ufV16fqGdH1deo66zKD90/3qMsn2bMG6nfvv+F4mQzbdVp/NkNGe/fxfJXOCMqsg+UmQ5skfUzEi6O2PHQntDzfcyKJjjt2RyHr7B3Zs2/HeN0DfQG5d7NivN92ntz+S5f7cMWLH576BZDn3uWtbP33pvn1pHLnPvf0D9A3kjlX6AQby5RIbAwM0XX/NjsSWzagg0eWWs5nC5Jdbzubtl80Urk+SoYbsn5V2JMxsJkm6mdx2qeBY2UHfyUoF+2dG+s6gdRkNPU4mw479JithO0GZ2Q6SaKgTDXUZaIQZTRnmzWwpd1hDRAT9A0ky7R1IElhf/wC9A+l7f9A3MDSx9Q9Ewbq+dP++/vRzmjD70/e+9HNu39UPP8LcvffecZ7+AZJ9B4L+9Bg79u9PYtze18/AQG5bcu6BgL6Bgbzv7Fzfn1seGBhXc28pZUSSsCNYtmADR+9fmjYFJygzqzpKaxp1WWhm8ib27OhYy+LFh0/a+QYGgv40GffnJbm+gQEGBtIkl64biNiRGAfyvlPw3YjkmLnXoP1yx9ixTyQJuH+AgmPm9lv98CO0T20s2e93gjIzq1CZjMggKnVy7Y6OJ9h3Rulq2H4M38zMKpITlJmZVaRJmW5jvCStJxkWaTxmA09OQDh7EpdJIZfHUC6TQi6PQhNVHvtHxJzBK6siQU0EScuHG869lrlMCrk8hnKZFHJ5FCp1ebiJz8zMKpITlJmZVaRaSlDnlzuACuQyKeTyGMplUsjlUaik5VEz96DMzKy61FINyszMqogTlJmZVaSaSFCSXizpfkmrJJ1X7ngmm6R5kq6TdJ+keyW9N10/U9JvJT2QvpdqFomKJCkr6XZJV6bLCyTdnF4nP5U09iRSexBJ0yVdIukvklZKekEtXyOS3p/+e7lH0k8kNdXaNSLpQknrJN2Tt27Ya0KJr6dlc5eko8Z7/j0+QUnKAt8CXgIcBrxB0mHljWrS9QHnRsRhwLHAu9IyOA+4NiIWAtemy7XkvcDKvOXPAV+JiAOBDcDZZYmqfL4GXBURhwDPJSmbmrxGJO0DvAdYFBGHA1ng9dTeNfID4MWD1o10TbwEWJi+lgLfGe/J9/gEBRwDrIqIByOiB1gGvKLMMU2qiFgTEbeln7eQ/OHZh6QcLkp3uwh4ZXkinHyS9gVeBnw/XRZwInBJukutlcc04ATgAoCI6ImIjdTwNUIymHazpDqgBVhDjV0jEXE98PSg1SNdE68AfhiJm4DpkuaO5/y1kKD2AR7NW34sXVeTJM0HjgRuBtojYk266QmgvUxhlcNXgQ8BuSlkZwEbI6IvXa6162QBsB74n7TZ8/uSWqnRayQiHge+CDxCkpg2ASuo7WskZ6RrYsL/1tZCgrKUpDbgUuB9EbE5f1skzxvUxDMHkk4D1kXEinLHUkHqgKOA70TEkcBWBjXn1dg1MoOkRrAA2BtoZWhTV80r9TVRCwnqcWBe3vK+6bqaIqmeJDldHBGXpavX5qrg6fu6csU3yY4DTpe0mqTJ90SS+y/T0+YcqL3r5DHgsYi4OV2+hCRh1eo1cjLwUESsj4he4DKS66aWr5Gcka6JCf9bWwsJ6lZgYdr7poHkRucVZY5pUqX3Vy4AVkbEl/M2XQGcmX4+E/jFZMdWDhHxkYjYNyLmk1wPv4+INwHXAWeku9VMeQBExBPAo5IOTledBNxHjV4jJE17x0pqSf/95MqjZq+RPCNdE1cA/5T25jsW2JTXFLhbamIkCUkvJbnnkAUujIhPlzmkSSXpeOAG4G523nP5KMl9qJ8B+5FMZ/LaiBh8Q3SPJmkx8MGIOE3SM0lqVDOB24E3R0R3OeObTJKOIOk00gA8CLyN5H9ia/IakfQJ4HUkvWBvB95Ock+lZq4RST8BFpNMq7EW+BhwOcNcE2ki/yZJU2gX8LaIWD6u89dCgjIzs+pTC018ZmZWhZygzMysIjlBmZlZRXKCMjOziuQEZWZmFckJyqxIkjrT9/mS3jgJ5zu9FkffN8txN3OzIknqjIi2/GenduG7dXljuJlZEVyDMtt1nwVeKOmOdM6grKQvSLo1nQfnHZA8BCzpBklXkIxCgKTLJa1I5xlamjugkjnLbpN0p6Rr03VvlfTN9PN8Sb9Pj3+tpP3S9T9I5+D5k6QHJZ2Rd8x/y4vpE+m6Vkm/Ss9zj6TXTVahme2qurF3MbNBziOvBpUmmk0R8TxJjcAfJV2T7nsUcHhEPJQun5U+dd8M3CrpUpL/UfwecEJEPCRp5jDn/AZwUURcJOks4OvsnOZgLnA8cAjJcDOXSDqVZF6eYwABV0g6AZgD/D0iXpbGPm3CSsVsgjlBmY3fqcBz8mov00iSQw9wS15yAniPpFeln+el+80Brs/tN8JQQi8AXp1+/hHw+bxtl0fEAHCfpNzUB6emr9vT5bb0XDcAX5L0OeDKiLhhd36w2WRwgjIbPwH/GhFXF6xM7lVtHbR8MvCCiOiS1AE0TcD588eCU977f0XEd4cEm0zF/VLgU5KujYj/nIAYzCac70GZ7botwJS85auBc9IpTZB0UDrZ32DTgA1pcjoEODZdfxNwgqQF6feHa+L7E8nI6wBvIqkJjeZq4Kx0DjAk7SNpL0l7A10R8WPgCyRNkGYVyTUos113F9Av6U7gByRzSc0HbktHdF7P8FOBXwW8U9JK4H6SxERErE/vY10mKUMyv84pg777rySz3f5bevy3jRZgRFwj6VDgz0lIdAJvBg4EviBpAOgFztm1n242edzN3MzMKpKb+MzMrCI5QZmZWUVygjIzs4rkBGVmZhXJCcrMzCqSE5SZmVUkJygzM6tI/z9sXX8tV8EDqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_hat= [-4.72682076  8.69637274 -3.26959518  0.39380814  1.08713375  3.96597329\n",
      "  0.92662326  2.15827014  1.24870917  2.16223996  2.11991062  2.39540951]\n",
      "Error de clasificacion= 13.64 %\n",
      "\n",
      "\n",
      "CPU times: user 21min 52s, sys: 1min 36s, total: 23min 29s\n",
      "Wall time: 22min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Método de SGD\n",
    "for batch_size in range(9,10):\n",
    "    \n",
    "    \n",
    "    print(\"*========================================================================*\")\n",
    "    #print(\"Tamaño de minilote= \",batch_size)\n",
    "    beta_hat, loss, error = SGD_paralelo(x_train, y_train, max_iter=10**4)\n",
    "    yhat = clasifica(x_test,beta_hat)\n",
    "    titulo=\"Batch size = \"+ str(batch_size)\n",
    "    graf_loss_err(loss,error,titulo)\n",
    "    print(\"beta_hat=\", beta_hat)\n",
    "    print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
