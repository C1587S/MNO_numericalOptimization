{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de los métodos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este notebook se plantea la solución del problema utilizando los siguiente métodos: Newton, Broyden-Fletcher-Goldfarb-Shanno  (BFGS) y el gradiente descendente estocástico (SGD). El presente notebook es autocontenido, sin embargo, la implementación principal se realiza con un enfoque modular.\n",
    "\n",
    "A continuación, se describe el conjunto de datos que se emplearán y se define el planteamiento del problema. Una explicación más detallada se realiza en el informe (en formato PDF) de este proyecto.\n",
    "\n",
    "**Nota:** Esta implementación se basa en material y actividades impartidas por los profesores de los cursos de [Métodos Numéricos y optimización](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/IV.optimizacion_convexa_y_machine_learning/4.3.Regresion_logistica_R.ipynb) (2010-I) (Prof. Erick Palacios Moreno) y Aprendizaje de Máquina (2019-II) (Prof. Rodrigo Mendoza Smith).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por la restricciones de uso de la base de datos de entrenamiento original (además de una serie de requerimientos protocolares como contar con la aprobación de un Comité de Ética Independiente), optamos por trabajar con una de las dos bases de datos que los autores emplearon para validar sus modelos: KGH. La base de datos en mención, consta de $106$ casos positivos  de  pacientes  con  ébola  y  un  case fatality rate global por encima del setenta por ciento.  Originalmente,  previo  al tratamiento de los datos, la base tenía únicamente $44$ registros de triaje, $58$ registros de carga viral, con un total de 78 valores faltantes en todo el data set. Para  harmonizar  los  datos,  los  autores  transformaron  la  carga  viral  en  CT,  conforme  con  la curva estándar qPCR:\n",
    "\n",
    "$$log_{(carga \\; viral)} = m*CT + c_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosotros, para fines del presente trabajo, empleamos una de las versiones imputadas de esta base de datos, dispuesta en el siguiente sitio: [ebola-imc-public](https://github.com/dapivei/ebola-imc-public/blob/master/data/kenema/test/pres-kgh/imputation-50.csv), misma que cuenta con $11$ variables: la variable output, $y_{i}$ asociada a la supervivencia o no del paciente ${i}$ con virus del ébola, y ${j}$ variables explicativas asociadas, $x_{i,j}$. Los regresores escogidos son aquellos que, conforme con nuestra principal referencia, son buenos predictores de la probabilidad de muerte o no de un paciente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Tipo| Nombre|Descripción|\n",
    "|---| --- | --- |\n",
    "|Variable Numérica| CT |El cycle threshold (CT) es una variable que se calcula a partir de una relación médica bien conocida (qPCR) y la carga viral (una expresión númerica de la cantidad de virus dado un volúmen de fluido que normalmente se correlaciona con la severidad de una infección viral activa).|\n",
    "|Variable Numérica|TEMP|Temperatura corporal del paciente. Toma valores de 1 a 73.|\n",
    "|Variable Numérica|_AGE_ |Edad del paciente. Toma valores de $1$ a $73$.|\n",
    "|Variable Categórica |_HEADCH_ | Presencia o no dolores de cabeza. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no dolores de cabeza.|\n",
    "|Variable Categórica |  _BLEED_ | Presencia o no de sangrado. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no sangrado. |\n",
    "|Variable Categórica |  _DIARR_ | Presencia o no de diarrea. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no diarrea.|\n",
    "|Variable Categórica | _VOMIT_ | Dificultad para comer, conocido como disfagia, término técnico para describir el síntoma consistente en dificultad para la deglución (problemaspara  tragar).   Esta  dificultad  suele  ir  acompañada  de  dolores,  a  veces lancinantes (disfagia dolorosa u odinofagia .  Toma valores valores $1$ o $0$, dependiendo de si el paciente presenta o no de disfacia\n",
    "|Variable Categórica | _PABD_ | Presencia o no de PADB.\n",
    "|Variable Categórica |_WEAK_ | Presencia o no de debilidad o fatiga general.|\n",
    "|Variable Categórica |_JAUN_ |Condición  en la cuál la piel, los ojos y los miembros mucosos que vuelven amarillos debido a altos niveles de bilirubina. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no ictericia.|\n",
    "|Variable Categórica |_OUT_| Muerte o no muerte del paciente.  Toma valores $1$ o $0$.  Dependiendo desi el paciente muere o no muere.|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problema de regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matemáticamente, este conjunto se define de la siguiente manera: \n",
    "\n",
    "$$\\mathcal{D}=\\left\\{ \\left(x_{i},y_{i}\\right)\\in\\mathbb{R}^{p}\\times\\left\\{ 0,1\\right\\} :i\\in\\left[m\\right]\\right\\} $$.\n",
    "\n",
    "El método de _regresión logística_ asume que $Pr\\left[y_{i}\\mid x_{i},\\beta\\right]\\sim Bernoulli\\left(\\mu_{i}\\right)$\n",
    "con los siguientes supuestos sobre la media, $\\mu_{i}$:\n",
    "\n",
    "$$\n",
    "\\mu_{i}=\\sigma\\left(\\beta^{T}x_{i}\\right) \\label{eq-3.1} \\tag{1}\n",
    "$$\n",
    "$$\n",
    "\\sigma(z)=\\left(1+\\exp\\left(-z\\right)\\right)^{-1} \\label{eq-3.2} \\tag{2}\n",
    "$$\n",
    "\n",
    "donde $\\beta\\in\\mathbb{R}^{p}$. \n",
    "\n",
    "\n",
    "Dado lo anterior, nuestro problema es encontrar un modelo tal que $\\hat{\\beta}\\in\\mathbb{R}^{p}$ explica de la mejor manera posible a $\\mathcal{D}$. \n",
    "\n",
    "Para lograr lo anterior, debemos estimar el conjunto de parámetros $\\hat{\\beta}$ para modelar $Pr\\left[y\\mid x,\\hat{\\beta}\\right]$ y predecir la etiqueta $\\hat{y}\\in\\left\\{ 0,1\\right\\} $ de un nuevo\n",
    "dato $x$ por medio de:\n",
    "\n",
    "$$\n",
    "\\hat{y}=\\begin{cases}\n",
    "1 & si\\,\\sigma\\left(\\hat{\\beta}^{T}x\\right)\\geq0.5\\\\\n",
    "0 & si\\,\\sigma\\left(\\hat{\\beta}^{T}x\\right)<0.5\n",
    "\\end{cases}\\label{eq-3.3} \\tag{3}\n",
    "$$\n",
    "\n",
    "la función de pérdida que queremos minimizar en este problema corresponde a la _log-verosimilitud negativa_ , que está dada por:\n",
    "\n",
    "$$\n",
    "F(\\beta):=LVN(\\beta)=-\\sum_{i=1}^{m}\\left[y_{i}log\\mu_{i}+(1-y_{i})log(1-\\mu_{i})\\right]\\label{eq-3.4} \\tag{4}\n",
    "$$\n",
    "\n",
    "\n",
    "Una vez planteado lo anterior, queremos encontrar $\\hat{\\beta}$ por medio de métodos numéricos de optimización de tal forma que se minimize ([4](#mjx-eqn-eq1)) para el conjunto de datos dado.\n",
    "\n",
    "\n",
    "_En los siguientes fragmentos de código se realiza el planteamiento del problema, desde la importación de datos hasta el proceso de entrenamiento del modelo utilizando distintos algoritmos de optimización que se explican con brevedad._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación y exploración del conjunto de datos\n",
    "\n",
    "En esta sección se importa y transforma los datos, con el fin de obtener el conjunto $\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/afcarl/ebola-imc-public/master/data/kenema/test/pres-kgh/imputation-50.csv\"\n",
    "df_raw=pd.read_csv(url,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>JAUN</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28.652450</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25.736016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20.747653</td>\n",
       "      <td>65.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>22.736993</td>\n",
       "      <td>44.0</td>\n",
       "      <td>38.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OUT         CT   AGE  TEMP  HEADCH  BLEED  DIARR  JAUN  VOMIT  PABD  WEAK\n",
       "0    1  28.652450  42.0  36.3       0      0      1     0      0     1     1\n",
       "1    1  25.736016  45.0  36.5       1      0      1     0      0     1     1\n",
       "2    1  20.747653  65.0  38.0       1      0      0     0      0     0     0\n",
       "3    1  22.736993  44.0  38.6       1      0      0     0      0     0     1\n",
       "4    1  20.846284  11.0  38.4       1      0      0     0      1     0     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()\n",
    "# df[df.isnull().any(axis=1)] - no hay NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT         int64\n",
       "CT        float64\n",
       "AGE       float64\n",
       "TEMP      float64\n",
       "HEADCH      int64\n",
       "BLEED       int64\n",
       "DIARR       int64\n",
       "JAUN        int64\n",
       "VOMIT       int64\n",
       "PABD        int64\n",
       "WEAK        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificar tipo de variables \n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>JAUN</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764151</td>\n",
       "      <td>25.720411</td>\n",
       "      <td>34.102170</td>\n",
       "      <td>37.256604</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.405660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.426545</td>\n",
       "      <td>5.869164</td>\n",
       "      <td>17.382844</td>\n",
       "      <td>1.030767</td>\n",
       "      <td>0.491436</td>\n",
       "      <td>0.249528</td>\n",
       "      <td>0.493352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407477</td>\n",
       "      <td>0.447916</td>\n",
       "      <td>0.502375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.149857</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.236301</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.680924</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>38.225000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.799999</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>39.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OUT          CT         AGE        TEMP      HEADCH       BLEED  \\\n",
       "count  106.000000  106.000000  106.000000  106.000000  106.000000  106.000000   \n",
       "mean     0.764151   25.720411   34.102170   37.256604    0.603774    0.066038   \n",
       "std      0.426545    5.869164   17.382844    1.030767    0.491436    0.249528   \n",
       "min      0.000000   12.100000    0.830000   36.000000    0.000000    0.000000   \n",
       "25%      1.000000   22.149857   22.000000   36.300000    0.000000    0.000000   \n",
       "50%      1.000000   25.236301   35.500000   37.250000    1.000000    0.000000   \n",
       "75%      1.000000   28.680924   45.000000   38.225000    1.000000    0.000000   \n",
       "max      1.000000   39.799999   80.000000   39.900000    1.000000    1.000000   \n",
       "\n",
       "            DIARR   JAUN       VOMIT        PABD        WEAK  \n",
       "count  106.000000  106.0  106.000000  106.000000  106.000000  \n",
       "mean     0.405660    0.0    0.207547    0.273585    0.500000  \n",
       "std      0.493352    0.0    0.407477    0.447916    0.502375  \n",
       "min      0.000000    0.0    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.0    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.0    0.000000    0.000000    0.500000  \n",
       "75%      1.000000    0.0    0.000000    1.000000    1.000000  \n",
       "max      1.000000    0.0    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resumen de las variables\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT       category\n",
       "CT         float64\n",
       "AGE        float64\n",
       "TEMP       float64\n",
       "HEADCH    category\n",
       "BLEED     category\n",
       "DIARR     category\n",
       "JAUN      category\n",
       "VOMIT     category\n",
       "PABD      category\n",
       "WEAK      category\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_cat = df_raw.copy()\n",
    "\n",
    "cat_vars = ['OUT', 'HEADCH', 'BLEED', 'DIARR', 'JAUN', 'VOMIT',\n",
    "       'PABD', 'WEAK']\n",
    "for var in cat_vars:\n",
    "    df_raw_cat[var] = df_raw_cat[var].astype('category')\n",
    "df_raw_cat.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.720411</td>\n",
       "      <td>34.102170</td>\n",
       "      <td>37.256604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.869164</td>\n",
       "      <td>17.382844</td>\n",
       "      <td>1.030767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.149857</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.236301</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>37.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.680924</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>38.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.799999</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>39.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CT         AGE        TEMP\n",
       "count  106.000000  106.000000  106.000000\n",
       "mean    25.720411   34.102170   37.256604\n",
       "std      5.869164   17.382844    1.030767\n",
       "min     12.100000    0.830000   36.000000\n",
       "25%     22.149857   22.000000   36.300000\n",
       "50%     25.236301   35.500000   37.250000\n",
       "75%     28.680924   45.000000   38.225000\n",
       "max     39.799999   80.000000   39.900000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>JAUN</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>99</td>\n",
       "      <td>63</td>\n",
       "      <td>106</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        OUT  HEADCH  BLEED  DIARR  JAUN  VOMIT  PABD  WEAK\n",
       "count   106     106    106    106   106    106   106   106\n",
       "unique    2       2      2      2     1      2     2     2\n",
       "top       1       1      0      0     0      0     0     1\n",
       "freq     81      64     99     63   106     84    77    53"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe categorical data\n",
    "df_proc_cat = df_raw_cat.select_dtypes(include=['category']).copy()\n",
    "df_proc_cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_vars = cat_vars[1:]\n",
    "\n",
    "for i, col_val in enumerate(cat_vars):\n",
    "    sns.catplot(x = col_val, y = None, hue= None, col=\"OUT\",\n",
    "                data=df_proc_cat, kind=\"count\",\n",
    "                height=4, aspect=1.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algunas observaciones sobre los datos**\n",
    "\n",
    "- El case fatality rate (OUT) de nuestra base de datos se sitúa en 76 por ciento. Es decir, del total de pacientes con ébola, 81 murieron.\n",
    "\n",
    "- Para este conjunto de datos la variable `JAUN` no tiene variabilidad, por lo tanto no es una variable, y se omite.\n",
    "\n",
    "\n",
    "Dado lo anterior, se ajusta el set de datos:\n",
    "\n",
    "- Se crean 3 grupos de edades, utilizando el percetil 25 (22 años), percentil 50 (36 años) y percentil 75 (45 años).\n",
    "\n",
    "- Se elimina la columna `JAUN`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones al conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT            int64\n",
       "CT           float64\n",
       "AGE          float64\n",
       "TEMP         float64\n",
       "HEADCH         int64\n",
       "BLEED          int64\n",
       "DIARR          int64\n",
       "JAUN           int64\n",
       "VOMIT          int64\n",
       "PABD           int64\n",
       "WEAK           int64\n",
       "INTER_AGE     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ajustes en df_raw \n",
    "df_proc = df_raw\n",
    "df_proc['INTER_AGE'] = \"NA\"\n",
    "\n",
    "df_proc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT             int64\n",
       "CT            float64\n",
       "TEMP          float64\n",
       "HEADCH          int64\n",
       "BLEED           int64\n",
       "DIARR           int64\n",
       "VOMIT           int64\n",
       "PABD            int64\n",
       "WEAK            int64\n",
       "hasta22       float64\n",
       "entre23y36    float64\n",
       "entre37y45    float64\n",
       "mayor45       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ajustes en df_raw \n",
    "df_proc = df_raw\n",
    "\n",
    "# para la variable edad se crean cuatro categorías\n",
    "age_p25 = math.ceil(df_proc['AGE'].quantile(.25))\n",
    "age_p50 = math.ceil(df_proc['AGE'].quantile(.50))\n",
    "age_p75 = math.ceil(df_proc['AGE'].quantile(.75))\n",
    "\n",
    "df_proc['INTER_AGE'] = \"NA\"\n",
    "df_proc.loc[(df_proc['AGE'] <= age_p25), 'INTER_AGE'] = 1\n",
    "df_proc.loc[(df_proc['AGE'] > age_p25) & (df_proc['AGE'] <= age_p50), 'INTER_AGE'] = 2\n",
    "df_proc.loc[(df_proc['AGE'] > age_p50) & (df_proc['AGE'] <= age_p75), 'INTER_AGE'] = 3\n",
    "df_proc.loc[(df_proc['AGE'] > age_p75), 'INTER_AGE'] = 4\n",
    "\n",
    "## one hot encoding\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(df_proc[['INTER_AGE']]).toarray())\n",
    "enc_df = enc_df.rename(columns={0: f\"hasta{age_p25}\", 1: f\"entre{age_p25+1}y{age_p50}\", 2: f\"entre{age_p50+1}y{age_p75}\", 3:f\"mayor{age_p75}\"})\n",
    "# merge with main df bridge_df on key values\n",
    "df_proc = df_proc.join(enc_df)\n",
    "\n",
    "# se asignan como categoricas a las binarias, incluido el output\n",
    "#bin_vars = ['OUT', 'HEADCH', 'BLEED', 'DIARR', 'JAUN', 'VOMIT',\n",
    "#       'PABD', 'WEAK', 'INTER_AGE', f\"hasta{age_p25}\", f\"entre{age_p25+1}y{age_p50}\", f\"entre{age_p50+1}y{age_p75}\", f\"mayor{age_p75}\"]\n",
    "\n",
    "#esta asignacion hace que genera problemas al evaluar el sigmoide\n",
    "#for var in bin_vars:\n",
    "#    df_proc[var] = df_proc[var].astype('category')\n",
    "    \n",
    "# se omiten las variables JAUN, AGE, INTER_AGE\n",
    "del_vars = [\"JAUN\", \"AGE\", \"INTER_AGE\"]\n",
    "for var in del_vars:\n",
    "    df_proc = df_proc.drop(var, axis=1)    \n",
    "    \n",
    "# se comprueban los tipos de variable\n",
    "df_proc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "      <th>hasta22</th>\n",
       "      <th>entre23y36</th>\n",
       "      <th>entre37y45</th>\n",
       "      <th>mayor45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28.652450</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25.736016</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20.747653</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>22.736993</td>\n",
       "      <td>38.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>38.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>24.191797</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>38.816561</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>21.960294</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>26.221948</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OUT         CT  TEMP  HEADCH  BLEED  DIARR  VOMIT  PABD  WEAK  hasta22  \\\n",
       "0      1  28.652450  36.3       0      0      1      0     1     1      0.0   \n",
       "1      1  25.736016  36.5       1      0      1      0     1     1      0.0   \n",
       "2      1  20.747653  38.0       1      0      0      0     0     0      0.0   \n",
       "3      1  22.736993  38.6       1      0      0      0     0     1      0.0   \n",
       "4      1  20.846284  38.4       1      0      0      1     0     1      1.0   \n",
       "..   ...        ...   ...     ...    ...    ...    ...   ...   ...      ...   \n",
       "101    1  24.191797  36.4       0      0      1      1     1     1      0.0   \n",
       "102    1  20.846284  38.4       0      0      0      1     0     1      0.0   \n",
       "103    0  38.816561  36.0       0      0      0      0     0     0      1.0   \n",
       "104    1  21.960294  36.4       0      0      0      0     0     0      0.0   \n",
       "105    0  26.221948  36.5       1      0      0      0     0     0      0.0   \n",
       "\n",
       "     entre23y36  entre37y45  mayor45  \n",
       "0           0.0         1.0      0.0  \n",
       "1           0.0         1.0      0.0  \n",
       "2           0.0         0.0      1.0  \n",
       "3           0.0         1.0      0.0  \n",
       "4           0.0         0.0      0.0  \n",
       "..          ...         ...      ...  \n",
       "101         0.0         1.0      0.0  \n",
       "102         1.0         0.0      0.0  \n",
       "103         0.0         0.0      0.0  \n",
       "104         1.0         0.0      0.0  \n",
       "105         0.0         1.0      0.0  \n",
       "\n",
       "[106 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planteamiento del problema de regresión\n",
    "\n",
    "A continuación se plantea el código que computa las ecuaciones ([1](#mjx-eqn-eq1)), ([2](#mjx-eqn-eq1)) y ([4](#mjx-eqn-eq1)), planteadas inicialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(z):\n",
    "    '''\n",
    "    Función que devuelve el sigmoide de un vector\n",
    "        ** Parámetros:\n",
    "            - z (vec): vector numérico de m entradas\n",
    "        ** Salidas\n",
    "            - sig (vec):  vector númerico de m entradas, cada entrada tiene un valor entre -1 y 1\n",
    "    '''\n",
    "    sig = 1/(1+ np.exp(-z))\n",
    "    \n",
    "    return sig\n",
    "    \n",
    "def calc_mu(X,beta):\n",
    "    '''\n",
    "    Función que calcula la media para una variable aleatoria con distribución bernoulli.\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - beta (vec): vector de p entradas\n",
    "        ** Salidas\n",
    "            - mu (vec): vector de m entradas\n",
    "    '''\n",
    "    a = np.matmul(beta,np.transpose(X))\n",
    "    mu = sigmoide(a)\n",
    "\n",
    "    return mu\n",
    "    \n",
    "def f(X,y,beta):\n",
    "    '''\n",
    "    Función que computa la log-verosimilitud negativa\n",
    "    ** Parámetros:\n",
    "        - X (mat): matriz de mxp entradas\n",
    "        - y (vec): vector de de m entradas de la variable output\n",
    "        - beta (vec): vector de p entradas\n",
    "    ** Salidas\n",
    "        - lvn (int): log-verosimilitud negativa\n",
    "    '''\n",
    "    prob = calc_mu(X,beta)\n",
    "    # Log-verosimilitud negativa \n",
    "    lvn = -sum(y*np.log(prob)+(1-y)*(np.log(1-prob)))\n",
    "    return lvn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reescribiendo la ecuación de la función de pérdida ([4](#mjx-eqn-eq1)), tenemos:\n",
    "\n",
    "$$F(\\beta)=- \\sum_{i=1}^{m}[y_i log\\mu_i + (1-y_i)log(1-\\mu_i)]$$\n",
    "\n",
    "Las expresiones correspondientes al gradiente y a la matriz hessiana asociados a este problema, se plantean a continuación:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla F(\\beta) & =\\frac{d}{d\\beta}F(\\beta)\\nonumber \\\\\n",
    " & =\\sum_{i}\\left(\\mu_{i}-y_{i}\\right)x_{i}\\nonumber \\\\\n",
    " & =\\boldsymbol{X}^{T}\\left(\\boldsymbol{\\mu}-\\boldsymbol{y}\\right)\\label{eq:gradient}\n",
    "\\end{align}\n",
    "\n",
    "Por otro lado, la ecuación que describe la matrix Hessiana es la siguiente:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla^{2}F(\\beta) & =\\frac{d}{d\\beta}\\nabla F\\left(\\beta\\right)^{T}\\nonumber \\\\\n",
    " & =\\sum_{i}\\left(\\nabla_{\\beta}\\mu_{i}\\right)x_{i}^{T}\\nonumber \\\\\n",
    " & =\\sum_{i}\\mu_{i}\\left(1-\\mu_{i}\\right)x_{i}x_{i}^{T}\\nonumber \\\\\n",
    " & =\\boldsymbol{X^{T}SX}\\label{eq:hessian}\n",
    "\\end{align}\n",
    "\n",
    "donde $\\boldsymbol{S}\\triangleq diag\\left(\\mu_{i}\\left(1-\\mu_{i}\\right)\\right)$.\n",
    "Como es resaltado por Murphy (2012), es definida positiva, lo que implica que ([4](#mjx-eqn-eq1)) es convexa\n",
    "y tiene un mínimo global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_f(X,y,beta):\n",
    "    '''\n",
    "    Función que calcula el gradiente asociado la log-verosimilitud negativa del problema de regresión logística\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - beta (vec): vector de p entradas\n",
    "        ** Salidas\n",
    "            - grad (vec): vector de m entradas\n",
    "    '''\n",
    "    mu = calc_mu(X,beta)    \n",
    "    grad = np.matmul(np.transpose(X), mu-y)    \n",
    "    return grad\n",
    "\n",
    "\n",
    "def hessiana_f(X,y,beta):\n",
    "    '''\n",
    "    Función que calcula la matriz Hessiana asociada a la log-verosimilitud negativa del problema de regresión logística\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - beta (vec): vector de p entradas\n",
    "        ** Salidas\n",
    "            - hes (vec): vector de m entradas\n",
    "    '''\n",
    "    mu = calc_mu(X,beta)\n",
    "    S = np.diag(mu*(1-mu))\n",
    "    hes = np.matmul(np.transpose(X),np.matmul(S,X))\n",
    "    return hes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    '''\n",
    "    Función que normaliza un vector\n",
    "        **Parametros:\n",
    "            - x: vector a normalizar\n",
    "            \n",
    "        **Salidas:\n",
    "            - norm : Vector x normalizado\n",
    "    '''\n",
    "    \n",
    "    norm = x/np.sqrt(sum(x*x))\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasifica(X, beta_hat,limit=0.5):\n",
    "    '''\n",
    "    Función que clasifica la ocurrencia de probabilidades en dos grupos.\n",
    "    Emplea el parámetro límite para delimitar si se clasifica en el grupo 0 o 1.\n",
    "        **Parámetros:\n",
    "            - X (mat): matrix of data\n",
    "            - beta_hat (array): optimized parameter\n",
    "            - limit (float64) 0<limit<1: Threshold for each classification\n",
    "        \n",
    "        **Saludas:\n",
    "            - yhat: array of classifed data\n",
    "    '''\n",
    "    mu = calc_mu(X,beta_hat)\n",
    "    yhat = mu\n",
    "    yhat[mu<limit] = 0\n",
    "    yhat[mu>=limit] = 1\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent_direction(X, y, beta, method=\"max\",H=None):\n",
    "    '''\n",
    "    Función que devuelve vector normalizado (px1) que apunta en la direccion de decenso\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - beta (vec float64): vector de entradas a optimizar\n",
    "            - method (str): método que determina la dirección de descenso\n",
    "                opciones:\n",
    "                    - max: método de descenso\n",
    "                    - newton: método de Newton\n",
    "                    - bfsg: metodo bfsg\n",
    "            - H (mat pxp): Parametro para direccion de decenso del metodo bfgs\n",
    "            \n",
    "        ** Salidas\n",
    "            - pk (vec): vector normalizado con la direccion del paso\n",
    "    '''\n",
    "    if(method == \"max\"):\n",
    "        pk = gradiente_f(X,y,beta)\n",
    "    \n",
    "    elif(method == \"newton\"):\n",
    "        grad = gradiente_f(X,y,beta)\n",
    "        hess = hessiana_f(X,y,beta)\n",
    "        pk = np.linalg.solve(hess,grad)\n",
    "        \n",
    "    elif(method==\"bfsg\"):\n",
    "        pk = np.matmul(H,gradiente_f(X,y,beta))\n",
    "                              \n",
    "    return - normalize(pk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_H(X,y,beta,beta_new=None,H=None):\n",
    "    '''\n",
    "    Función que actualiza los valores de la matriz H del metodo bfgs para cada iteracion\n",
    "        ** Parametros:\n",
    "            - beta (array) - valor de cantidad a optimizar en la iteracion actual\n",
    "            - beta_new (array)- valore de la cantidad a optimizar despues de la actualizacion\n",
    "            - H (mat)- valor de la matriz H en la iteracion anterior\n",
    "        \n",
    "        ** Salidas:\n",
    "            - H (mat): valor de la matriz para la siguiente iteracion\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    w = gradiente_f(X,y,beta_new)- gradiente_f(X,y,beta)\n",
    "    z = beta_new-beta\n",
    "    Hz = np.matmul(H,z)\n",
    "    dotwz = np.dot(w,z)\n",
    "    dotzhz = np.dot(Hz,z)\n",
    "    H = H+(np.outer(w,w)/dotwz)-(np.outer(Hz,Hz)/dotzhz)\n",
    "   \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lr(X, y, beta, lr, pk, c1=10**(-4), tao=0.5, reset_lr=False):\n",
    "    '''\n",
    "    Función que calcula el tamaño del paso para cada iteración utilizando la condicion de armijo.\n",
    "    La tasa de aprendizaje minima es la que tenia en el paso anterior.\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - lr (float64): tasa de aprendizaje\n",
    "            - pk (array px1 float64): direccion de decenso\n",
    "            - c1 (float64) 0<c1<1: parametro de control\n",
    "            - tao (float64) 0<tao<1: parametro de decrecimiento de lr\n",
    "                \n",
    "        ** Salidas\n",
    "            - lr (float64): tamaño de paso\n",
    "    '''\n",
    "    #pruebas unitarias:\n",
    "    #verificar que tao esta entre 0 y 1\n",
    "    #verificare que c1 esta entre 0 y 1\n",
    "    #verificar que pk es negativo\n",
    "    \n",
    "    #inicializamos \n",
    "    tao = 0.9\n",
    "    max_iter = 100\n",
    "    iter = 0\n",
    "    \n",
    "    #inicializa lr\n",
    "    if reset_lr==True: lr = 1\n",
    "\n",
    "    #evalauciones periodicas\n",
    "    grad = gradiente_f(X,y,beta)\n",
    "    eval_f = f(X,y, beta)\n",
    "    \n",
    "    #primera iteracion\n",
    "    f_x =  f(X,y, beta + lr*pk) #en nocedal es phi(alpha)\n",
    "    f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) # en nocedal es l(alhpa)\n",
    "    \n",
    "    while ((f_x>f_x1) & (iter<max_iter)):\n",
    "        lr = lr*tao\n",
    "        f_x =  f(X,y, beta + lr*pk) \n",
    "        f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) \n",
    "        iter+=1\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba\n",
    "# prueba\n",
    "# No esta funcionando bien\n",
    "# Longitud de paso con condiciones completas de wolf\n",
    "\n",
    "def calc_lr_wolf(X, y, beta, lr, pk, c1=10**(-4), c2=0.9, tao=0.5, reset_lr=False):\n",
    "    '''\n",
    "    Función que calcula el tamaño del paso para cada iteración utilizando la condicion de armijo.\n",
    "    La tasa de aprendizaje minima es la que tenía en el paso anterior.\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - lr (float64): tasa de aprendizaje\n",
    "            - pk (array px1 float64): direccion de decenso\n",
    "            - c1 (float64) 0<c1<1: parametro de control\n",
    "            - tao (float64) 0<tao<1: parametro de decrecimiento de lr\n",
    "                \n",
    "        ** Salidas\n",
    "            - lr (float64): tamaño de paso\n",
    "    '''\n",
    "    #pruebas unitarias:\n",
    "    #verificar que tao esta entre 0 y 1\n",
    "    #verificare que c1 esta entre 0 y 1\n",
    "    #verificar que pk es negativo\n",
    "    \n",
    "    # Inicializamos \n",
    "    tao = 0.5\n",
    "    max_iter = 50\n",
    "    iter = 0\n",
    "    \n",
    "    # Inicializa lr\n",
    "    if reset_lr==True: lr=1\n",
    "\n",
    "    # Evalauciones periodicas\n",
    "    grad = gradiente_f(X,y,beta)\n",
    "    eval_f = f(X,y, beta)\n",
    "    \n",
    "    # Primera iteracion\n",
    "    f_x =  f(X,y, beta + lr*pk) #en nocedal es phi(alpha)\n",
    "    f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) # en nocedal es l(alhpa)\n",
    "    \n",
    "    gf_x = np.dot(gradiente_f(X,y, beta+lr*pk) , pk)\n",
    "    gf_x1 = c2* np.dot(grad, pk)\n",
    "    \n",
    "    while ((f_x>f_x1) & (gf_x<gf_x1) & (iter<max_iter)):\n",
    "        lr =lr*tao\n",
    "        f_x =  f(X,y, beta + lr*pk) \n",
    "        f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) \n",
    "        \n",
    "        gf_x = np.dot(gradiente_f(X,y, beta+lr*pk) , pk)\n",
    "        #gf_x1 = c2* np.dot(grad, pk)\n",
    "    \n",
    "        \n",
    "        iter+=1\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, lr=1, tol=10**(-7), max_iter=10**5, method=\"max\", reset_lr=False, verbose_n=1000):\n",
    "    '''\n",
    "    Función que devuelve vector de parámetros beta (px1) resultante del proceso de optimización por descenso de gradiente\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - lr (float64): valor inicial de la tasa de aprendizaje\n",
    "            - tol (float64): criterio de convergencia\n",
    "            - max_iter (int): número máximo de iteraciones\n",
    "            - method (str): método que determina la dirección de descenso\n",
    "                opciones:\n",
    "                    - max: método de descenso\n",
    "                    - newton: método de Newton\n",
    "                    - bfsg\n",
    "            \n",
    "        ** Salidas\n",
    "            - beta_new (vec): vector de p entradas con parámetros que minimizan la función de pérdida\n",
    "    '''\n",
    "\n",
    "    # Inicializa\n",
    "    iteraciones=0\n",
    "    H = None\n",
    "    dims = X.shape[1]\n",
    "    tol = tol*dims\n",
    "    \n",
    "    # Inicializamos beta aleatoria\n",
    "    beta = np.random.normal(1,3,dims)\n",
    "    if method ==\"bfsg\": H = np.identity(dims)\n",
    "    \n",
    "    # Primera iteracion\n",
    "    pk =  descent_direction(X, y, beta, method,H)\n",
    "    beta_new = beta + lr*pk\n",
    "    if method == \"bfsg\": H=calc_H(X,y,beta,beta_new,H) \n",
    "    \n",
    "    # Condición de paro.\n",
    "    while ((np.linalg.norm(gradiente_f(X,y,beta_new)) > tol) & (iteraciones < max_iter)):\n",
    "        iteraciones+=1 #contador de ciclo\n",
    "        \n",
    "        beta = beta_new\n",
    "        pk =  descent_direction(X,y,beta,method,H)\n",
    "        lr = calc_lr(X, y, beta, lr, pk, reset_lr = reset_lr)\n",
    "        \n",
    "        beta_new = beta + lr*pk\n",
    "        \n",
    "        if method == \"bfsg\": H=calc_H(X,y,beta,beta_new,H)\n",
    "            \n",
    "        # Imprime\n",
    "        if iteraciones % verbose_n == 0:\n",
    "            grad=np.linalg.norm(gradiente_f(X,y,beta_new))\n",
    "            print(f'gard:{grad:.7E}, lr:{lr:.4E}, iter:{iteraciones}')\n",
    "        \n",
    "    print(\"**************************************************\")\n",
    "    if iteraciones == max_iter:print(\"Alcanzó el número máximo de iteraciones\")\n",
    "    print(\"iteraciones=\",iteraciones)\n",
    "    print(\"||grad_f||=\",np.linalg.norm(gradiente_f(X,y,beta_new)))\n",
    "    print(\"**************************************************\")\n",
    "    \n",
    "    return beta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data =df_proc.to_numpy()\n",
    "y = data[:,0]\n",
    "X = data[:,1:]\n",
    "x_train, x_test, y_train, y_test=train_test_split(X,y,test_size=.2)\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "iteraciones= 16593\n",
      "||grad_f||= 1.0399150193139557e-06\n",
      "**************************************************\n",
      "beta_hat= [-12.86959747  25.1079574   -7.76389331   2.92291351   4.82423981\n",
      "   3.30592463   1.44203925   3.19768379   3.74964275   5.14513205\n",
      "   5.01755838   4.34508613]\n",
      "Error de clasificacion= 13.64 %\n",
      "CPU times: user 2.67 s, sys: 22.2 ms, total: 2.69 s\n",
      "Wall time: 2.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "beta_hat = gradient_descent(x_train,y_train,max_iter=10**6,reset_lr=False,verbose_n=100000)\n",
    "yhat = clasifica(x_test,beta_hat)\n",
    "\n",
    "print(\"beta_hat=\", beta_hat)\n",
    "print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gard:5.2686433E+00, lr:1.0000E+00, iter:10\n",
      "gard:8.7242228E-01, lr:1.0000E+00, iter:20\n",
      "gard:1.1122993E-01, lr:1.0000E+00, iter:30\n",
      "gard:6.9181560E-04, lr:1.0942E-01, iter:40\n",
      "gard:1.2844428E-04, lr:2.0276E-02, iter:50\n",
      "gard:2.8952954E-05, lr:4.6384E-03, iter:60\n",
      "gard:5.3613100E-06, lr:8.5950E-04, iter:70\n",
      "gard:1.2393521E-06, lr:1.7696E-04, iter:80\n",
      "**************************************************\n",
      "iteraciones= 81\n",
      "||grad_f||= 9.957681085804994e-07\n",
      "**************************************************\n",
      "beta_hat= [-12.86958514  25.1079274   -7.76388546   2.92295453   4.82423279\n",
      "   3.30592052   1.44203804   3.19767979   3.74964046   5.14512866\n",
      "   5.01755672   4.34508548]\n",
      "Error de clasificacion= 13.64 %\n",
      "CPU times: user 25.3 ms, sys: 4.3 ms, total: 29.6 ms\n",
      "Wall time: 50.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Método de Newton\n",
    "beta_hat = gradient_descent(x_train,y_train, method=\"newton\",max_iter = 10**5,verbose_n = 10)\n",
    "yhat = clasifica(x_test,beta_hat)\n",
    "\n",
    "print(\"beta_hat=\", beta_hat)\n",
    "print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gard:1.5026183E-04, lr:6.1704E-05, iter:100000\n",
      "gard:4.1612017E-05, lr:1.7427E-05, iter:200000\n",
      "**************************************************\n",
      "iteraciones= 272277\n",
      "||grad_f||= 1.1920621551314674e-06\n",
      "**************************************************\n",
      "beta_hat= [-12.86958672  25.10791047  -7.76388126   2.92219843   4.82423254\n",
      "   3.30591455   1.442042     3.19767815   3.74964351   5.1451287\n",
      "   5.01755709   4.34508782]\n",
      "Error de clasificacion= 13.64 %\n",
      "CPU times: user 1min 1s, sys: 56 µs, total: 1min 1s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#metodo bfsg\n",
    "\n",
    "beta_hat = gradient_descent(x_train,y_train, method = \"bfsg\",max_iter = 10**6,lr=1,verbose_n = 100000)\n",
    "yhat = clasifica(x_test,beta_hat)\n",
    "\n",
    "print(\"beta_hat=\", beta_hat)\n",
    "print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso del gradiente estocastico\n",
    "\n",
    "Calculamos la función de riego empirico como la esperanza de la funcion de perdida evaluada sobre todos los puntos del dominio.\n",
    "\n",
    "$$L_{emp}=\\frac{1}{m} \\sum^{m}_{i=1} y_i log(\\mu_i) + (1-y_i) log(1-\\mu_i)$$  \n",
    "<br>\n",
    "$$ \\mu_i = (1+e^{-\\beta^T x_i})^{-1}= \\sigma(\\beta^T x_i)$$\n",
    "\n",
    "Y el gradiente de la función de riesgo esta dado por:\n",
    "\n",
    "$$\\nabla L=\\frac{dL}{d\\mu_i} =\\frac{1}{m} \\sum^{m}_{i=1} x_i(\\mu_i-y_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def riesgo_empirico(X,y,beta):\n",
    "    mu=calc_mu(X,beta)\n",
    "    loss=-sum(y*np.log(mu)+(1-y)*np.log(1-mu))\n",
    "    return loss\n",
    "\n",
    "def gradiente_riesgo_empirico(X,y,beta):\n",
    "    m = X.shape[0]\n",
    "    mu = calc_mu(X,beta)\n",
    "    return np.matmul(np.transpose(X),mu-y)/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def mini_lotes(X,y,q=3):\n",
    "    cols = X.shape[1]\n",
    "    data = np.hstack((X,y[:,None]))\n",
    "    np.random.shuffle(data)\n",
    "    data = data[0:q]\n",
    "    X = data[:,0:cols]\n",
    "    y = data[:,cols]\n",
    "    return X,y\n",
    "\n",
    "def batch(m,q=10):\n",
    "    index=np.random.randint(low=0,high=m,size=q)\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SGD(X,y,batch_size,verbose_n=100,max_iter=10**5):\n",
    "\n",
    "    #inicializa\n",
    "    m=X.shape[0]\n",
    "    epsilon = 10**(-6)\n",
    "    beta = np.random.normal(0,1,X.shape[1])    \n",
    "    step_size=.01\n",
    "    iteraciones = 0\n",
    "    epoca=0\n",
    "    ipe=int(m/q)#iteraciones por epoca\n",
    "    \n",
    "    #primera iteracion\n",
    "    index=batch(m,batch_size)\n",
    "    x_lote=X[index,:]\n",
    "    y_lote = y[index]\n",
    "    beta_new = beta - step_size * gradiente_riesgo_empirico(x_lote,y_lote,beta) \n",
    "\n",
    "    #while ((np.linalg.norm(gradiente_f(X,y,beta_new)) > epsilon) & (iteraciones < max_iter)):\n",
    "    # while abs(f(X,y,beta) - f(X,y,beta_new)) > epsilon:\n",
    "    while iteraciones<max_iter:\n",
    "        iteraciones +=1\n",
    "        #print(\"iteraciones1=\",iteraciones)\n",
    "        beta = beta_new\n",
    "        #x_lote,y_lote = mini_lotes(X,y,q)\n",
    "        index=batch(m,batch_size)\n",
    "        x_lote=X[index,:]\n",
    "        y_lote = y[index]\n",
    "        beta_new = beta - step_size * gradiente_riesgo_empirico(x_lote,y_lote,beta)\n",
    "        #print(\"iteraciones2=\",iteraciones)\n",
    "        if iteraciones%100000==0:\n",
    "            epoca+=1\n",
    "            loss=riesgo_empirico(X,y,beta)\n",
    "            print(f'loss:{loss:.4}, epoca:{epoca}, iter:{iteraciones}')\n",
    "        #print(\"iteraciones3=\",iteraciones)\n",
    "    print(\"iteraciones=\",iteraciones)\n",
    "    return beta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Tamaño de minilote=  1\n",
      "loss:13.5, epoca:1, iter:100000\n",
      "loss:12.21, epoca:2, iter:200000\n",
      "loss:11.73, epoca:3, iter:300000\n",
      "loss:11.49, epoca:4, iter:400000\n",
      "loss:11.33, epoca:5, iter:500000\n",
      "loss:11.26, epoca:6, iter:600000\n",
      "loss:11.17, epoca:7, iter:700000\n",
      "loss:11.13, epoca:8, iter:800000\n",
      "loss:11.09, epoca:9, iter:900000\n",
      "loss:11.08, epoca:10, iter:1000000\n",
      "iteraciones= 1000000\n",
      "beta_hat= [-11.51397593  21.23478067  -6.84298925   1.19637253   4.19402414\n",
      "   2.6197877    1.44105778   2.67482847   3.6101607    4.79551517\n",
      "   4.81202666   4.43423504]\n",
      "Error de clasificacion= 13.64 %\n",
      "\n",
      "\n",
      "####################\n",
      "Tamaño de minilote=  2\n",
      "loss:13.5, epoca:1, iter:100000\n",
      "loss:12.19, epoca:2, iter:200000\n",
      "loss:11.7, epoca:3, iter:300000\n",
      "loss:11.46, epoca:4, iter:400000\n",
      "loss:11.32, epoca:5, iter:500000\n",
      "loss:11.23, epoca:6, iter:600000\n",
      "loss:11.17, epoca:7, iter:700000\n",
      "loss:11.13, epoca:8, iter:800000\n",
      "loss:11.13, epoca:9, iter:900000\n",
      "loss:11.07, epoca:10, iter:1000000\n",
      "iteraciones= 1000000\n",
      "beta_hat= [-11.5896808   21.22202562  -6.8058721    1.34884813   4.07326182\n",
      "   2.74396282   1.50597275   2.73657549   3.52953423   4.85633518\n",
      "   4.85202186   4.3477978 ]\n",
      "Error de clasificacion= 13.64 %\n",
      "\n",
      "\n",
      "####################\n",
      "Tamaño de minilote=  3\n",
      "loss:13.55, epoca:1, iter:100000\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Método de SGD\n",
    "for batch_size in range(1,10):\n",
    "    print(\"####################\")\n",
    "    print(\"Tamaño de minilote= \",batch_size)\n",
    "    beta_hat = SGD(x_train, y_train, max_iter=10**6, batch_size=batch_size)\n",
    "    yhat = clasifica(x_test,beta_hat)\n",
    "    \n",
    "    \n",
    "    print(\"beta_hat=\", beta_hat)\n",
    "    print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
