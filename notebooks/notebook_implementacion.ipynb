{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de los métodos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este notebook se plantea la solución del problema utilizando los algoritmos planteados. Este archivo está autocontenido, sin embargo, la implementación principal se realiza con enfoque modular.\n",
    "\n",
    "A continuación se describe el planteamiento del problema, y su implementación con el set de datos utilizado. Una explicación más detallada se realiza en el informe (en formato PDF) de este proyecto.\n",
    "\n",
    "\n",
    "**Nota:** Esta implementación se basa en material y actividades impartidas por los profesores de los cursos de [Métodos Numéricos y optimización](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/IV.optimizacion_convexa_y_machine_learning/4.3.Regresion_logistica_R.ipynb) (2010-I) (Prof. Erick Palacios Moreno) y Aprendizaje de Máquina (2019-II) (Prof. Rodrigo Mendoza Smith).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, se considera un conjunto de datos que incorpora una variable output, $y_{i}$ asociada a la supervivencia o no del paciente ${i}$ con virus del ébola, y ${j}$ variables explicativas asociadas, $x_{i,j}$. Los regresores escogidos son aquellos que, conforme con nuestra principal referencia, son buenos predictores de la probabilidad de muerte o no de un paciente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Tipo| Nombre|Descripción|\n",
    "|---| --- | --- |\n",
    "|Variable Numérica| CT |El cycle threshold (CT) es una variable que se calcula a partir de una relación médica bien conocida (qPCR) y la carga viral (una expresión númerica de la cantidad de virus dado un volúmen de fluido que normalmente se correlaciona con la severidad de una infección viral activa).|\n",
    "|Variable Numérica|TEMP|Temperatura corporal del paciente.|\n",
    "|Variable Numérica|_AGE_ |Edad del paciente.|\n",
    "|Variable Categórica |_HEADCH_ | Presencia o no dolores de cabeza. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no dolores de cabeza.|\n",
    "|Variable Categórica |  _BLEED_ | Presencia o no de sangrado. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no sangrado. |\n",
    "|Variable Categórica |  _DIARR_ | Presencia o no de diarrea. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no diarrea.|\n",
    "|Variable Categórica | _VOMIT_ | Presencia o no de vómitos. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no vómito.|\n",
    "|Variable Categórica | _PABD_ | Presencia o no de PADB.\n",
    "|Variable Categórica |_WEAK_ | Presencia o no de debilidad o fatiga general.|\n",
    "|Variable Categórica |_JAUN_ |Condición  en la cuál la piel, los ojos y los miembros mucosos que vuelven amarillos debido a altos niveles de bilirubina. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no ictericia.|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problema de regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matemáticamente, este conjunto se define de la siguiente manera: \n",
    "\n",
    "$$\\mathcal{D}=\\left\\{ \\left(x_{i},y_{i}\\right)\\in\\mathbb{R}^{p}\\times\\left\\{ 0,1\\right\\} :i\\in\\left[m\\right]\\right\\} $$.\n",
    "\n",
    "El método de _regresión logística_ asume que $Pr\\left[y_{i}\\mid x_{i},\\beta\\right]\\sim Bernoulli\\left(\\mu_{i}\\right)$\n",
    "con los siguientes supuestos sobre la media, $\\mu_{i}$:\n",
    "\n",
    "$$\n",
    "\\mu_{i}=\\sigma\\left(\\beta^{T}x_{i}\\right) \\label{eq-3.1} \\tag{1}\n",
    "$$\n",
    "$$\n",
    "\\sigma(z)=\\left(1+\\exp\\left(-z\\right)\\right)^{-1} \\label{eq-3.2} \\tag{2}\n",
    "$$\n",
    "\n",
    "donde $\\beta\\in\\mathbb{R}^{p}$. \n",
    "\n",
    "\n",
    "Dado lo anterior, nuestro problema es encontrar un modelo tal que $\\hat{\\beta}\\in\\mathbb{R}^{p}$ explica de la mejor manera posible a $\\mathcal{D}$. \n",
    "\n",
    "Para lograr lo anterior, debemos estimar el conjunto de parámetros $\\hat{\\beta}$ para modelar $Pr\\left[y\\mid x,\\hat{\\beta}\\right]$ y predecir la etiqueta $\\hat{y}\\in\\left\\{ 0,1\\right\\} $ de un nuevo\n",
    "dato $x$ por medio de:\n",
    "\n",
    "$$\n",
    "\\hat{y}=\\begin{cases}\n",
    "1 & si\\,\\sigma\\left(\\hat{\\beta}^{T}x\\right)\\geq0.5\\\\\n",
    "0 & si\\,\\sigma\\left(\\hat{\\beta}^{T}x\\right)<0.5\n",
    "\\end{cases}\\label{eq-3.3} \\tag{3}\n",
    "$$\n",
    "\n",
    "la función de pérdida que queremos minimizar en este problema corresponde a la _log-verosimilitud negativa_ , que está dada por:\n",
    "\n",
    "$$\n",
    "F(\\beta):=LVN(\\beta)=-\\sum_{i=1}^{m}\\left[y_{i}log\\mu_{i}+(1-y_{i})log(1-\\mu_{i})\\right]\\label{eq-3.4} \\tag{4}\n",
    "$$\n",
    "\n",
    "\n",
    "Una vez planteado lo anterior, queremos encontrar $\\hat{\\beta}$ por medio de métodos numéricos de optimización de tal forma que se minimize ([4](#mjx-eqn-eq1)) para el conjunto de datos dado.\n",
    "\n",
    "\n",
    "_En los siguientes fragmentos de código se realiza el planteamiento del problema, desde la importación de datos hasta el proceso de entrenamiento del modelo utilizando distintos algoritmos de optimización que se explican con brevedad._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de datos\n",
    "\n",
    "En esta sección se importa y transforma los datos, con el fin de obtener el conjunto $\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/afcarl/ebola-imc-public/master/data/kenema/test/pres-kgh/imputation-50.csv\"\n",
    "df_raw=pd.read_csv(url,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>JAUN</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.652450</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.736016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20.747653</td>\n",
       "      <td>65.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.736993</td>\n",
       "      <td>44.0</td>\n",
       "      <td>38.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OUT         CT   AGE  TEMP  HEADCH  BLEED  DIARR  JAUN  VOMIT  PABD  WEAK\n",
       "0    1  28.652450  42.0  36.3       0      0      1     0      0     1     1\n",
       "1    1  25.736016  45.0  36.5       1      0      1     0      0     1     1\n",
       "2    1  20.747653  65.0  38.0       1      0      0     0      0     0     0\n",
       "3    1  22.736993  44.0  38.6       1      0      0     0      0     0     1\n",
       "4    1  20.846284  11.0  38.4       1      0      0     0      1     0     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()\n",
    "# df[df.isnull().any(axis=1)] - no hay NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT         int64\n",
       "CT        float64\n",
       "AGE       float64\n",
       "TEMP      float64\n",
       "HEADCH      int64\n",
       "BLEED       int64\n",
       "DIARR       int64\n",
       "JAUN        int64\n",
       "VOMIT       int64\n",
       "PABD        int64\n",
       "WEAK        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificar tipo de variables \n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>JAUN</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>25.720411</td>\n",
       "      <td>34.102170</td>\n",
       "      <td>37.256604</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.405660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.426545</td>\n",
       "      <td>5.869164</td>\n",
       "      <td>17.382844</td>\n",
       "      <td>1.030767</td>\n",
       "      <td>0.491436</td>\n",
       "      <td>0.249528</td>\n",
       "      <td>0.493352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407477</td>\n",
       "      <td>0.447916</td>\n",
       "      <td>0.502375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.149857</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.236301</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.680924</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>38.225000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.799999</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>39.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OUT          CT         AGE        TEMP      HEADCH       BLEED  \\\n",
       "count  106.000000  106.000000  106.000000  106.000000  106.000000  106.000000   \n",
       "mean     0.764151   25.720411   34.102170   37.256604    0.603774    0.066038   \n",
       "std      0.426545    5.869164   17.382844    1.030767    0.491436    0.249528   \n",
       "min      0.000000   12.100000    0.830000   36.000000    0.000000    0.000000   \n",
       "25%      1.000000   22.149857   22.000000   36.300000    0.000000    0.000000   \n",
       "50%      1.000000   25.236301   35.500000   37.250000    1.000000    0.000000   \n",
       "75%      1.000000   28.680924   45.000000   38.225000    1.000000    0.000000   \n",
       "max      1.000000   39.799999   80.000000   39.900000    1.000000    1.000000   \n",
       "\n",
       "            DIARR   JAUN       VOMIT        PABD        WEAK  \n",
       "count  106.000000  106.0  106.000000  106.000000  106.000000  \n",
       "mean     0.405660    0.0    0.207547    0.273585    0.500000  \n",
       "std      0.493352    0.0    0.407477    0.447916    0.502375  \n",
       "min      0.000000    0.0    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.0    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.0    0.000000    0.000000    0.500000  \n",
       "75%      1.000000    0.0    0.000000    1.000000    1.000000  \n",
       "max      1.000000    0.0    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resumen de las variables\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "**Algunas observaciones sobre los datos**\n",
    "\n",
    "- Se determinan 3 grupos de edades, utilizando el percetil 25 (22 años), percentil 50 (36 años) y percentil 75 (45 años)   \n",
    "- Para este conjunto de datos la variable `JAUN` no tiene variabilidad, por lo tanto no es una variable, y se omite.\n",
    "\n",
    "Dado lo anterior, se ajusta el set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT            int64\n",
       "CT           float64\n",
       "AGE          float64\n",
       "TEMP         float64\n",
       "HEADCH         int64\n",
       "BLEED          int64\n",
       "DIARR          int64\n",
       "JAUN           int64\n",
       "VOMIT          int64\n",
       "PABD           int64\n",
       "WEAK           int64\n",
       "INTER_AGE     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ajustes en df_raw \n",
    "df_proc = df_raw\n",
    "df_proc['INTER_AGE'] = \"NA\"\n",
    "\n",
    "df_proc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT             int64\n",
       "CT            float64\n",
       "TEMP          float64\n",
       "HEADCH          int64\n",
       "BLEED           int64\n",
       "DIARR           int64\n",
       "VOMIT           int64\n",
       "PABD            int64\n",
       "WEAK            int64\n",
       "hasta22       float64\n",
       "entre23y36    float64\n",
       "entre37y45    float64\n",
       "mayor45       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ajustes en df_raw \n",
    "df_proc = df_raw\n",
    "\n",
    "# para la variable edad se crean cuatro categorías\n",
    "age_p25 = math.ceil(df_proc['AGE'].quantile(.25))\n",
    "age_p50 = math.ceil(df_proc['AGE'].quantile(.50))\n",
    "age_p75 = math.ceil(df_proc['AGE'].quantile(.75))\n",
    "\n",
    "df_proc['INTER_AGE'] = \"NA\"\n",
    "df_proc.loc[(df_proc['AGE'] <= age_p25), 'INTER_AGE'] = 1\n",
    "df_proc.loc[(df_proc['AGE'] > age_p25) & (df_proc['AGE'] <= age_p50), 'INTER_AGE'] = 2\n",
    "df_proc.loc[(df_proc['AGE'] > age_p50) & (df_proc['AGE'] <= age_p75), 'INTER_AGE'] = 3\n",
    "df_proc.loc[(df_proc['AGE'] > age_p75), 'INTER_AGE'] = 4\n",
    "\n",
    "## one hot encoding\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(df_proc[['INTER_AGE']]).toarray())\n",
    "enc_df = enc_df.rename(columns={0: f\"hasta{age_p25}\", 1: f\"entre{age_p25+1}y{age_p50}\", 2: f\"entre{age_p50+1}y{age_p75}\", 3:f\"mayor{age_p75}\"})\n",
    "# merge with main df bridge_df on key values\n",
    "df_proc = df_proc.join(enc_df)\n",
    "\n",
    "# se asignan como categoricas a las binarias, incluido el output\n",
    "bin_vars = ['OUT', 'HEADCH', 'BLEED', 'DIARR', 'JAUN', 'VOMIT',\n",
    "       'PABD', 'WEAK', 'INTER_AGE', f\"hasta{age_p25}\", f\"entre{age_p25+1}y{age_p50}\", f\"entre{age_p50+1}y{age_p75}\", f\"mayor{age_p75}\"]\n",
    "\n",
    "#esta asignacion hace que genera problemas al evaluar el sigmoide\n",
    "#for var in bin_vars:\n",
    "#    df_proc[var] = df_proc[var].astype('category')\n",
    "    \n",
    "# se omiten las variables JAUN, AGE, INTER_AGE\n",
    "del_vars = [\"JAUN\", \"AGE\", \"INTER_AGE\"]\n",
    "for var in del_vars:\n",
    "    df_proc = df_proc.drop(var, axis=1)    \n",
    "    \n",
    "# se comprueban los tipos de variable\n",
    "df_proc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "      <th>hasta22</th>\n",
       "      <th>entre23y36</th>\n",
       "      <th>entre37y45</th>\n",
       "      <th>mayor45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.652450</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.736016</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20.747653</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.736993</td>\n",
       "      <td>38.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>38.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>24.191797</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>38.816561</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>21.960294</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>26.221948</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OUT         CT  TEMP  HEADCH  BLEED  DIARR  VOMIT  PABD  WEAK  hasta22  \\\n",
       "0      1  28.652450  36.3       0      0      1      0     1     1      0.0   \n",
       "1      1  25.736016  36.5       1      0      1      0     1     1      0.0   \n",
       "2      1  20.747653  38.0       1      0      0      0     0     0      0.0   \n",
       "3      1  22.736993  38.6       1      0      0      0     0     1      0.0   \n",
       "4      1  20.846284  38.4       1      0      0      1     0     1      1.0   \n",
       "..   ...        ...   ...     ...    ...    ...    ...   ...   ...      ...   \n",
       "101    1  24.191797  36.4       0      0      1      1     1     1      0.0   \n",
       "102    1  20.846284  38.4       0      0      0      1     0     1      0.0   \n",
       "103    0  38.816561  36.0       0      0      0      0     0     0      1.0   \n",
       "104    1  21.960294  36.4       0      0      0      0     0     0      0.0   \n",
       "105    0  26.221948  36.5       1      0      0      0     0     0      0.0   \n",
       "\n",
       "     entre23y36  entre37y45  mayor45  \n",
       "0           0.0         1.0      0.0  \n",
       "1           0.0         1.0      0.0  \n",
       "2           0.0         0.0      1.0  \n",
       "3           0.0         1.0      0.0  \n",
       "4           0.0         0.0      0.0  \n",
       "..          ...         ...      ...  \n",
       "101         0.0         1.0      0.0  \n",
       "102         1.0         0.0      0.0  \n",
       "103         0.0         0.0      0.0  \n",
       "104         1.0         0.0      0.0  \n",
       "105         0.0         1.0      0.0  \n",
       "\n",
       "[106 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planteamiento del problema de regresión\n",
    "\n",
    "A continuación se plantea el código que computa las ecuaciones ([1](#mjx-eqn-eq1)), ([2](#mjx-eqn-eq1)) y ([4](#mjx-eqn-eq1)), planteadas inicialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(z):\n",
    "    '''\n",
    "    Devuelve el sigmoide de un vector\n",
    "        ** Parámetros:\n",
    "            - z (vec): vector numérico de m entradas\n",
    "        ** Salidas\n",
    "            - (float64) valor entre -1 y 1\n",
    "    '''\n",
    "    return 1/(1+ np.exp(-z))\n",
    "    \n",
    "def calc_mu(X,beta):\n",
    "    '''\n",
    "    Calcula la media para una variable aleatoria con distribución bernoulli.\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - beta (vec): vector de p entradas\n",
    "        ** Salidas\n",
    "            - mu (vec): vector de m entradas\n",
    "    '''\n",
    "    a = np.matmul(beta,np.transpose(X))\n",
    "    mu = sigmoide(a)\n",
    "\n",
    "    return mu\n",
    "    \n",
    "def f(X,y,beta):\n",
    "    '''\n",
    "    Función que computa la log-verosimilitud negativa\n",
    "    ** Parámetros:\n",
    "        - X (mat): matriz de mxp entradas\n",
    "        - y (vec): vector de de m entradas de la variable output\n",
    "        - beta (vec): vector de p entradas\n",
    "    ** Salidas\n",
    "        - lvn (int): log-verosimilitud negativa\n",
    "    '''\n",
    "    prob = calc_mu(X,beta)\n",
    "    # log-verosimilitud negativa \n",
    "    lvn = -sum(y*np.log(prob)+(1-y)*(np.log(1-prob)))\n",
    "    return lvn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reescribiendo la ecuación de la función de pérdida ([4](#mjx-eqn-eq1)), tenemos:\n",
    "\n",
    "$$F(\\beta)=- \\sum_{i=1}^{m}[y_i log\\mu_i + (1-y_i)log(1-\\mu_i)]$$\n",
    "\n",
    "Las expresiones correspondientes al gradiente y a la matriz hessiana asociados a este problema, se plantean a continuación:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla F(\\beta) & =\\frac{d}{d\\beta}F(\\beta)\\nonumber \\\\\n",
    " & =\\sum_{i}\\left(\\mu_{i}-y_{i}\\right)x_{i}\\nonumber \\\\\n",
    " & =\\boldsymbol{X}^{T}\\left(\\boldsymbol{\\mu}-\\boldsymbol{y}\\right)\\label{eq:gradient}\n",
    "\\end{align}\n",
    "\n",
    "Por otro lado, la ecuación que describe la matrix Hessiana es la siguiente:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla^{2}F(\\beta) & =\\frac{d}{d\\beta}\\nabla F\\left(\\beta\\right)^{T}\\nonumber \\\\\n",
    " & =\\sum_{i}\\left(\\nabla_{\\beta}\\mu_{i}\\right)x_{i}^{T}\\nonumber \\\\\n",
    " & =\\sum_{i}\\mu_{i}\\left(1-\\mu_{i}\\right)x_{i}x_{i}^{T}\\nonumber \\\\\n",
    " & =\\boldsymbol{X^{T}SX}\\label{eq:hessian}\n",
    "\\end{align}\n",
    "\n",
    "donde $\\boldsymbol{S}\\triangleq diag\\left(\\mu_{i}\\left(1-\\mu_{i}\\right)\\right)$.\n",
    "Como es resaltado por Murphy (2012), es definida positiva, lo que implica que ([4](#mjx-eqn-eq1)) es convexa\n",
    "y tiene un mínimo global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_f(X,y,beta):\n",
    "    '''\n",
    "    Calcula el gradiente asociado la log-verosimilitud negativa del problema de regresión logística\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - beta (vec): vector de p entradas\n",
    "        ** Salidas\n",
    "            - grad (vec): vector de m entradas\n",
    "    '''\n",
    "    mu=calc_mu(X,beta)    \n",
    "    grad = np.matmul(np.transpose(X), mu-y)    \n",
    "    return grad\n",
    "\n",
    "\n",
    "def hessiana_f(X,y,beta):\n",
    "    '''\n",
    "    Calcula la matriz Hessiana asociada a la log-verosimilitud negativa del problema de regresión logística\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - beta (vec): vector de p entradas\n",
    "        ** Salidas\n",
    "            - grad (vec): vector de m entradas\n",
    "    '''\n",
    "    mu=calc_mu(X,beta)\n",
    "    S=np.diag(mu*(1-mu))\n",
    "    hes=np.matmul(np.transpose(X),np.matmul(S,X))\n",
    "    return hes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    '''\n",
    "    Funcion que normaliza un vector\n",
    "        **Parametros:\n",
    "            - x: vector a normalizar\n",
    "            \n",
    "        **Salidas:\n",
    "            - x': Vector x normalizado\n",
    "    '''\n",
    "    return x/np.sqrt(sum(x*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasifica(X, beta_hat,limit=0.5):\n",
    "    '''\n",
    "    This function clasifies the ocurrance probabilities into 2 groups.\n",
    "    It uses the limit parameter to delimit wheather a point is assigned to group zero or group 1.\n",
    "        **Parameters:\n",
    "            - X (mat): matrix of data\n",
    "            - beta_hat (array): optimized parameter\n",
    "            - limit (float64) 0<limit<1: Threshold for each classification\n",
    "        \n",
    "        **Out:\n",
    "            - yhat: array of classifed data\n",
    "    '''\n",
    "    mu=calc_mu(X,beta_hat)\n",
    "    yhat=mu\n",
    "    yhat[mu<limit]=0\n",
    "    yhat[mu>=limit]=1\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent_direction(X, y, beta, method=\"max\",H=None):\n",
    "    '''\n",
    "    Devuelve vector normalizado (px1) que apunta en la direccion de decenso\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - beta (vec float64): vector de entradas a optimizar\n",
    "            - method (str): método que determina la dirección de descenso\n",
    "                opciones:\n",
    "                    - max: método de descenso\n",
    "                    - newton: método de Newton\n",
    "                    - bfsg: metodo bfsg\n",
    "            - H (mat pxp): Parametro para direccion de decenso del metodo bfgs\n",
    "            \n",
    "        ** Salidas\n",
    "            - pk (vec): vector normalizado con la direccion del paso\n",
    "    '''\n",
    "    if(method==\"max\"):\n",
    "        pk=gradiente_f(X,y,beta)\n",
    "    \n",
    "    elif(method==\"newton\"):\n",
    "        grad=gradiente_f(X,y,beta)\n",
    "        hess=hessiana_f(X,y,beta)\n",
    "        pk=np.linalg.solve(hess,grad)\n",
    "        \n",
    "    elif(method==\"bfsg\"):\n",
    "        pk=np.matmul(H,gradiente_f(X,y,beta))\n",
    "                              \n",
    "    return - normalize(pk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_H(X,y,beta,beta_new=None,H=None):\n",
    "    '''\n",
    "    Funcion que actualiza los valores de la matriz H del metodo bfgs para cada iteracion\n",
    "        ** Parametros:\n",
    "            - beta (array) - valor de cantidad a optimizar en la iteracion actual\n",
    "            - beta_new (array)- valore de la cantidad a optimizar despues de la actualizacion\n",
    "            - H (mat)- valor de la matriz H en la iteracion anterior\n",
    "        \n",
    "        ** Salidas:\n",
    "            - H (mat): valor de la matriz para la siguiente iteracion\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    w= gradiente_f(X,y,beta_new)- gradiente_f(X,y,beta)\n",
    "    z=beta_new-beta\n",
    "    Hz=np.matmul(H,z)\n",
    "    dotwz=np.dot(w,z)\n",
    "    dotzhz=np.dot(Hz,z)\n",
    "    H=H+(np.outer(w,w)/dotwz)-(np.outer(Hz,Hz)/dotzhz)\n",
    "   \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lr(X, y, beta, lr, pk, c1=10**(-4), tao=0.5, reset_lr=False):\n",
    "    '''\n",
    "    Calucla el tamaño del paso para cada iteración utilizando la condicion de armijo.\n",
    "    La tasa de aprendizaje minima es la que tenia en el paso anterior.\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - lr (float64): tasa de aprendizaje\n",
    "            - pk (array px1 float64): direccion de decenso\n",
    "            - c1 (float64) 0<c1<1: parametro de control\n",
    "            - tao (float64) 0<tao<1: parametro de decrecimiento de lr\n",
    "                \n",
    "        ** Salidas\n",
    "            - lr (float64): tamaño de paso\n",
    "    '''\n",
    "    #pruebas unitarias:\n",
    "    #verificar que tao esta entre 0 y 1\n",
    "    #verificare que c1 esta entre 0 y 1\n",
    "    #verificar que pk es negativo\n",
    "    \n",
    "    #inicializamos \n",
    "    tao=0.9\n",
    "    max_iter=100\n",
    "    iter=0\n",
    "    \n",
    "    #inicializa lr\n",
    "    if reset_lr==True: lr=1\n",
    "\n",
    "    #evalauciones periodicas\n",
    "    grad=gradiente_f(X,y,beta)\n",
    "    eval_f= f(X,y, beta)\n",
    "    \n",
    "    #primera iteracion\n",
    "    f_x=  f(X,y, beta + lr*pk) #en nocedal es phi(alpha)\n",
    "    f_x1= eval_f + c1 * lr *  np.dot(grad,pk) # en nocedal es l(alhpa)\n",
    "    \n",
    "    while ((f_x>f_x1) & (iter<max_iter)):\n",
    "        lr=lr*tao\n",
    "        f_x=  f(X,y, beta + lr*pk) \n",
    "        f_x1= eval_f + c1 * lr *  np.dot(grad,pk) \n",
    "        iter+=1\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba\n",
    "# prueba\n",
    "# No esta funcionando bien\n",
    "# Longitud de paso con condiciones completas de wolf\n",
    "\n",
    "def calc_lr_wolf(X, y, beta, lr, pk, c1=10**(-4), c2=0.9, tao=0.5, reset_lr=False):\n",
    "    '''\n",
    "    Calucla el tamaño del paso para cada iteración utilizando la condicion de armijo.\n",
    "    La tasa de aprendizaje minima es la que tenia en el paso anterior.\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - lr (float64): tasa de aprendizaje\n",
    "            - pk (array px1 float64): direccion de decenso\n",
    "            - c1 (float64) 0<c1<1: parametro de control\n",
    "            - tao (float64) 0<tao<1: parametro de decrecimiento de lr\n",
    "                \n",
    "        ** Salidas\n",
    "            - lr (float64): tamaño de paso\n",
    "    '''\n",
    "    #pruebas unitarias:\n",
    "    #verificar que tao esta entre 0 y 1\n",
    "    #verificare que c1 esta entre 0 y 1\n",
    "    #verificar que pk es negativo\n",
    "    \n",
    "    #inicializamos \n",
    "    tao=0.5\n",
    "    max_iter=50\n",
    "    iter=0\n",
    "    \n",
    "    #inicializa lr\n",
    "    if reset_lr==True: lr=1\n",
    "\n",
    "    #evalauciones periodicas\n",
    "    grad=gradiente_f(X,y,beta)\n",
    "    eval_f= f(X,y, beta)\n",
    "    \n",
    "    #primera iteracion\n",
    "    f_x=  f(X,y, beta + lr*pk) #en nocedal es phi(alpha)\n",
    "    f_x1= eval_f + c1 * lr *  np.dot(grad,pk) # en nocedal es l(alhpa)\n",
    "    \n",
    "    gf_x= np.dot(gradiente_f(X,y, beta+lr*pk) , pk)\n",
    "    gf_x1 = c2* np.dot(grad, pk)\n",
    "    \n",
    "    while ((f_x>f_x1) & (gf_x<gf_x1) & (iter<max_iter)):\n",
    "        lr=lr*tao\n",
    "        f_x=  f(X,y, beta + lr*pk) \n",
    "        f_x1= eval_f + c1 * lr *  np.dot(grad,pk) \n",
    "        \n",
    "        gf_x= np.dot(gradiente_f(X,y, beta+lr*pk) , pk)\n",
    "        #gf_x1 = c2* np.dot(grad, pk)\n",
    "    \n",
    "        \n",
    "        iter+=1\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, lr=1, tol=10**(-7), max_iter=10**5, method=\"max\", reset_lr=False, verbose_n=1000):\n",
    "    '''\n",
    "    Devuelve vector de parámetros beta (px1) resultante del proceso de optimización por descenos de gradiente\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - lr (float64): valor inicial de la tasa de aprendizaje\n",
    "            - tol (float64): criterio de convergencia\n",
    "            - max_iter (int): número máximo de iteraciones\n",
    "            - method (str): método que determina la dirección de descenso\n",
    "                opciones:\n",
    "                    - max: método de descenso\n",
    "                    - newton: método de Newton\n",
    "                    - bfsg\n",
    "            \n",
    "        ** Salidas\n",
    "            - beta_new (vec): vector de p entradas con parámetros que minimizan la función de pérdida\n",
    "    '''\n",
    "\n",
    "    #inicializa\n",
    "    iteraciones=0\n",
    "    H=None\n",
    "    dims=X.shape[1]\n",
    "    tol=tol*dims\n",
    "    \n",
    "    #inicializamos beta aleatoria\n",
    "    beta=np.random.normal(1,3,dims)\n",
    "    if method==\"bfsg\": H=np.identity(dims)\n",
    "    \n",
    "    #primera iteracion\n",
    "    pk =  descent_direction(X, y, beta, method,H)\n",
    "    beta_new= beta + lr*pk\n",
    "    if method==\"bfsg\": H=calc_H(X,y,beta,beta_new,H) \n",
    "    \n",
    "    #condición de paro.\n",
    "    while ((np.linalg.norm(gradiente_f(X,y,beta_new))>tol) & (iteraciones<max_iter)):\n",
    "        iteraciones+=1 #contador de ciclo\n",
    "        \n",
    "        beta = beta_new\n",
    "        pk =  descent_direction(X,y,beta,method,H)\n",
    "        lr= calc_lr(X, y, beta, lr, pk, reset_lr=reset_lr)\n",
    "        \n",
    "        beta_new = beta + lr*pk\n",
    "        \n",
    "        if method==\"bfsg\": H=calc_H(X,y,beta,beta_new,H)\n",
    "            \n",
    "        #imprime\n",
    "        if iteraciones % verbose_n == 0:\n",
    "            grad=np.linalg.norm(gradiente_f(X,y,beta_new))\n",
    "            print(f'gard:{grad:.7E}, lr:{lr:.4E}, iter:{iteraciones}')\n",
    "        \n",
    "    print(\"##########################\")\n",
    "    if iteraciones==max_iter:print(\"Alcanzo el numero maximo de iteraciones\")\n",
    "    print(\"iteraciones=\",iteraciones)\n",
    "    print(\"||grad_f||=\",np.linalg.norm(gradiente_f(X,y,beta_new)))\n",
    "    print(\"##########################\")\n",
    "    \n",
    "    return beta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data =df_proc.to_numpy()\n",
    "y = data[:,0]\n",
    "X = data[:,1:]\n",
    "x_train, x_test, y_train, y_test=train_test_split(X,y,test_size=.2)\n",
    "\n",
    "#scale data\n",
    "scaler=MinMaxScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gard:1.3446352E-03, lr:7.7355E-04, iter:100000\n",
      "gard:3.7976139E-04, lr:2.1847E-04, iter:200000\n",
      "gard:3.7976029E-04, lr:2.1847E-04, iter:300000\n",
      "gard:3.7975974E-04, lr:2.1847E-04, iter:400000\n",
      "gard:1.0725527E-04, lr:6.1704E-05, iter:500000\n",
      "gard:1.0725521E-04, lr:6.1704E-05, iter:600000\n",
      "gard:1.0725517E-04, lr:6.1704E-05, iter:700000\n",
      "gard:1.0725513E-04, lr:6.1704E-05, iter:800000\n",
      "gard:1.0725511E-04, lr:6.1704E-05, iter:900000\n",
      "gard:1.0725509E-04, lr:6.1704E-05, iter:1000000\n",
      "##########################\n",
      "Alcanzo el numero maximo de iteraciones\n",
      "iteraciones= 1000000\n",
      "||grad_f||= 0.00010725508650594913\n",
      "##########################\n",
      "beta_hat= [-11.09777516  19.61336523  -8.02464584   0.6500527    3.39512425\n",
      "  16.07473001   0.43832494   2.47718908   3.78224043   6.32984722\n",
      "   7.14380548   9.50486614]\n",
      "Error de clasificacion= 13.64 %\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "beta_hat=gradient_descent(x_train,y_train,max_iter=10**6,reset_lr=False,verbose_n=100000)\n",
    "yhat=clasifica(x_test,beta_hat)\n",
    "\n",
    "print(\"beta_hat=\", beta_hat)\n",
    "print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gard:1.2137203E+01, lr:1.0000E+00, iter:10\n",
      "gard:1.4664947E+00, lr:1.0000E+00, iter:20\n",
      "gard:2.1898733E-01, lr:1.0000E+00, iter:30\n",
      "gard:1.8407239E-04, lr:1.0000E+00, iter:40\n",
      "##########################\n",
      "iteraciones= 46\n",
      "||grad_f||= 4.563113314902949e-07\n",
      "##########################\n",
      "beta_hat= [-11.09779315  19.61337157  -8.02466872   0.65005577   3.39510652\n",
      "  18.12233953   0.43832299   2.47718376   3.78223349   6.3298425\n",
      "   7.14380395   9.50487452]\n",
      "Error de clasificacion= 13.64 %\n",
      "Wall time: 13.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Método de Newton\n",
    "beta_hat=gradient_descent(x_train,y_train, method=\"newton\",max_iter=10**5,verbose_n=10)\n",
    "yhat=clasifica(x_test,beta_hat)\n",
    "\n",
    "print(\"beta_hat=\", beta_hat)\n",
    "print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gard:2.5454654E-03, lr:1.4556E-03, iter:100000\n",
      "gard:2.5363263E-03, lr:1.4556E-03, iter:200000\n",
      "gard:7.2580603E-04, lr:4.1110E-04, iter:300000\n",
      "gard:7.2257272E-04, lr:4.1110E-04, iter:400000\n",
      "gard:7.2076327E-04, lr:4.1110E-04, iter:500000\n",
      "gard:7.1958096E-04, lr:4.1110E-04, iter:600000\n",
      "gard:7.1874460E-04, lr:4.1110E-04, iter:700000\n",
      "gard:7.1812213E-04, lr:4.1110E-04, iter:800000\n",
      "gard:7.1764183E-04, lr:4.1110E-04, iter:900000\n",
      "gard:7.1726100E-04, lr:4.1110E-04, iter:1000000\n",
      "##########################\n",
      "Alcanzo el numero maximo de iteraciones\n",
      "iteraciones= 1000000\n",
      "||grad_f||= 0.000717260995592072\n",
      "##########################\n",
      "beta_hat= [-11.09740522  19.61267014  -8.02424412   0.67363978   3.39532364\n",
      "  12.52192842   0.43827301   2.47713566   3.78218635   6.32978696\n",
      "   7.14347882   9.50436543]\n",
      "Error de clasificacion= 13.64 %\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#metodo bfsg\n",
    "beta_hat=gradient_descent(x_train,y_train, method=\"bfsg\",max_iter=10**6,lr=1,verbose_n=100000)\n",
    "yhat=clasifica(x_test,beta_hat)\n",
    "\n",
    "print(\"beta_hat=\", beta_hat)\n",
    "print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso del gradiente estocastico\n",
    "\n",
    "Calculamos la función de riego empirico como la esperanza de la funcion de perdida evaluada sobre todos los puntos del dominio.\n",
    "\n",
    "$$L_{emp}=\\frac{1}{m} \\sum^{m}_{i=1} y_i log(\\mu_i) + (1-y_i) log(1-\\mu_i)$$  \n",
    "<br>\n",
    "$$ \\mu_i = (1+e^{-\\beta^T x_i})^{-1}= \\sigma(\\beta^T x_i)$$\n",
    "\n",
    "Y el gradiente de la función de riesgo esta dado por:\n",
    "\n",
    "$$\\nabla L=\\frac{dL}{d\\mu_i} =\\frac{1}{m} \\sum^{m}_{i=1} x_i(\\mu_i-y_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_L(X,y,beta):\n",
    "    m=X.shape[0]\n",
    "    mu=calc_mu(X,beta)\n",
    "    return np.matmul(np.transpose(X),mu-y)/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_lotes(X,y,q=3):\n",
    "    cols=X.shape[1]\n",
    "    data=np.hstack((X,y[:,None]))\n",
    "    np.random.shuffle(data)\n",
    "    data=data[0:q]\n",
    "    X=data[:,0:cols]\n",
    "    y=data[:,cols]\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def SDG(X,y,q):\n",
    "    #inicializa\n",
    "    epsilon=10**(-6)\n",
    "    beta=np.random.normal(0,1,X.shape[1])    \n",
    "    step_size=.01\n",
    "    j=0\n",
    "\n",
    "    #primera iteracion\n",
    "    x_lote, y_lote = mini_lotes(X,y,q)\n",
    "    beta_new= beta - step_size * gradiente_L(x_lote,y_lote,beta) \n",
    "    \n",
    "    while abs(f(X,y,beta) - f(X,y,beta_new)) > epsilon:\n",
    "        beta=beta_new\n",
    "        x_lote,y_lote=mini_lotes(X,y,q)\n",
    "        beta_new= beta - step_size * gradiente_L(x_lote,y_lote,beta)\n",
    "\n",
    "        j=j+1\n",
    "        if j>50000:\n",
    "            break\n",
    "    \n",
    "    print(\"iteraciones=\",j)\n",
    "    return beta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteraciones= 8897\n",
      "beta_hat= [-0.83309139  0.48950584  0.44620611  1.04011629  0.45094662  0.80497107\n",
      "  0.31259103  0.46601967  0.42295115  0.86221139  0.74196454  0.25103816]\n",
      "Error de clasificacion= 31.82 %\n",
      "iteraciones= 13270\n",
      "beta_hat= [-0.30821643  0.87318595  0.93670273  0.00497669  0.07562983  0.50797713\n",
      "  0.70054496  0.91411294 -0.31569036  0.14226605  0.14608515 -0.75830777]\n",
      "Error de clasificacion= 27.27 %\n",
      "iteraciones= 4520\n",
      "beta_hat= [ 1.31846843e-03 -5.25456675e-01 -5.80633496e-01  1.00581065e+00\n",
      "  1.34464837e+00 -6.91958169e-01 -1.01679165e+00  1.23707694e+00\n",
      "  5.06007681e-01 -4.72660905e-01  1.88024556e+00  2.00680707e+00]\n",
      "Error de clasificacion= 40.91 %\n",
      "iteraciones= 7819\n",
      "beta_hat= [ 0.99341639 -0.53861034  0.12236935  0.10489803  0.00836162  0.17666456\n",
      "  1.07010245 -0.16938264  0.97130622  0.3828556   0.36671477  1.84911791]\n",
      "Error de clasificacion= 36.36 %\n",
      "iteraciones= 4819\n",
      "beta_hat= [ 0.43966227 -1.64822262 -0.19878508  0.11564698 -0.00345734 -0.21598724\n",
      "  1.20621448  0.97274902 -0.29903988  0.42791614  0.85370713  0.34298956]\n",
      "Error de clasificacion= 45.45 %\n",
      "iteraciones= 2975\n",
      "beta_hat= [ 1.30849388 -0.11257775  1.14775511  0.72615593 -0.52403566 -0.89104899\n",
      " -0.70196262 -0.1808166  -0.20341841  0.54709153  0.83070631 -0.25763712]\n",
      "Error de clasificacion= 63.64 %\n",
      "iteraciones= 10030\n",
      "beta_hat= [-0.5702031   2.63251451  0.15422967 -0.48008723  0.11651555  1.88027769\n",
      "  0.75346821  0.21546949  0.87842616 -0.56879366  0.36481278 -0.37409188]\n",
      "Error de clasificacion= 27.27 %\n",
      "iteraciones= 3130\n",
      "beta_hat= [ 2.66377821  0.83661231  0.32166526 -0.10994688 -0.54243144 -0.45667228\n",
      "  1.34839373  0.74191783 -0.62769415 -0.00466891 -0.19758503  0.97580792]\n",
      "Error de clasificacion= 36.36 %\n",
      "iteraciones= 12021\n",
      "beta_hat= [-0.81616564  1.34682114  0.97796688  0.7860344  -0.05920178  1.8952869\n",
      " -0.91918005  0.79462223  0.23948048  1.23966488 -0.2766144   0.02145019]\n",
      "Error de clasificacion= 27.27 %\n",
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Método de SGD\n",
    "for q in range(1,10):\n",
    "    beta_hat=SDG(x_train,y_train,q)\n",
    "    yhat=clasifica(x_test,beta_hat)\n",
    "\n",
    "    print(\"beta_hat=\", beta_hat)\n",
    "    print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
