{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import adds\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mThis is a test in RED\u001b[0m\n",
      "\u001b[34mThis is a test in BLUE\u001b[0m\n",
      "\u001b[1m\u001b[32mThis is a bold text in green\u001b[0m\n",
      "\u001b[1m\u001b[42mThis is a text with green background\u001b[0m\n",
      "\u001b[32mThis is a green text with \u001b[1mbold\u001b[0m\u001b[32m text included\u001b[0m\n",
      "\u001b[1mUse this\u001b[0m even with \u001b[1m\u001b[31mno parameters\u001b[0m in the with statement\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# or implied, of Diego Navarro Mellén.\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "# Special END separator\n",
    "END = '0e8ed89a-47ba-4cdb-938e-b8af8e084d5c'\n",
    "\n",
    "# Text attributes\n",
    "ALL_OFF = '\\033[0m'\n",
    "BOLD = '\\033[1m'\n",
    "UNDERSCORE = '\\033[4m'\n",
    "BLINK = '\\033[5m'\n",
    "REVERSE = '\\033[7m'\n",
    "CONCEALED = '\\033[7m'\n",
    "\n",
    "# Foreground colors\n",
    "FG_BLACK = '\\033[30m'\n",
    "FG_RED = '\\033[31m'\n",
    "FG_GREEN = '\\033[32m'\n",
    "FG_YELLOW = '\\033[33m'\n",
    "FG_BLUE = '\\033[34m'\n",
    "FG_MAGENTA = '\\033[35m'\n",
    "FG_CYAN = '\\033[36m'\n",
    "FG_WHITE = '\\033[37m'\n",
    "\n",
    "# Background colors\n",
    "BG_BLACK = '\\033[40m'\n",
    "BG_RED = '\\033[41m'\n",
    "BG_GREEN = '\\033[42m'\n",
    "BG_YELLOW = '\\033[43m'\n",
    "BG_BLUE = '\\033[44m'\n",
    "BG_MAGENTA = '\\033[45m'\n",
    "BG_CYAN = '\\033[46m'\n",
    "BG_WHITE = '\\033[47m'\n",
    "\n",
    "\n",
    "class pretty_output():\n",
    "    '''\n",
    "    Context manager for pretty terminal prints\n",
    "    '''\n",
    "\n",
    "    def __init__(self, *attr):\n",
    "        self.attributes = attr\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        pass\n",
    "\n",
    "    def write(self, msg):\n",
    "        style = ''.join(self.attributes)\n",
    "        print('{}{}{}'.format(style, msg.replace(END, ALL_OFF + style), ALL_OFF))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    with pretty_output(FG_RED) as out:\n",
    "        out.write('This is a test in RED')\n",
    "\n",
    "    with pretty_output(FG_BLUE) as out:\n",
    "        out.write('This is a test in BLUE')\n",
    "\n",
    "    with pretty_output(BOLD, FG_GREEN) as out:\n",
    "        out.write('This is a bold text in green')\n",
    "\n",
    "    with pretty_output(BOLD, BG_GREEN) as out:\n",
    "        out.write('This is a text with green background')\n",
    "\n",
    "    with pretty_output(FG_GREEN) as out:\n",
    "        out.write('This is a green text with ' + BOLD + 'bold' + END + ' text included')\n",
    "\n",
    "    with pretty_output() as out:\n",
    "        out.write(BOLD + 'Use this' + END + ' even with ' + BOLD + FG_RED + 'no parameters' + END + ' in the with statement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de los métodos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este notebook se plantea la solución del problema utilizando los siguiente métodos: Newton, Broyden-Fletcher-Goldfarb-Shanno  (BFGS) y el gradiente descendente estocástico (SGD). El presente notebook es autocontenido, sin embargo, la implementación principal se realiza con un enfoque modular.\n",
    "\n",
    "A continuación, se describe el conjunto de datos que se emplearán y se define el planteamiento del problema. Una explicación más detallada se realiza en el informe (en formato PDF) de este proyecto.\n",
    "\n",
    "**Nota:** Esta implementación se basa en material y actividades impartidas por los profesores de los cursos de [Métodos Numéricos y optimización](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/IV.optimizacion_convexa_y_machine_learning/4.3.Regresion_logistica_R.ipynb) (2010-I) (Prof. Erick Palacios Moreno) y Aprendizaje de Máquina (2019-II) (Prof. Rodrigo Mendoza Smith).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema de regresión Logística\n",
    "\n",
    "Como es resaltado por Murphy (2012), el problema de regresión logística es una generalización del problema de regresión lineal, convirtiendolo hacia un problema de clasificación, siempre y cuando la variable de respuesta sea de carácter binario (i.e. $y\\in\\left\\{ 0,1\\right\\} $), y por tanto se pueda asumir que sigue una distribución Bernoulli. En este caso, dicha variable de respuesta corresponde a si el paciente muere a casua del virus del ébola $(1)$, o no $(0)$. \n",
    "\n",
    "Dado lo anterior, utilizamos:\n",
    "\n",
    "$$\n",
    "{Pr[y\\mid\\boldsymbol{x,w}]=Ber(y\\mid\\mu(x))}\\n",
    "$$\n",
    "\n",
    "donde la media, se define en términos de la probabilidad de que el\n",
    "paciente muera, es decir, $\\mu(x)=E\\left[y\\mid x\\right]=p\\left(y=1\\mid x\\right)$.\n",
    "Donde el conjunto de variables explicativas está representado por\n",
    "$x$.\n",
    "\n",
    "Por otro lado, para la realización del computo de la media, se utiliza\n",
    "la función sigmoide, $\\sigma(x)$, la cual garantiza que dada una\n",
    "combinación lineal de las variables explicativas, con los parámetros\n",
    "del modelo (i.e. $\\beta^{T}x$), se cumpla que $0\\leq\\mu(x)\\leq1$:\n",
    "\n",
    "$$\n",
    "\\mu\\left(x\\right)=\\sigma\\left(\\beta^{T}x\\right)\\label{eq:mu_x}\n",
    "$$\n",
    "\n",
    "donde $\\sigma$ está definida por:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma(x)=\\frac{1}{1+\\exp(-x)}=\\frac{e^{x}}{e^{x}+1}\\label{eq:sigmoide} \n",
    "\\end{equation}\n",
    "\n",
    "Los resultados asociados a la ecuación $\\mu(x)$ están dados\n",
    "en términos de probabilidades. Así, es necesario definir un umbral clasificatorio para definir si el modelo predice que el paciente fallezca, o no. En este ejercicio, como se hace usualmente, y como realizan Colubri et. al (2019), se toma como umbral el valor de $0.5$. Es decir:\n",
    "\n",
    "$$\n",
    "\\hat{y}=\\left\\{\n",
    "\\begin{array}{@{}ll@{}}\n",
    "0, & \\text{si}\\ \\sigma(\\hat{\\beta}^Tx)  < 0.5 \\\\\n",
    "1, & \\text{si} \\ \\sigma(\\hat{\\beta}^Tx) \\geq 0.5\n",
    "\\end{array}\\right. \\label{eq:umbral}\n",
    "$$\n",
    "\n",
    "Los parámetros asociados a las variables regresoras, $\\hat{\\beta}$, son estimados con el conjunto de datos de entrenamiento. \n",
    "\n",
    "### Función de pérdida\n",
    "\n",
    "La función de pérdida asociada a este problema es la log-verosimilitud\n",
    "negativa, o entropía cruzada, definida de las siguiente forma:\n",
    "\n",
    "\n",
    "$$\n",
    "LVN(\\beta)=-\\sum_{i=1}^{N}\\left[y_{i}log\\mu_{i}+(1-y_{i})log(1-\\mu_{i})\\right]\\label{eq:lvn2}\n",
    "$$\n",
    "\n",
    "**Este problema no tiene solución analítica**. Es por esta razón que para minimizar\n",
    "la función de pérdida en torno a $\\beta$ es requerido **utilizar métodos de optimización numérica**. \n",
    "\n",
    "El código asociado a estos componentes se pone a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasifica(X, beta_hat,limit=0.5):\n",
    "    '''\n",
    "    \n",
    "    Función que clasifica la ocurrencia de probabilidades en dos grupos.\n",
    "    \n",
    "    Emplea el parámetro límite para delimitar si se clasifica en el grupo 0 o 1.\n",
    "    \n",
    "        ** Parámetros:\n",
    "        \n",
    "            - X (mat): matriz de mxp entradas\n",
    "            \n",
    "            - beta_hat (array): optimized parameter\n",
    "            \n",
    "            - limit (float64): 0<limit<1: Threshold for each classification\n",
    "            \n",
    "        \n",
    "        ** Salidas:\n",
    "        \n",
    "            - yhat: array of classifed data\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    if type(X) is not np.ndarray or type (beta_hat) is not np.ndarray:\n",
    "        sys.exit('Error: X y beta_hat deben ser de tipo numpy.ndarray')\n",
    "    if limit > 1 or limit < 0:\n",
    "        sys.exit('Error:  limit es un paramétro que debe estar entre 0 y 1')       \n",
    "    \n",
    "    mu = calc_mu(X,beta_hat)\n",
    "    yhat = mu\n",
    "    yhat[mu<limit] = 0\n",
    "    yhat[mu>=limit] = 1\n",
    "    return yhat\n",
    "\n",
    "def sigmoide(z):\n",
    "    '''\n",
    "    Función que devuelve el sigmoide de un vector\n",
    "        - Parámetros:\n",
    "            -- z (vec): vector numérico de m entradas\n",
    "        - Salidas\n",
    "            -- sig (vec): vector númerico de m entradas, cada entrada tiene \n",
    "                         un valor entre -1 y 1\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    if type(z) is not np.ndarray:\n",
    "        sys.exit('Error: la entrada debe ser de tipo numpy.ndarray')\n",
    "        \n",
    "    sig = 1/(1+ np.exp(-z))\n",
    "    \n",
    "    return sig\n",
    "    \n",
    "def calc_mu(X,beta):\n",
    "    '''\n",
    "    Función que calcula la media para una variable aleatoria con distribución bernoulli.\n",
    "        - Parámetros:\n",
    "            -- X (mat): matriz de mxp entradas\n",
    "            -- beta (vec): vector con p entradas\n",
    "        - Salidas\n",
    "            -- mu (vec): vector de m entradas\n",
    "    '''\n",
    "    a = np.matmul(beta,np.transpose(X))\n",
    "    mu = sigmoide(a)\n",
    "\n",
    "    return mu\n",
    "    \n",
    "def f(X,y,beta):\n",
    "    '''\n",
    "    \n",
    "    Función que computa la log-verosimilitud negativa\n",
    "    \n",
    "        - Parámetros:\n",
    "    \n",
    "            -- X (mat): matriz de mxp entradas\n",
    "\n",
    "            -- y (vec): vector de de m entradas de la variable output\n",
    "\n",
    "            -- beta (vec): vector de p entradas\n",
    "\n",
    "        - Salidas\n",
    "    \n",
    "            -- lvn (int): log-verosimilitud negativa\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "    if beta.shape[0]!= p:\n",
    "        sys.exit('Error:  El número de columnas de X debe ser igual al número de entradas del vector beta.')\n",
    "\n",
    "    prob = calc_mu(X,beta)\n",
    "    # Log-verosimilitud negativa \n",
    "    lvn = -sum(y*np.log(prob)+(1-y)*(np.log(1-prob)))\n",
    "    return lvn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por la restricciones de uso de la base de datos de entrenamiento original (además de una serie de requerimientos protocolares como contar con la aprobación de un Comité de Ética Independiente), optamos por trabajar con una de las dos bases de datos que los autores emplearon para validar sus modelos: KGH. La base de datos en mención, consta de $106$ casos positivos  de  pacientes  con  ébola  y  un  case fatality rate global por encima del setenta por ciento.  Originalmente,  previo  al tratamiento de los datos, la base tenía únicamente $44$ registros de triaje, $58$ registros de carga viral, con un total de 78 valores faltantes en todo el data set. Para  harmonizar  los  datos,  los  autores  transformaron  la  carga  viral  en  CT,  conforme  con  la curva estándar qPCR:\n",
    "\n",
    "$$log_{(carga \\; viral)} = m*CT + c_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosotros, para fines del presente trabajo, empleamos una de las versiones imputadas de esta base de datos, dispuesta en el siguiente sitio: [ebola-imc-public](https://github.com/dapivei/ebola-imc-public/blob/master/data/kenema/test/pres-kgh/imputation-50.csv), misma que cuenta con $11$ variables: la variable output, $y_{i}$ asociada a la supervivencia o no del paciente ${i}$ con virus del ébola, y ${j}$ variables explicativas asociadas, $x_{i,j}$. Los regresores escogidos son aquellos que, conforme con nuestra principal referencia, son buenos predictores de la probabilidad de muerte o no de un paciente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Tipo| Nombre|Descripción|\n",
    "|---| --- | --- |\n",
    "|Variable Numérica| CT |El cycle threshold (CT) es una variable que se calcula a partir de una relación médica bien conocida (qPCR) y la carga viral (una expresión númerica de la cantidad de virus dado un volúmen de fluido que normalmente se correlaciona con la severidad de una infección viral activa).|\n",
    "|Variable Numérica|TEMP|Temperatura corporal del paciente. Toma valores de $36$ a $39.9$.|\n",
    "|Variable Numérica|_AGE_ |Edad del paciente. Toma valores de $1$ a $73$.|\n",
    "|Variable Categórica |_HEADCH_ | Presencia o no dolores de cabeza. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no dolores de cabeza.|\n",
    "|Variable Categórica |  _BLEED_ | Presencia o no de sangrado. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no sangrado. |\n",
    "|Variable Categórica |  _DIARR_ | Presencia o no de diarrea. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no diarrea.|\n",
    "|Variable Categórica | _VOMIT_ | Dificultad para comer, conocido como disfagia, término técnico para describir el síntoma consistente en dificultad para la deglución (problemaspara  tragar).   Esta  dificultad  suele  ir  acompañada  de  dolores,  a  veces lancinantes (disfagia dolorosa u odinofagia .  Toma valores valores $1$ o $0$, dependiendo de si el paciente presenta o no de disfacia\n",
    "|Variable Categórica | _PABD*_ | Presencia o no de PADB.\n",
    "|Variable Categórica |_WEAK_ | Presencia o no de debilidad o fatiga general.|\n",
    "|Variable Categórica |_JAUN_ |Condición  en la cuál la piel, los ojos y los miembros mucosos que vuelven amarillos debido a altos niveles de bilirubina. Toma valores valores $0$ o $1$, dependiendo de si el paciente presenta o no ictericia.|\n",
    "|Variable Categórica |_OUT_| Muerte o no muerte del paciente.  Toma valores $1$ o $0$.  Dependiendo desi el paciente muere o no muere.|\n",
    "\n",
    "\n",
    "*: _PABD_ se refiere a Donación de sangre autóloga -personas en donde los trasplantes y las transfusiones la misma persona es a la vez donante y receptora- preoperatoria, Preoperative Autologous Blood Donation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación y exploración del conjunto de datos\n",
    "\n",
    "En esta sección se importa y transforma los datos, con el fin de obtener el conjunto $\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/afcarl/ebola-imc-public/master/data/kenema/test/pres-kgh/imputation-50.csv\"\n",
    "df_raw=pd.read_csv(url,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>JAUN</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28.652450</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25.736016</td>\n",
       "      <td>45.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20.747653</td>\n",
       "      <td>65.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>22.736993</td>\n",
       "      <td>44.0</td>\n",
       "      <td>38.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OUT         CT   AGE  TEMP  HEADCH  BLEED  DIARR  JAUN  VOMIT  PABD  WEAK\n",
       "0    1  28.652450  42.0  36.3       0      0      1     0      0     1     1\n",
       "1    1  25.736016  45.0  36.5       1      0      1     0      0     1     1\n",
       "2    1  20.747653  65.0  38.0       1      0      0     0      0     0     0\n",
       "3    1  22.736993  44.0  38.6       1      0      0     0      0     0     1\n",
       "4    1  20.846284  11.0  38.4       1      0      0     0      1     0     1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()\n",
    "# df[df.isnull().any(axis=1)] - no hay NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT         int64\n",
       "CT        float64\n",
       "AGE       float64\n",
       "TEMP      float64\n",
       "HEADCH      int64\n",
       "BLEED       int64\n",
       "DIARR       int64\n",
       "JAUN        int64\n",
       "VOMIT       int64\n",
       "PABD        int64\n",
       "WEAK        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificar tipo de variables \n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>JAUN</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764151</td>\n",
       "      <td>25.720411</td>\n",
       "      <td>34.102170</td>\n",
       "      <td>37.256604</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.405660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.426545</td>\n",
       "      <td>5.869164</td>\n",
       "      <td>17.382844</td>\n",
       "      <td>1.030767</td>\n",
       "      <td>0.491436</td>\n",
       "      <td>0.249528</td>\n",
       "      <td>0.493352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407477</td>\n",
       "      <td>0.447916</td>\n",
       "      <td>0.502375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.149857</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.236301</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.680924</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>38.225000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.799999</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>39.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              OUT          CT         AGE        TEMP      HEADCH       BLEED  \\\n",
       "count  106.000000  106.000000  106.000000  106.000000  106.000000  106.000000   \n",
       "mean     0.764151   25.720411   34.102170   37.256604    0.603774    0.066038   \n",
       "std      0.426545    5.869164   17.382844    1.030767    0.491436    0.249528   \n",
       "min      0.000000   12.100000    0.830000   36.000000    0.000000    0.000000   \n",
       "25%      1.000000   22.149857   22.000000   36.300000    0.000000    0.000000   \n",
       "50%      1.000000   25.236301   35.500000   37.250000    1.000000    0.000000   \n",
       "75%      1.000000   28.680924   45.000000   38.225000    1.000000    0.000000   \n",
       "max      1.000000   39.799999   80.000000   39.900000    1.000000    1.000000   \n",
       "\n",
       "            DIARR   JAUN       VOMIT        PABD        WEAK  \n",
       "count  106.000000  106.0  106.000000  106.000000  106.000000  \n",
       "mean     0.405660    0.0    0.207547    0.273585    0.500000  \n",
       "std      0.493352    0.0    0.407477    0.447916    0.502375  \n",
       "min      0.000000    0.0    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.0    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.0    0.000000    0.000000    0.500000  \n",
       "75%      1.000000    0.0    0.000000    1.000000    1.000000  \n",
       "max      1.000000    0.0    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resumen de las variables\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT       category\n",
       "CT         float64\n",
       "AGE        float64\n",
       "TEMP       float64\n",
       "HEADCH    category\n",
       "BLEED     category\n",
       "DIARR     category\n",
       "JAUN      category\n",
       "VOMIT     category\n",
       "PABD      category\n",
       "WEAK      category\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_cat = df_raw.copy()\n",
    "\n",
    "cat_vars = ['OUT', 'HEADCH', 'BLEED', 'DIARR', 'JAUN', 'VOMIT',\n",
    "       'PABD', 'WEAK']\n",
    "for var in cat_vars:\n",
    "    df_raw_cat[var] = df_raw_cat[var].astype('category')\n",
    "df_raw_cat.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.720411</td>\n",
       "      <td>34.102170</td>\n",
       "      <td>37.256604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.869164</td>\n",
       "      <td>17.382844</td>\n",
       "      <td>1.030767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.149857</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.236301</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>37.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.680924</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>38.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.799999</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>39.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CT         AGE        TEMP\n",
       "count  106.000000  106.000000  106.000000\n",
       "mean    25.720411   34.102170   37.256604\n",
       "std      5.869164   17.382844    1.030767\n",
       "min     12.100000    0.830000   36.000000\n",
       "25%     22.149857   22.000000   36.300000\n",
       "50%     25.236301   35.500000   37.250000\n",
       "75%     28.680924   45.000000   38.225000\n",
       "max     39.799999   80.000000   39.900000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>JAUN</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>99</td>\n",
       "      <td>63</td>\n",
       "      <td>106</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        OUT  HEADCH  BLEED  DIARR  JAUN  VOMIT  PABD  WEAK\n",
       "count   106     106    106    106   106    106   106   106\n",
       "unique    2       2      2      2     1      2     2     2\n",
       "top       1       1      0      0     0      0     0     1\n",
       "freq     81      64     99     63   106     84    77    53"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe categorical data\n",
    "df_proc_cat = df_raw_cat.select_dtypes(include=['category']).copy()\n",
    "df_proc_cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2YAAADQCAYAAABsrnILAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQRUlEQVR4nO3dbbCtZVkH8P/FW+gYA+pRkYOBSYyYhXoGmfxSmHW0ElIqmFRKij5I40th6KSp6QxmSozaFJMKNCUyaoKOoxlBjhOih8TkZRgQGTyBcEgdfEmdg1cf9kI3h80568BZ6157799vZs9ez/08z3qu/WHNNf99P8+9qrsDAADAOHuNLgAAAGC9E8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8xgkKraWFUXV9WNVfXlqjqnqvab7Pu9qnrXDsdfXlWbqurKqrq6qm6tqm2T11dX1WEPsZ7XVNVNVXVDVf3qQ3kvABbfIvWhqnpUVV1WVd/e8bqwXghmMEBVVZIPJ/lIdx+R5GeSPCLJW3Z1bnc/s7uPTvL6JB/o7qMnP7c8hHqOSnJSkqck2Zzkb6tq7wf7fgAstkXrQ0m+l+R1Sf70IbwHrGqCGYxxXJLvdff7kqS770nyyiQvraqHD6jn+CQXdvf3u/srSW5KcsyAOgCYj4XqQ939ne7+TJYCGqxL+4wuANappyS5avlAd99dVbcmedKeuEBVnZ3kl1bYdWF3n7XD2CFJPrtse+tkDIC1adH6EKx7ghmMUUl6J+Mr7ctOxu9/YPcrd7OeB30tAFadRetDsO4JZjDGtUleuHygqg5IcmiSLyf5qSQH7XDOI5PcNe0FdvM/lVsn177XxiS3TXstAFadRetDsO4JZjDGpUnOqqqXdPcFk4U23p7kvO7+blV9Psm7qupx3f21qtqU5CeSfHXaC+zmfyovSfLPVfWOJI9PckSSz+3G+QCsLovWh2DdE8xggO7uqvrNLK1++LosLcTz8SSvney/o6penuTjVbVXkm8nObm7fzijeq6tqouSXJdke5KXTR4EB2ANWrQ+lCRVdUuSA5LsV1UnJPmV7r5uVteDRVPdHiMBAAAYyXL5AAAAgwlmAAAAgwlmAAAAgwlmAAAAg62KVRk3b97cn/jEJ0aXAcDqt9KXqe+SPgTAHrRiL1oVM2Z33TX1dxkCwB6nDwEwa6simAEAAKxlghkAAMBgghkAAMBgghkAAMBgghkAAMBgghkAAMBgq+J7zABgrXnGGReMLoF17qq3vWR0CcAyZswAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGm3kwq6q9q+oLVfWxyfbhVXVlVd1YVR+oqv1mXQMAAMAim8eM2cuTXL9s+61Jzu7uI5J8I8mpc6gBAABgYc00mFXVxiS/luQfJtuV5LgkH5wccn6SE2ZZAwAAwKKb9YzZ3yR5dZIfTrYfleSb3b19sr01ySErnVhVp1XVlqrasm3bthmXCQD3pQ8BME8zC2ZV9etJ7uzuq5YPr3Bor3R+d5/b3Zu6e9OGDRtmUiMAPBB9CIB52meG7/2sJM+vqucl2T/JAVmaQTuwqvaZzJptTHLbDGsAAABYeDObMevu13T3xu4+LMlJSf69u383yWVJTpwcdkqSi2dVAwAAwGow4nvM/izJq6rqpiw9c/aeATUAAAAsjFneyvgj3X15kssnr29Ocsw8rgsAALAajJgxAwAAYBnBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYDDBDAAAYLC5fI8ZAADsrlvf9NTRJbDOPeH1X5rbtcyYAQAADCaYAQAADCaYAQAADCaYAQAADCaYAQAADCaYAQAADCaYAQAADCaYAQAADCaYAQAADCaYAQAADCaYAQAADCaYAQAADCaYAQAADCaYAQAADCaYAQAADDazYFZV+1fV56rqi1V1bVW9cTJ+eFVdWVU3VtUHqmq/WdUAAACwGsxyxuz7SY7r7p9PcnSSzVV1bJK3Jjm7u49I8o0kp86wBgAAgIU3s2DWS7492dx38tNJjkvywcn4+UlOmFUNAAAAq8FMnzGrqr2r6uokdyb5VJIvJ/lmd2+fHLI1ySEPcO5pVbWlqrZs27ZtlmUCwP3oQwDM00yDWXff091HJ9mY5JgkT17psAc499zu3tTdmzZs2DDLMgHgfvQhAOZpLqsydvc3k1ye5NgkB1bVPpNdG5PcNo8aAAAAFtUsV2XcUFUHTl4/LMkvJ7k+yWVJTpwcdkqSi2dVAwAAwGqwz64PedAOTnJ+Ve2dpQB4UXd/rKquS3JhVb05yReSvGeGNQAAACy8mQWz7v7vJE9bYfzmLD1vBgAAQOb0jBkAAAAPTDADAAAYTDADAAAYbKpgVlWXTjMGAADA7tvp4h9VtX+Shyd5dFUdlKQmuw5I8vgZ1wYAALAu7GpVxj9K8ooshbCr8uNgdneSd8+wLgAAgHVjp8Gsu89Jck5V/XF3v3NONQEAAKwrU32PWXe/s6p+Iclhy8/p7gtmVBcAAMC6MVUwq6p/TPLTSa5Ocs9kuJMIZgAAAA/RVMEsyaYkR3V3z7IYAACA9Wja7zG7JsnjZlkIAADAejXtjNmjk1xXVZ9L8v17B7v7+TOpCgAAYB2ZNpi9YZZFAAAArGfTrsr4H7MuBAAAYL2adlXGb2VpFcYk2S/Jvkm+090HzKowAACA9WLaGbOfXL5dVSckOWYmFQEAAKwz067KeB/d/ZEkx+3hWgAAANalaW9lfMGyzb2y9L1mvtMMAABgD5h2VcbfWPZ6e5Jbkhy/x6sBAABYh6Z9xuz3Z10IAADAejXVM2ZVtbGq/qWq7qyqO6rqQ1W1cdbFAQAArAfTLv7xviSXJHl8kkOSfHQyBgAAwEM0bTDb0N3v6+7tk5/zkmzY2QlVdWhVXVZV11fVtVX18sn4I6vqU1V14+T3QQ/xbwAAAFjVpg1md1XVi6pq78nPi5L87y7O2Z7kT7r7yUmOTfKyqjoqyZlJLu3uI5JcOtkGAABYt6YNZi9N8ttJvpbk9iQnJtnpgiDdfXt3/9fk9beSXJ+l2yCPT3L+5LDzk5yw+2UDAACsHdMul/+XSU7p7m8kS7cjJvnrLAW2Xaqqw5I8LcmVSR7b3bcnS+Gtqh6zmzUDAACsKdPOmP3cvaEsSbr761kKWrtUVY9I8qEkr+juu6ctrKpOq6otVbVl27Zt054GAHuEPgTAPE0bzPZavkjHZMZsl7NtVbVvlkLZP3X3hyfDd1TVwZP9Bye5c6Vzu/vc7t7U3Zs2bNjpOiMAsMfpQwDM07S3Mr49yX9W1QeTdJaeN3vLzk6oqkryniTXd/c7lu26JMkpSc6a/L54d4sGAABYS6YKZt19QVVtSXJckkrygu6+bhenPSvJi5N8qaqunoy9NkuB7KKqOjXJrUl+60FVDgAAsEZMO2OWSRDbVRhbfvxnshTiVvLsad8HAABgrZv2GTMAAABmZOoZs7XkGWdcMLoEyFVve8noEgAAWBBmzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAYTzAAAAAabWTCrqvdW1Z1Vdc2ysUdW1aeq6sbJ74NmdX0AAIDVYpYzZucl2bzD2JlJLu3uI5JcOtkGAABY12YWzLr700m+vsPw8UnOn7w+P8kJs7o+AADAajHvZ8we2923J8nk92Me6MCqOq2qtlTVlm3bts2tQABI9CEA5mthF//o7nO7e1N3b9qwYcPocgBYZ/QhAOZp3sHsjqo6OEkmv++c8/UBAAAWzryD2SVJTpm8PiXJxXO+PgAAwMKZ5XL5709yRZIjq2prVZ2a5Kwkz6mqG5M8Z7INAACwru0zqzfu7pMfYNezZ3VNAACA1WhhF/8AAABYLwQzAACAwQQzAACAwQQzAACAwWa2+Aewut36pqeOLgHyhNd/aXQJADAXZswAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGGxLMqmpzVd1QVTdV1ZkjagAAAFgUcw9mVbV3kncneW6So5KcXFVHzbsOAACARTFixuyYJDd1983d/YMkFyY5fkAdAAAAC6G6e74XrDoxyebu/oPJ9ouTPLO7T9/huNOSnDbZPDLJDXMtlF15dJK7RhcBC87nZPHc1d2bpzlQH1p4Pl8wHZ+VxbNiL9pnQCG1wtj90mF3n5vk3NmXw4NRVVu6e9PoOmCR+ZysbvrQYvP5gun4rKweI25l3Jrk0GXbG5PcNqAOAACAhTAimH0+yRFVdXhV7ZfkpCSXDKgDAABgIcz9Vsbu3l5Vpyf5ZJK9k7y3u6+ddx08ZG7vgV3zOYHZ8fmC6fisrBJzX/wDAACA+xryBdMAAAD8mGAGAAAwmGDGbqmqzVV1Q1XdVFVnjq4HFlFVvbeq7qyqa0bXAmuRXgQ7pw+tToIZU6uqvZO8O8lzkxyV5OSqOmpsVbCQzksy1ZcYA7tHL4KpnBd9aNURzNgdxyS5qbtv7u4fJLkwyfGDa4KF092fTvL10XXAGqUXwS7oQ6uTYMbuOCTJV5dtb52MAcC86EXAmiSYsTtqhTHftwDAPOlFwJokmLE7tiY5dNn2xiS3DaoFgPVJLwLWJMGM3fH5JEdU1eFVtV+Sk5JcMrgmANYXvQhYkwQzptbd25OcnuSTSa5PclF3Xzu2Klg8VfX+JFckObKqtlbVqaNrgrVCL4Jd04dWp+p2WzYAAMBIZswAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8xggVTVPVV1dVVdW1VfrKpXVdVek32/WFUf2+H4i6vqih3G3lBV/zN5n+uq6uRl+86rqq9M9n2xqp49n78MgNVCL4IxBDNYLP/X3Ud391OSPCfJ85L8xUoHVtWBSZ6e5MCqOnyH3Wd399FJjk/y91W177J9Z0z2vSLJ3+3xvwCA1U4vggEEM1hQ3X1nktOSnF5VtcIhL0zy0SQXJjnpAd7jxiTfTXLQCruvSHLInqkWgLVIL4L5EcxggXX3zVn6nD5mhd0nJ3n/5OfkFfanqp6e5MZJY93R5iQf2UOlArBG6UUwH/uMLgDYpfv9h7KqHpvkSUk+091dVdur6me7+5rJIa+sqj9M8sQsNb3l3lZVf5WlBnvsLAsHYM3Qi2DGzJjBAquqJya5J8mO/2X8nSzdEvKVqrolyWG57y0kZ3f3kZPjLqiq/ZftOyNLjfTPk5w/m8oBWCv0IpgPwQwWVFVtyNID0e/q7t5h98lJNnf3Yd19WJJnZIV7+7v7w0m2JDllh/EfJjknyV5V9aszKB+ANUAvgvkRzGCxPOzeJYqT/FuSf03yxuUHVNVhSZ6Q5LP3jnX3V5LcXVXPXOE935TkR0sdLzunk7w5yav35B8AwKqnF8EAdf9/fgAAADBPZswAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAGE8wAAAAG+3+C36e0ItPv5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_vars = cat_vars[1:]\n",
    "\n",
    "for i, col_val in enumerate(cat_vars):\n",
    "    sns.catplot(x = col_val, y = None, hue= None, col=\"OUT\",\n",
    "                data=df_proc_cat, kind=\"count\",\n",
    "                height=3, aspect=2);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algunas observaciones sobre los datos**\n",
    "\n",
    "- El case fatality rate (OUT) de nuestra base de datos se sitúa en 76 por ciento. Es decir, del total de pacientes con ébola, 81 murieron.\n",
    "\n",
    "- Para este conjunto de datos la variable `JAUN` no tiene variabilidad, por lo tanto no es una variable, y se omite.\n",
    "\n",
    "\n",
    "Dado lo anterior, se ajusta el set de datos:\n",
    "\n",
    "- Se crean 3 grupos de edades, utilizando el percetil 25 (22 años), percentil 50 (36 años) y percentil 75 (45 años).\n",
    "\n",
    "- Se elimina la columna `JAUN`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones al conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT            int64\n",
       "CT           float64\n",
       "AGE          float64\n",
       "TEMP         float64\n",
       "HEADCH         int64\n",
       "BLEED          int64\n",
       "DIARR          int64\n",
       "JAUN           int64\n",
       "VOMIT          int64\n",
       "PABD           int64\n",
       "WEAK           int64\n",
       "INTER_AGE     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ajustes en df_raw \n",
    "df_proc = df_raw\n",
    "df_proc['INTER_AGE'] = \"NA\"\n",
    "\n",
    "df_proc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OUT             int64\n",
       "CT            float64\n",
       "TEMP          float64\n",
       "HEADCH          int64\n",
       "BLEED           int64\n",
       "DIARR           int64\n",
       "VOMIT           int64\n",
       "PABD            int64\n",
       "WEAK            int64\n",
       "hasta22       float64\n",
       "entre23y36    float64\n",
       "entre37y45    float64\n",
       "mayor45       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ajustes en df_raw \n",
    "df_proc = df_raw\n",
    "\n",
    "# para la variable edad se crean cuatro categorías\n",
    "age_p25 = math.ceil(df_proc['AGE'].quantile(.25))\n",
    "age_p50 = math.ceil(df_proc['AGE'].quantile(.50))\n",
    "age_p75 = math.ceil(df_proc['AGE'].quantile(.75))\n",
    "\n",
    "df_proc['INTER_AGE'] = \"NA\"\n",
    "df_proc.loc[(df_proc['AGE'] <= age_p25), 'INTER_AGE'] = 1\n",
    "df_proc.loc[(df_proc['AGE'] > age_p25) & (df_proc['AGE'] <= age_p50), 'INTER_AGE'] = 2\n",
    "df_proc.loc[(df_proc['AGE'] > age_p50) & (df_proc['AGE'] <= age_p75), 'INTER_AGE'] = 3\n",
    "df_proc.loc[(df_proc['AGE'] > age_p75), 'INTER_AGE'] = 4\n",
    "\n",
    "## one hot encoding\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(df_proc[['INTER_AGE']]).toarray())\n",
    "enc_df = enc_df.rename(columns={0: f\"hasta{age_p25}\", 1: f\"entre{age_p25+1}y{age_p50}\", 2: f\"entre{age_p50+1}y{age_p75}\", 3:f\"mayor{age_p75}\"})\n",
    "# merge with main df bridge_df on key values\n",
    "df_proc = df_proc.join(enc_df)\n",
    "    \n",
    "# se omiten las variables JAUN, AGE, INTER_AGE\n",
    "del_vars = [\"JAUN\", \"AGE\", \"INTER_AGE\"]\n",
    "for var in del_vars:\n",
    "    df_proc = df_proc.drop(var, axis=1)    \n",
    "    \n",
    "# se comprueban los tipos de variable\n",
    "df_proc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OUT</th>\n",
       "      <th>CT</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>HEADCH</th>\n",
       "      <th>BLEED</th>\n",
       "      <th>DIARR</th>\n",
       "      <th>VOMIT</th>\n",
       "      <th>PABD</th>\n",
       "      <th>WEAK</th>\n",
       "      <th>hasta22</th>\n",
       "      <th>entre23y36</th>\n",
       "      <th>entre37y45</th>\n",
       "      <th>mayor45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28.652450</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25.736016</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20.747653</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>22.736993</td>\n",
       "      <td>38.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>38.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>24.191797</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>20.846284</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>38.816561</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>21.960294</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>26.221948</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OUT         CT  TEMP  HEADCH  BLEED  DIARR  VOMIT  PABD  WEAK  hasta22  \\\n",
       "0      1  28.652450  36.3       0      0      1      0     1     1      0.0   \n",
       "1      1  25.736016  36.5       1      0      1      0     1     1      0.0   \n",
       "2      1  20.747653  38.0       1      0      0      0     0     0      0.0   \n",
       "3      1  22.736993  38.6       1      0      0      0     0     1      0.0   \n",
       "4      1  20.846284  38.4       1      0      0      1     0     1      1.0   \n",
       "..   ...        ...   ...     ...    ...    ...    ...   ...   ...      ...   \n",
       "101    1  24.191797  36.4       0      0      1      1     1     1      0.0   \n",
       "102    1  20.846284  38.4       0      0      0      1     0     1      0.0   \n",
       "103    0  38.816561  36.0       0      0      0      0     0     0      1.0   \n",
       "104    1  21.960294  36.4       0      0      0      0     0     0      0.0   \n",
       "105    0  26.221948  36.5       1      0      0      0     0     0      0.0   \n",
       "\n",
       "     entre23y36  entre37y45  mayor45  \n",
       "0           0.0         1.0      0.0  \n",
       "1           0.0         1.0      0.0  \n",
       "2           0.0         0.0      1.0  \n",
       "3           0.0         1.0      0.0  \n",
       "4           0.0         0.0      0.0  \n",
       "..          ...         ...      ...  \n",
       "101         0.0         1.0      0.0  \n",
       "102         1.0         0.0      0.0  \n",
       "103         0.0         0.0      0.0  \n",
       "104         1.0         0.0      0.0  \n",
       "105         0.0         1.0      0.0  \n",
       "\n",
       "[106 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planteamiento del problema de regresión\n",
    "\n",
    "Para los algoritmos a utilizar, es imprecindible la utilización del gradiente y la matriz hessiana asoaciados a $LVN(\\beta)$, los cuales se definen a continuación:\n",
    "\n",
    "$$\n",
    "\\nabla LVN=\\frac{d}{d\\boldsymbol{\\beta}}f(\\boldsymbol{\\beta})=\\sum_{i}(\\mu_{i}-y_{i})x_{i}=X^{T}(\\mu-y)\\label{eq:gradiente}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla^{2}LVN=\\frac{d}{d\\boldsymbol{\\beta}}g(\\boldsymbol{\\beta})^{T}=\\sum\\left(\\nabla_{\\beta}\\mu_{i}\\right)x_{i}^{T}=\\sum\\mu_{i}(1-\\mu_{i})x_{i}x_{i}^{T}=\\boldsymbol{X}^{T}\\boldsymbol{S}\\boldsymbol{X}\\label{eq:hessiana}\n",
    "$$\n",
    "\n",
    "donde $\\boldsymbol{S}\\triangleq diag(\\mu_{i}(1-\\mu_{i}))$. Adicionalmente, como resalta Murphy (2012), dado que $\\boldsymbol{H}$ es positiva definida, entonces $LVN(\\beta)$ tiene un mínimo global que puede ser alcanzable utilizando métodos de optimización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_f(X,y,beta):\n",
    "    '''\n",
    "    Función que calcula el gradiente asociado la log-verosimilitud negativa del \n",
    "    problema de regresión logística\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - beta (vec): vector de p entradas\n",
    "        ** Salidas:\n",
    "            - grad (vec): vector de m entradas\n",
    "    '''\n",
    "        \n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "    if beta.shape[0]!= p:\n",
    "        sys.exit('Error:  El número de columnas de X debe ser igual al número de entradas del vector beta.')\n",
    "\n",
    "    mu = calc_mu(X,beta)    \n",
    "    grad = np.matmul(np.transpose(X), mu-y)    \n",
    "    return grad\n",
    "\n",
    "\n",
    "def hessiana_f(X,y,beta):\n",
    "    '''\n",
    "    Función que calcula la matriz Hessiana asociada a la log-verosimilitud negativa del \n",
    "    problema de regresión logística\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - beta (vec): vector de p entradas \n",
    "        ** Salidas\n",
    "            - hes (vec): vector de m entradas\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "    if beta.shape[0]!= p:\n",
    "        sys.exit('Error:  El número de columnas de X debe ser igual al número de entradas del vector beta.')\n",
    "\n",
    "    mu = calc_mu(X,beta)\n",
    "    S = np.diag(mu*(1-mu))\n",
    "    hes = np.matmul(np.transpose(X),np.matmul(S,X))\n",
    "    return hes\n",
    "\n",
    "def normalize(x):\n",
    "    '''\n",
    "    Función que normaliza un vector\n",
    "        ** Parametros:\n",
    "            - x: vector a normalizar\n",
    "        ** Salidas:\n",
    "            - norm : vector x normalizado\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    if type(x) is not np.ndarray:\n",
    "        sys.exit('Error: la entrada debe ser de tipo numpy.ndarray')\n",
    "         \n",
    "    norm = x/np.sqrt(sum(x*x))\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de máximo descenso\n",
    "\n",
    "El método de máximo descenso es el método de búsqueda de línea más\n",
    "sencillo, y plantea que la forma de encontrar el mínimo de una función\n",
    "$f(\\beta_{k})$ es por medio de la búsqueda iterativa de $\\beta_{k}$\n",
    "siguiendo la dirección negativa del gradiente asociado, i-.e. $-p^{T}\\nabla f_{k}$ (donde $\\nabla f_{k}$ es el gradiente de la función $f$ con respecto\n",
    "a $\\beta_{k}$. ). Cabe anotar que, como es resaltado por Nocedal, este supuesto está\n",
    "basado en el Teorema de Taylor, el cual establece que:\n",
    "\n",
    "$$\n",
    "f(\\beta_{k}+\\alpha_k p)\\approx f(\\beta_{k})+\\alpha_k p^{T}\\nabla f_{k}\n",
    "$$\n",
    "\n",
    "donde $\\alpha_k$ es el paso del descenso o tasa de aprendizaje en la iteración $k$. Así, en la ecuación anterior\n",
    "la función $f$ disminuye a una tasa de paso, multiplicada por el\n",
    "gradiente y el paso, y una dirección $p$, es decir: $p^{T}\\nabla f_{k}$.\n",
    "Por otro lado, dado que el gradiente es negativo se cumple que:\n",
    "\n",
    "$$\n",
    "f(\\beta_{k}+\\alpha_k p)<f(\\beta_{k})\\label{eq:condicion_desc}\n",
    "$$\n",
    "\n",
    "\n",
    "Adicional a lo anterior, es de vital importancia adicionar un componente\n",
    "al problema, correspondiente a la elección de la tasa de aprendizaje,\n",
    "$\\alpha$, en la medida que, valores muy altos de la misma, pueden\n",
    "impedir que haya convergencia hacia el mínimo y el algoritmo se estanque,\n",
    "o que su convergencia sea demasiado lenta.\n",
    "\n",
    "Así, como es presentado por Nocedal & Wright (2006) y Murphy (2012), el último componente\n",
    "que se requiere adicionar al problema de optimización planteado, y\n",
    "que a su vez lo convierte en un método de búsqueda de línea o minimización\n",
    "de línea (line search), es elegir $\\alpha$\n",
    "tal que se minimice:\n",
    "\n",
    "$$\n",
    "\\varphi(\\alpha)=f(\\beta_{k}+\\alpha_k p)\\label{eq:cond_linesearch}\n",
    "$$\n",
    "\n",
    "En el método de descenso de gradiente, la forma de\n",
    "actualizar el vector de parámetros es como se define a continuación:\n",
    "\n",
    "$$\n",
    "\\beta_{k+1}=\\beta_{k}-\\alpha\\nabla f_{k}\\label{eq:steepest_descent}\n",
    "$$\n",
    "\n",
    "De esta forma dado un $\\beta_{0}$ inicial elegido aleatoriamente,\n",
    "la actualización de los pesos continúa hasta que $\\|\\nabla f_{k}\\|\\approx0$ \n",
    "o hasta que un número definido de iteraciones se alcance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de Newton\n",
    "\n",
    "El método de Newton es parte la familia de métodos de optimización\n",
    "de segundo orden, en la medida que tienen en cuenta la curvatura de\n",
    "la función a optimizar, la cual es incorporada por la matriz Hessiana,\n",
    "$\\nabla^{2}f$. Lo anterior, implica un mayor costo en términos de\n",
    "cómputo con respecto al algoritmo de máximo descenso. Sin embargo,\n",
    "la existencia de dicha curvatura, en la mayoría de los problemas,\n",
    "permite lograr niveles de convergencia mucho más rápido. \n",
    "\n",
    "En particular, en este método, la forma de actualizar el vector de\n",
    "parámetros es de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\beta_{k+1}=\\beta_{k}-\\alpha_{k}\\nabla^{2}f_{k}^{-1}\\nabla f_{k}\\label{eq:act_newton}\n",
    "$$\n",
    "\n",
    "### Método BFGS\n",
    "\n",
    "El método de propuesto por Broyden, Fletcher, Goldfarb and Shanno\n",
    "(BFGS) es un algoritmo quasi-newtoniano que aborda una solución a\n",
    "los problemas en los cuales es muy costoso el cómputo de la matriz\n",
    "Hessiana de $f_{k}$. Como es descrito por Murphy, este método iterativamente\n",
    "computa una aproximación de $\\nabla^{2}f_{k}$ a partir del gradiente,\n",
    "$\\nabla f_{k}$.\n",
    "\n",
    "Dado lo anterior, la aproximación de la matriz Hessiana se define\n",
    "como $H_{k}\\approx\\nabla^{2}f_{k}$, y se calcula con una función\n",
    "de rango 2 dada por:\n",
    "\n",
    "\\begin{align}\n",
    "H_{k+1} & =H_{k}+\\frac{w_{k}(w_{k})^{T}}{(w_{k})^{T}z_{k}}-\\frac{H_{k}z_{k}(H_{k}z_{k})^{T}}{(z_{k})^{T}H_{k}z_{k}}\\label{eq:H}\\\\\n",
    "z_{k} & =\\beta_{k+1}-\\beta_{k}\\label{z}\\\\\n",
    "w_{k} & =\\nabla f_{k+1}-\\nabla f_{k}\\label{eq:w}\n",
    "\\end{align}\n",
    "\n",
    "Como es mencionado por Murphy (2012), por lo general el algoritmo se inicializa\n",
    "con $H_{o}=I$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent_direction(X, y, beta, method=\"max\",H=None):\n",
    "    '''\n",
    "    Función que devuelve vector normalizado (px1) que apunta en la direccion de decenso\n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - beta (vec float64): vector de entradas a optimizar\n",
    "            - method (str): método que determina la dirección de descenso\n",
    "    \n",
    "                    --Opciones:\n",
    "                            --- max: método de descenso\n",
    "                            --- newton: método de Newton\n",
    "                            --- bfsg: metodo bfsg\n",
    "            - H (mat pxp): Parámetro para la dirección de decenso del metodo bfgs\n",
    "    \n",
    "        ** Salidas\n",
    "            - pk (vec): vector normalizado con la direccion del paso\n",
    "    '''\n",
    "    if(method == \"max\"):\n",
    "        pk = gradiente_f(X,y,beta)\n",
    "    \n",
    "    elif(method == \"newton\"):\n",
    "        grad = gradiente_f(X,y,beta)\n",
    "        hess = hessiana_f(X,y,beta)\n",
    "        pk = np.linalg.solve(hess,grad)\n",
    "        \n",
    "    elif(method==\"bfsg\"):\n",
    "        # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "        if type(H) is not np.ndarray:\n",
    "            sys.exit('Error: H debe ser de tipo numpy.ndarray')\n",
    "        pk = np.matmul(H,gradiente_f(X,y,beta))\n",
    "                              \n",
    "    return - normalize(pk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_H(X,y,beta,beta_new=None,H=None):\n",
    "    '''\n",
    "    Función que actualiza los valores de la matriz H del metodo bfgs para cada iteracion\n",
    "        ** Parametros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - beta (array) - valor de cantidad a optimizar en la iteracion actual\n",
    "            - beta_new (array)- valore de la cantidad a optimizar despues de la actualizacion\n",
    "            - H (mat)- valor de la matriz H en la iteracion anterior\n",
    "        ** Salidas:\n",
    "            - H (mat): valor de la matriz para la siguiente iteracion       \n",
    "    '''\n",
    "    \n",
    "    w = gradiente_f(X,y,beta_new)- gradiente_f(X,y,beta)\n",
    "    z = beta_new-beta\n",
    "    Hz = np.matmul(H,z)\n",
    "    dotwz = np.dot(w,z)\n",
    "    dotzhz = np.dot(Hz,z)\n",
    "    H = H+(np.outer(w,w)/dotwz)-(np.outer(Hz,Hz)/dotzhz)\n",
    "   \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lr(X, y, beta, lr, pk, c1=10**(-4), tao=0.5, reset_lr=False):\n",
    "    '''\n",
    "    Función que calcula el tamaño del paso para cada iteración utilizando la condicion de armijo.\n",
    "    La tasa de aprendizaje minima es la que tenia en el paso anterior.\n",
    "    \n",
    "        ** Parámetros:\n",
    "        \n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - lr (float64): tasa de aprendizaje\n",
    "            - pk (array px1 float64): direccion de decenso\n",
    "            - c1 (float64) 0<c1<1: parametro de control\n",
    "            - tao (float64) 0<tao<1: parametro de decrecimiento de lr\n",
    "            \n",
    "        ** Salidas\n",
    "        \n",
    "            - lr (float64): tamaño de paso\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad    \n",
    "    if tao > 1 or tao < 0:\n",
    "        sys.exit('Error:  tao es un parámetro que debe estar entre 0 y 1')  \n",
    "    if c1 > 1 or c1 < 0:\n",
    "        sys.exit('Error:  c1 es un paramétro que debe estar entre 0 y 1') \n",
    "\n",
    "    # Inicializamos \n",
    "    tao = 0.9\n",
    "    max_iter = 100\n",
    "    iter = 0\n",
    "    \n",
    "    # Inicializa lr\n",
    "    if reset_lr==True: lr = 1\n",
    "\n",
    "    # Evaluaciones periódicas\n",
    "    grad = gradiente_f(X,y,beta)\n",
    "    eval_f = f(X,y, beta)\n",
    "    \n",
    "    # Primera iteracion\n",
    "    f_x =  f(X,y, beta + lr*pk) #en nocedal es phi(alpha)\n",
    "    f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) # en nocedal es l(alhpa)\n",
    "    \n",
    "    while ((f_x > f_x1) & (iter < max_iter)):\n",
    "        lr = lr*tao\n",
    "        f_x =  f(X,y, beta + lr*pk) \n",
    "        f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) \n",
    "        iter+=1\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba\n",
    "# prueba\n",
    "# No esta funcionando bien\n",
    "# Longitud de paso con condiciones completas de wolf\n",
    "\n",
    "def calc_lr_wolf(X, y, beta, lr, pk, c1=10**(-4), c2=0.9, tao=0.5, reset_lr=False):\n",
    "    '''\n",
    "    \n",
    "    Función que calcula el tamaño del paso para cada iteración utilizando la condicion de armijo.\n",
    "    \n",
    "    La tasa de aprendizaje minima es la que tenía en el paso anterior.\n",
    "    \n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - lr (float64): tasa de aprendizaje\n",
    "            - pk (array px1 float64): direccion de decenso\n",
    "            - c1 (float64) 0<c1<1: parametro de control\n",
    "            - tao (float64) 0<tao<1: parametro de decrecimiento de lr\n",
    "    \n",
    "        ** Salidas    \n",
    "            - lr (float64): tamaño de paso\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    if tao > 1 or tao < 0:\n",
    "        sys.exit('Error:  tao es un parámetro que debe estar entre 0 y 1')  \n",
    "    if c1 > 1 or c1 < 0:\n",
    "        sys.exit('Error:  c1 es un paramétro que debe estar entre 0 y 1') \n",
    "    #if pk >= 0 :\n",
    "    #    sys.exit('Error: pk debe ser negativo')\n",
    "        \n",
    "    # Inicializamos \n",
    "    tao = 0.5\n",
    "    max_iter = 50\n",
    "    iter = 0\n",
    "    \n",
    "    # Inicializa lr\n",
    "    if reset_lr==True: lr=1\n",
    "\n",
    "    # Evalauciones periodicas\n",
    "    grad = gradiente_f(X,y,beta)\n",
    "    eval_f = f(X,y, beta)\n",
    "    \n",
    "    # Primera iteracion\n",
    "    f_x =  f(X,y, beta + lr*pk) #en nocedal es phi(alpha)\n",
    "    f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) # en nocedal es l(alhpa)\n",
    "    \n",
    "    gf_x = np.dot(gradiente_f(X,y, beta+lr*pk) , pk)\n",
    "    gf_x1 = c2* np.dot(grad, pk)\n",
    "    \n",
    "    while ((f_x>f_x1) & (gf_x<gf_x1) & (iter<max_iter)):\n",
    "        lr =lr*tao\n",
    "        f_x =  f(X,y, beta + lr*pk) \n",
    "        f_x1 = eval_f + c1 * lr *  np.dot(grad,pk) \n",
    "        \n",
    "        gf_x = np.dot(gradiente_f(X,y, beta+lr*pk) , pk)\n",
    "        #gf_x1 = c2* np.dot(grad, pk)\n",
    "    \n",
    "        \n",
    "        iter+=1\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, lr=1, tol=10**(-7), max_iter=10**5, method=\"max\", reset_lr=False, verbose_n=1000):\n",
    "    '''\n",
    "    Función que devuelve vector de parámetros beta (px1) resultante del proceso\n",
    "    de optimización por descenso de gradiente\n",
    "    \n",
    "        ** Parámetros:\n",
    "            - X (mat): matriz de mxp entradas\n",
    "            - y (vec): vector de de m entradas de la variable output\n",
    "            - lr (float64): valor inicial de la tasa de aprendizaje\n",
    "            - tol (float64): criterio de convergencia\n",
    "            - max_iter (int): número máximo de iteraciones\n",
    "            - method (str): método que determina la dirección de descenso\n",
    "                Opciones:\n",
    "                    -- max: método de descenso\n",
    "                    -- newton: método de Newton\n",
    "                    -- bfsg\n",
    "        ** Salidas\n",
    "            - beta_new (vec): vector de p entradas con parámetros que minimizan la función de pérdida\n",
    "    '''\n",
    "    # imprime método\n",
    "    out.write(BOLD + \"=\"*65)\n",
    "    if (method==\"max\"):\n",
    "        out.write(BOLD + 'Método de máximo descenso')\n",
    "    elif (method==\"newton\"):\n",
    "        out.write(BOLD + 'Método de Newton')\n",
    "    elif (method==\"bfsg\"):\n",
    "        out.write(BOLD + 'Método de BFGS')\n",
    "    out.write(BOLD + \"=\"*65)\n",
    "    \n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "\n",
    "    \n",
    "    # Inicializa\n",
    "    iteraciones=0\n",
    "    H = None\n",
    "    dims = X.shape[1]\n",
    "    tol = tol*dims\n",
    "    \n",
    "    # Inicializamos beta aleatoria\n",
    "    beta = np.random.normal(1,3,dims)\n",
    "    if method ==\"bfsg\": H = np.identity(dims)\n",
    "    \n",
    "    # Primera iteracion\n",
    "    pk =  descent_direction(X, y, beta, method,H)\n",
    "    beta_new = beta + lr*pk\n",
    "    if method == \"bfsg\": H=calc_H(X,y,beta,beta_new,H) \n",
    "    \n",
    "    # Condición de paro.\n",
    "    while ((np.linalg.norm(gradiente_f(X,y,beta_new)) > tol) & (iteraciones < max_iter)):\n",
    "        iteraciones+=1 #contador de ciclo\n",
    "        \n",
    "        beta = beta_new\n",
    "        pk =  descent_direction(X,y,beta,method,H)\n",
    "        lr = calc_lr(X, y, beta, lr, pk, reset_lr = reset_lr)\n",
    "        \n",
    "        beta_new = beta + lr*pk\n",
    "        \n",
    "        if method == \"bfsg\": H=calc_H(X,y,beta,beta_new,H)\n",
    "            \n",
    "        # Imprime\n",
    "\n",
    "        if iteraciones % verbose_n == 0:\n",
    "            grad=np.linalg.norm(gradiente_f(X,y,beta_new))\n",
    "            out.write(UNDERSCORE + f'Iteración: {iteraciones}' + ALL_OFF + f' gradiente: {grad:.7E}, alpha: {lr:.4E}')            \n",
    "\n",
    "    print(\"\\n\") \n",
    "    out.write(BOLD  + '** Resultados Finales')\n",
    "    if iteraciones == max_iter:out.write(BOLD + 'El algoritmo paro porque' + BOLD + FG_RED + 'se alcanzo el nro. máximo de iteraciones.')\n",
    "    out.write(BOLD + f'* Total de iteraciones: ' +ALL_OFF+ f'{iteraciones}'  )\n",
    "    out.write(BOLD + f'* Norma del gradiente de f: ' +ALL_OFF+ f'{np.linalg.norm(gradiente_f(X,y,beta_new))}' )\n",
    "    out.write(BOLD + f'* beta_hat:' )\n",
    "    pprint.pprint(beta_new)\n",
    "    print(\"\\n\") \n",
    "    \n",
    "    return beta_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "np.random.seed(3338014)\n",
    "    \n",
    "data =df_proc.to_numpy()\n",
    "y = data[:,0]\n",
    "X = data[:,1:]\n",
    "x_train, x_test, y_train, y_test=train_test_split(X,y,test_size=.2)\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=================================================================\u001b[0m\n",
      "\u001b[1mMétodo de máximo descenso\u001b[0m\n",
      "\u001b[1m=================================================================\u001b[0m\n",
      "\u001b[4mIteración: 500\u001b[0m gradiente: 2.5045446E-01, alpha: 7.1790E-02\u001b[0m\n",
      "\u001b[4mIteración: 1000\u001b[0m gradiente: 1.9681746E-02, alpha: 5.7264E-03\u001b[0m\n",
      "\u001b[4mIteración: 1500\u001b[0m gradiente: 3.6459555E-03, alpha: 1.0611E-03\u001b[0m\n",
      "\u001b[4mIteración: 2000\u001b[0m gradiente: 4.4262414E-04, alpha: 1.2901E-04\u001b[0m\n",
      "\u001b[4mIteración: 2500\u001b[0m gradiente: 2.3181024E-05, alpha: 6.7516E-06\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m** Resultados Finales\u001b[0m\n",
      "\u001b[1m* Total de iteraciones: \u001b[0m2964\u001b[0m\n",
      "\u001b[1m* Norma del gradiente de f: \u001b[0m9.756061172576794e-07\u001b[0m\n",
      "\u001b[1m* beta_hat:\u001b[0m\n",
      "array([-10.36242902,  16.25102342,  -3.90446862,   0.60600272,\n",
      "         0.77744891,   4.55476501,  -0.91897329,   3.3866912 ,\n",
      "         3.76095218,   3.9617985 ,   4.98358393,   6.21113331])\n",
      "\n",
      "\n",
      "\u001b[1m* Error de clasificación: \u001b[0m4.55%\u001b[0m\n",
      "\u001b[1m=================================================================\u001b[0m\n",
      "CPU times: user 650 ms, sys: 47.8 ms, total: 697 ms\n",
      "Wall time: 660 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "np.random.seed(3338014) # para replicabilidad\n",
    "beta_hat = gradient_descent(x_train,y_train,max_iter=10**6,reset_lr=False,verbose_n=500)\n",
    "yhat = clasifica(x_test,beta_hat)\n",
    "\n",
    "out.write(BOLD + f'* Error de clasificación: ' + ALL_OFF + f'{round(100*sum(abs(y_test-yhat))/len(yhat),2)}%' )\n",
    "out.write(BOLD + \"=\"*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=================================================================\u001b[0m\n",
      "\u001b[1mMétodo de Newton\u001b[0m\n",
      "\u001b[1m=================================================================\u001b[0m\n",
      "\u001b[4mIteración: 20\u001b[0m gradiente: 4.3186382E-01, alpha: 1.0000E+00\u001b[0m\n",
      "\u001b[4mIteración: 40\u001b[0m gradiente: 6.6389532E-04, alpha: 7.0697E-03\u001b[0m\n",
      "\u001b[4mIteración: 60\u001b[0m gradiente: 5.1340283E-05, alpha: 5.6392E-04\u001b[0m\n",
      "\u001b[4mIteración: 80\u001b[0m gradiente: 2.6953093E-06, alpha: 2.9513E-05\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m** Resultados Finales\u001b[0m\n",
      "\u001b[1m* Total de iteraciones: \u001b[0m87\u001b[0m\n",
      "\u001b[1m* Norma del gradiente de f: \u001b[0m1.1609129137769218e-06\u001b[0m\n",
      "\u001b[1m* beta_hat:\u001b[0m\n",
      "array([-10.36243506,  16.25103288,  -3.90446995,   0.60600623,\n",
      "         0.77744971,   4.55476817,  -0.91897444,   3.3866927 ,\n",
      "         3.76095382,   3.96180007,   4.98358595,   6.21113592])\n",
      "\n",
      "\n",
      "\u001b[1m* Error de clasificación: \u001b[0m4.55%\u001b[0m\n",
      "\u001b[1m=================================================================\u001b[0m\n",
      "CPU times: user 177 ms, sys: 16.6 ms, total: 194 ms\n",
      "Wall time: 71.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Método de Newton\n",
    "np.random.seed(3338014) # para replicabilidad\n",
    "beta_hat = gradient_descent(x_train,y_train, method=\"newton\",max_iter = 10**5,verbose_n = 20)\n",
    "yhat = clasifica(x_test,beta_hat)\n",
    "\n",
    "out.write(BOLD + f'* Error de clasificación: ' + ALL_OFF + f'{round(100*sum(abs(y_test-yhat))/len(yhat),2)}%' )\n",
    "out.write(BOLD + \"=\"*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m=================================================================\u001b[0m\n",
      "\u001b[1mMétodo de BFGS\u001b[0m\n",
      "\u001b[1m=================================================================\u001b[0m\n",
      "\u001b[4mIteración: 10000\u001b[0m gradiente: 7.0627661E-02, alpha: 2.0276E-02\u001b[0m\n",
      "\u001b[4mIteración: 20000\u001b[0m gradiente: 3.6716352E-03, alpha: 1.0611E-03\u001b[0m\n",
      "\u001b[4mIteración: 30000\u001b[0m gradiente: 1.9548109E-04, alpha: 5.5533E-05\u001b[0m\n",
      "\u001b[4mIteración: 40000\u001b[0m gradiente: 2.3716148E-05, alpha: 6.7516E-06\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m** Resultados Finales\u001b[0m\n",
      "\u001b[1m* Total de iteraciones: \u001b[0m47837\u001b[0m\n",
      "\u001b[1m* Norma del gradiente de f: \u001b[0m1.1624129428409921e-06\u001b[0m\n",
      "\u001b[1m* beta_hat:\u001b[0m\n",
      "array([-10.36240975,  16.25097655,  -3.90446056,   0.60599614,\n",
      "         0.77744804,   4.55475336,  -0.91896656,   3.38668298,\n",
      "         3.76094818,   3.96179347,   4.98357503,   6.21112378])\n",
      "\n",
      "\n",
      "\u001b[1m* Error de clasificación: \u001b[0m4.55%\u001b[0m\n",
      "\u001b[1m=================================================================\u001b[0m\n",
      "CPU times: user 16.6 s, sys: 810 ms, total: 17.4 s\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Método BFSG\n",
    "np.random.seed(333814) # para replicabilidad\n",
    "beta_hat = gradient_descent(x_train,y_train, method = \"bfsg\",max_iter = 10**6,lr=1,verbose_n = 10000)\n",
    "yhat = clasifica(x_test,beta_hat)\n",
    "\n",
    "out.write(BOLD + f'* Error de clasificación: ' + ALL_OFF + f'{round(100*sum(abs(y_test-yhat))/len(yhat),2)}%' )\n",
    "out.write(BOLD + \"=\"*65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso del gradiente estocastico\n",
    "\n",
    "Calculamos la función de riesgo empírico como la esperanza de la funcion de perdida evaluada sobre todos los puntos del dominio.\n",
    "\n",
    "$$L_{emp}=\\frac{1}{m} \\sum^{m}_{i=1} y_i log(\\mu_i) + (1-y_i) log(1-\\mu_i)$$  \n",
    "<br>\n",
    "$$ \\mu_i = (1+e^{-\\beta^T x_i})^{-1}= \\sigma(\\beta^T x_i)$$\n",
    "\n",
    "Y el gradiente de la función de riesgo esta dado por:\n",
    "\n",
    "$$\\nabla L=\\frac{dL}{d\\mu_i} =\\frac{1}{m} \\sum^{m}_{i=1} x_i(\\mu_i-y_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def riesgo_empirico(X,y,beta):\n",
    "    \n",
    "    '''\n",
    "    Función que calcular el riesgo empírico como la esperanza de la función de pérdida\n",
    "    evaluada sobre todos los puntos del dominio.\n",
    "    \n",
    "        - Parámetros:\n",
    "            -- X (mat): matriz de mxp entradas\n",
    "            -- y (vec): vector de de m entradas de la variable output\n",
    "            -- beta (vec): vector con p entradas\n",
    "\n",
    "        - Salidas\n",
    "            \n",
    "            -- loss (float64): riesgo empírico\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "    if beta.shape[0]!= p:\n",
    "        sys.exit('Error:  El número de columnas de X debe ser igual al número de entradas del vector beta.')\n",
    "\n",
    "\n",
    "    mu=calc_mu(X,beta)\n",
    "    loss=-sum(y*np.log(mu)+(1-y)*np.log(1-mu))\n",
    "    return loss\n",
    "\n",
    "def gradiente_riesgo_empirico(X,y,beta):\n",
    "    \n",
    "    '''\n",
    "    Función que calcula el gradiente de la función de riesgo.\n",
    "        - Parámetros:\n",
    "            -- X (mat): matriz de mxp entradas.\n",
    "            -- y (vec): vector de de m entradas de la variable output.\n",
    "            -- beta (vec): vector con p entradas.\n",
    "\n",
    "        - Salidas:\n",
    "            -- grad_riesgo_emp (vec): vector de p entradas\n",
    "    '''\n",
    "    # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "    if beta.shape[0]!= p:\n",
    "        sys.exit('Error:  El número de columnas de X debe ser igual al número de entradas del vector beta.')\n",
    "\n",
    "    m = X.shape[0]\n",
    "    mu = calc_mu(X,beta)\n",
    "    grad_riesgo_emp = np.matmul(np.transpose(X),mu-y)/m\n",
    "    return grad_riesgo_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def batch(m,q=10):\n",
    "\n",
    "    index=np.random.randint(low=0,high=m,size=q)\n",
    "    return index\n",
    "\n",
    "def error_train(X,y,beta):\n",
    "    prediction=clasifica(X,beta)\n",
    "    err=round(100*sum(abs(y-prediction))/len(prediction),2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SGD(X,y,batch_size,verbose_n=100,max_iter=10**5):\n",
    "\n",
    "     # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "\n",
    "\n",
    "    # Inicializa\n",
    "    m=X.shape[0]\n",
    "    epsilon = 10**(-6)\n",
    "    beta = np.random.normal(0,1,X.shape[1])    \n",
    "    step_size=.01\n",
    "    iteraciones = 0\n",
    "    epoca=0\n",
    "    ipe=int(m/batch_size)#iteraciones por epoca\n",
    "    \n",
    "    # Primera iteracion\n",
    "    index=batch(m,batch_size)\n",
    "    x_lote=X[index,:]\n",
    "    y_lote = y[index]\n",
    "    beta_new = beta - step_size * gradiente_riesgo_empirico(x_lote,y_lote,beta) \n",
    "    \n",
    "\n",
    "    perdida=riesgo_empirico(X,y,beta)\n",
    "    error=error_train(X,y,beta)\n",
    "    \n",
    "    # while ((np.linalg.norm(gradiente_f(X,y,beta_new)) > epsilon) & (iteraciones < max_iter)):\n",
    "    # while abs(f(X,y,beta) - f(X,y,beta_new)) > epsilon:\n",
    "    while iteraciones<max_iter:\n",
    "        iteraciones +=1\n",
    "        #print(\"iteraciones1=\",iteraciones)\n",
    "        beta = beta_new\n",
    "        #x_lote,y_lote = mini_lotes(X,y,q)\n",
    "        index=batch(m,batch_size)\n",
    "        x_lote=X[index,:]\n",
    "        y_lote = y[index]\n",
    "        beta_new = beta - step_size * gradiente_riesgo_empirico(x_lote,y_lote,beta)\n",
    "        #print(\"iteraciones2=\",iteraciones)\n",
    "        if iteraciones%10000==0:\n",
    "            epoca+=1\n",
    "            loss=riesgo_empirico(X,y,beta)\n",
    "            perdida=np.append(perdida,loss)\n",
    "            err=error_train(X,y,beta)\n",
    "            error=np.append(error, error_train(x_test,y_test,beta_hat))\n",
    "            print(f'loss:{loss:.4}, epoca:{epoca}, iter:{iteraciones}')\n",
    "        #print(\"iteraciones3=\",iteraciones)\n",
    "    print(\"Nº DE INTERACIONES: \",iteraciones)\n",
    "    return beta_new,perdida,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graf_loss_err(loss,error,title):\n",
    "    '''\n",
    "    Función para graficar la pérdida o riesgo emírico y el error\n",
    "    de entrenamiento en cada iterazación.\n",
    "        - Entradas:\n",
    "                    -- loss\n",
    "                    -- error\n",
    "                    ---title\n",
    "        - Salidas:\n",
    "                    -- plot\n",
    "    '''\n",
    "    \n",
    "    x=np.arange(0,len(error))\n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "    axs[0].plot(x, error)\n",
    "    axs[0].set_xlabel('Iteraciones')\n",
    "    axs[0].set_ylabel('Train error %')\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    axs[1].plot(x, loss)\n",
    "    axs[1].set_xlabel('Iteraciones')\n",
    "    axs[1].set_ylabel('Perdida')\n",
    "    axs[1].grid(True)\n",
    "    axs[0].set_title(title, fontsize=14)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#graf_loss_err(loss[0,20],error[0:20],\"Batch size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*========================================================================*\n",
      "Tamaño de minilote=  9\n",
      "loss:24.65, epoca:1, iter:10000\n",
      "loss:19.97, epoca:2, iter:20000\n",
      "loss:17.92, epoca:3, iter:30000\n",
      "loss:16.75, epoca:4, iter:40000\n",
      "loss:15.98, epoca:5, iter:50000\n",
      "loss:15.43, epoca:6, iter:60000\n",
      "loss:15.02, epoca:7, iter:70000\n",
      "loss:14.69, epoca:8, iter:80000\n",
      "loss:14.42, epoca:9, iter:90000\n",
      "loss:14.21, epoca:10, iter:100000\n",
      "Nº DE INTERACIONES:  100000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_hat= [-5.51625653  9.41234684 -2.34521111 -0.25427645  0.59709283  2.51511279\n",
      " -0.01347701  2.10364421  2.07589005  1.96217798  2.23616146  3.42584893]\n",
      "Error de clasificacion= 9.09 %\n",
      "\n",
      "\n",
      "CPU times: user 9.07 s, sys: 482 ms, total: 9.56 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(3338014) # para replicabilidad\n",
    "# Método de SGD\n",
    "for batch_size in range(9,10):\n",
    "    \n",
    "    \n",
    "    print(\"*========================================================================*\")\n",
    "    print(\"Tamaño de minilote= \",batch_size)\n",
    "    beta_hat, loss, error = SGD(x_train, y_train, max_iter=10**5, batch_size=batch_size)\n",
    "    yhat = clasifica(x_test,beta_hat)\n",
    "    titulo=\"Batch size = \"+ str(batch_size)\n",
    "    graf_loss_err(loss,error,titulo)\n",
    "    print(\"beta_hat=\", beta_hat)\n",
    "    print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_batch(m):\n",
    "    index=np.arange(0,m)\n",
    "    np.random.shuffle(index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/distributed/dashboard/core.py:79: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "from dask.distributed import Client, progress\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:59415</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:59416/status' target='_blank'>http://127.0.0.1:59416/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>8.59 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:59415' processes=4 threads=8, memory=8.59 GB>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paso 1. Dividir el dominio en partes iguales\n",
    "cores = multiprocessing.cpu_count() # cpus disponibles\n",
    "#n_subint = int(density_p/p) # número de puntos o nodos en cada core o cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construye_indices(ids,m,cores):\n",
    "    '''\n",
    "    Argumentos:\n",
    "    ----------\n",
    "    * ids: Identificador del core dónde se está corriendo el task. \n",
    "    * m (array): Numero total de puntos de entrenamiento.\n",
    "    * cores (int) : Número de cores o cpus disponibles\n",
    "    \n",
    "    Salidas:\n",
    "    -------\n",
    "    * (index_from, index_to): Rango de indices que se seleccionan del verctor de permutaciones\n",
    "    '''\n",
    "    \n",
    "    tamano_int = int(m/cores) #tamaño de cada sub intervalo.\n",
    "    index_from = ids*tamano_int #construyen los subintervalo\n",
    "    index_to = index_from + tamano_int\n",
    "    if ids==(cores-1): index_to=m\n",
    "    return (index_from,index_to)\n",
    "\n",
    "\n",
    "def evalua_gradiente(intervalo,perm,X,y,beta):\n",
    "    \"\"\"\n",
    "    Función que evalúa el gradiente del riesgo empirico para cada conjunto de indices de permutaciones    \n",
    "    Argumentos:\n",
    "    ----------\n",
    "    * intervalo: Intervalo de indices del vector perm a utilizar\n",
    "    * perm: Vector de permutaciones \n",
    "    * X: Puntos de entrenamiento\n",
    "    * y: Etiquetas de los puntos de entrenamiento\n",
    "    * beta: Vector de parametros a optimizar\n",
    "    \n",
    "    Salidas:\n",
    "    * Evaluacion del gradiente del riesgo empirico para un mini lote\n",
    "    --------\n",
    "\n",
    "    \"\"\"   \n",
    "    index=perm[intervalo[0]:intervalo[1]]\n",
    "    x_lote = X[index,:]\n",
    "    y_lote = y[index]\n",
    "    gradiente=gradiente_riesgo_empirico(x_lote,y_lote,beta) \n",
    "    return gradiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_paralelo(X,y,verbose_n=100,max_iter=10**5):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "\n",
    "     # Se revisa que los parámetros de entrada sean congruentes con la funcionalidad\n",
    "    m,p = X.shape\n",
    "    if y.shape[0]!= m:\n",
    "        sys.exit('Error:  El número de renglones de X debe ser igual al número de entradas del vector y.')\n",
    "\n",
    "    \n",
    "    # Inicializa\n",
    "    m=X.shape[0]\n",
    "    epsilon = 10**(-6)\n",
    "    beta = np.random.normal(0,1,X.shape[1])    \n",
    "    step_size=.01\n",
    "    iteraciones = 0\n",
    "    epoca=0\n",
    "    \n",
    "    # Primera iteracion\n",
    "    perm=n_batch(m)\n",
    "    #calcula los indices\n",
    "    indices = client.map(construye_indices,range(cores),\n",
    "                **{'m':m,'cores':cores})\n",
    "\n",
    "    #evalua el gradiente en cada batch en paralelo\n",
    "    grad_riesgo_empirico=client.map(evalua_gradiente,indices,\n",
    "                **{'perm':perm,'X':X,'y':y,'beta':beta})\n",
    "\n",
    "    results=client.gather(grad_riesgo_empirico)\n",
    "    actualiza=sum(results)\n",
    "    \n",
    "    beta_new = beta - step_size * actualiza  \n",
    "    #gradiente_riesgo_empirico(x_lote,y_lote,beta) \n",
    "    \n",
    "    perdida=riesgo_empirico(X,y,beta)\n",
    "    error=error_train(X,y,beta)\n",
    "    \n",
    "    # while ((np.linalg.norm(gradiente_f(X,y,beta_new)) > epsilon) & (iteraciones < max_iter)):\n",
    "    # while abs(f(X,y,beta) - f(X,y,beta_new)) > epsilon:\n",
    "    while iteraciones<max_iter:\n",
    "        iteraciones +=1\n",
    "        beta = beta_new\n",
    "        perm=n_batch(m)\n",
    "        #calcula los indices\n",
    "        indices = client.map(construye_indices,range(cores),**{'m':m,'cores':cores})\n",
    "        #evalua el gradiente en cada batch en paralelo\n",
    "        grad_riesgo_empirico=client.map(evalua_gradiente,indices,\n",
    "                     **{'perm':perm,'X':X,'y':y,'beta':beta})\n",
    "        #gather results\n",
    "        results=client.gather(grad_riesgo_empirico)\n",
    "        actualiza=sum(results)\n",
    "        \n",
    "        beta_new = beta - step_size * actualiza\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if iteraciones%100==0:\n",
    "            epoca+=1\n",
    "            loss=riesgo_empirico(X,y,beta)\n",
    "            perdida=np.append(perdida,loss)\n",
    "            err=error_train(X,y,beta)\n",
    "            error=np.append(error, error_train(x_test,y_test,beta_hat))\n",
    "            print(f'loss:{loss:.4}, epoca:{epoca}, iter:{iteraciones}')\n",
    "        #print(\"iteraciones3=\",iteraciones)\n",
    "    print(\"Nº DE INTERACIONES: \",iteraciones)\n",
    "    return beta_new,perdida,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*========================================================================*\n",
      "loss:49.64, epoca:1, iter:100\n",
      "loss:43.67, epoca:2, iter:200\n",
      "loss:39.34, epoca:3, iter:300\n",
      "loss:36.08, epoca:4, iter:400\n",
      "loss:33.54, epoca:5, iter:500\n",
      "loss:31.53, epoca:6, iter:600\n",
      "loss:29.91, epoca:7, iter:700\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Método de SGD\n",
    "np.random.seed(3338014)\n",
    "for batch_size in range(9,10):\n",
    "    \n",
    "    print(\"*========================================================================*\")\n",
    "    #print(\"Tamaño de minilote= \",batch_size)\n",
    "    beta_hat, loss, error = SGD_paralelo(x_train, y_train, max_iter=10**4)\n",
    "    yhat = clasifica(x_test,beta_hat)\n",
    "    titulo=\"Batch size = \"+ str(batch_size)\n",
    "    graf_loss_err(loss,error,titulo)\n",
    "    print(\"beta_hat=\", beta_hat)\n",
    "    print(\"Error de clasificacion=\",round(100*sum(abs(y_test-yhat))/len(yhat),2),\"%\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados del modelo logístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se mencionó anteriormente, el problema de regresión logística\n",
    "es una extensión del problema de regresión lineal, aplicada hacia\n",
    "un problema de clasificación. En este sentido, la regresión logística\n",
    "modela las probabilidades de clasificación de una variable dependiente\n",
    "dentro de dos posibles categorías, 0 y 1. \n",
    "\n",
    "La probabilidad\n",
    "de que un paciente muera a causa del virus del ébola para este modelo\n",
    "se define de la siguiente forma:\n",
    "\n",
    "$$\n",
    "P\\left(y=1\\right)=\\frac{e^{\\beta^{T}x}}{1+e^{\\beta^{T}x}}\\label{eq:prob_y1a}\n",
    "$$\n",
    "\n",
    "Lo que es equivalente a:\n",
    "\n",
    "$$\n",
    "P\\left(y=1\\right)=\\frac{e^{\\beta_{0}+\\beta_{1}x_{1}+\\ldots+\\beta_{p}x_{p}}}{1+e^{\\beta_{0}+\\beta_{1}x_{1}+\\ldots+\\beta_{p}x_{p}}}\\label{eq:prob_y1b}\n",
    "$$\n",
    "\n",
    "- Para este ejercicio, no estamos considerando el término equivalente al intercepto en el caso de regresión\n",
    "lineal (i.e $\\beta_{0}=0)$.\n",
    "\n",
    "- A diferencia de un modelo de regresión tradicional, en este caso los pesos no afectan de forma lineal las probabilidades.\n",
    "- Para lograr interpretabilidad en cuanto a las probabilidades, es necesario despejar el componente lineal de la ecuación. \n",
    "\n",
    "El término *logit* y corresponde al logaritmo del cociente entre la probabilidad de morir y la probabilidad de sobrevivir al virus (ratio de\n",
    "probabilidades: línea recta, dependiente del conjunto de covariables, $x$):\n",
    "\n",
    "$$\n",
    "\\lambda=\\log\\left\\{ \\frac{P\\left(y=1\\right)}{1-P\\left(y=1\\right)}\\right\\} =\\beta_{1}x_{1}+\\ldots+\\beta_{p}x_{p}\\label{eq:param_logit}\n",
    "$$\n",
    "\n",
    "\n",
    "- El modelo logístico, dada la naturaleza\n",
    "dicotómica de la variable de salida del mismo no asume homocedasticidad.\n",
    "\n",
    "- La interpretación de los resultados del modelo de regresión logística \n",
    "se realiza en términos del valor del ratio de probabilidades, que corresponde \n",
    "al operador exponencial de $\\lambda$. Dicho operador se lee como \n",
    "el indicador de variación en el ratio de probabilidades como resultado del\n",
    "cambio en una unidad en la predicción.\n",
    "\n",
    "\n",
    "Los resultados para nuestro ejercicio implican:\n",
    "\n",
    "$$\n",
    "ratio\\:probs=\\exp(\\log\\{-10.95x_{1}+18.88x_{2}-4.42x_{3}+1.14x_{4}+1.40x_{5}+4.76x_{6}-0.94x_{7}+3.006x_{8}+3.73x_{9}+4.45x_{10}+5.20x_{11}+6.38x_{12}\n",
    "$$\n",
    "\n",
    "donde $x_{1},\\ldots,x_{12}$ corresponden a: cycle threshold,\n",
    "temperatura, dolor de cabeza, sangrado, diarrea, vómito, presencia\n",
    "de PABD, debilidad, edad hasta 22 años, edad entre 23 y 36 años, edad\n",
    "entre 37 y 45 años, y edad mayor a 45 años, respectivamente.\n",
    "\n",
    "- Se debe calcular un valor de referencia con el cual se pueda comparar. \n",
    "\n",
    "En este sentido, tomaremos dicho valor para el caso en el cual la persona no tiene ninguna complicación de salud adicional al virus del ébola, y su edad se encuentra en un rango de 0 años a 22 años\n",
    "\n",
    "Es decir que en la ecuación anterior, se tiene $x_{i}=0$ para $i=3,4,5,6,7,8$\n",
    "y $x_{9}=1$:\n",
    "\n",
    "$$\n",
    "ratio\\:probs=\\exp\\left(\\log\\left\\{ -10.95x_{1}+18.88x_{2}+3.73\\right\\} \\right)\n",
    "$$\n",
    "\n",
    "Si tomamos los valores promedio de cycle treshold $\\bar{x}_{1}$,\n",
    "y de temperatura, $\\bar{x}_{2}$ , tenemos lo siguiente:\n",
    "\n",
    "$$\n",
    "ratio\\:probs_{0}=\\exp\\left(\\log\\left\\{ -10.95\\bar{x}_{1}+18.88\\bar{x}_{2}+3.73\\right\\} \\right)=\\exp\\left(\\log\\left\\{ -10.95(25.72)+18.88(37.25)+3.73\\right\\} \\right)=425.75\n",
    "$$\n",
    "\n",
    "Por otro lado, si quisiéramos analizar, por ejemplo, cual es el efecto\n",
    "de que la persona tenga sangrado sobre la probabilidad de que la persona\n",
    "muera por presencia del virus del ébola, debemos calcular el ratio\n",
    "de probabilidades ahora con $x_{4}=1$:\n",
    "\n",
    "$$\n",
    "ratio\\:probs_{1}=\\exp\\left(\\log\\left\\{ -10.95\\bar{x}_{1}+18.88\\bar{x}_{2}+1.14+3.73\\right\\} \\right)=\\exp\\left(\\log\\left\\{ -10.95(25.72)+18.88(37.25)+1.14+3.73\\right\\} \\right)=426.8\n",
    "$$\n",
    "\n",
    "\n",
    "Ahora, si calculamos el ratio entre $ratio\\:probs_{0}$ y $ratio\\:probs_{1}$, tenemos:\n",
    "\n",
    "$$\n",
    "\\frac{ratio\\:probs_{1}}{ratio\\:probs_{0}}=\\frac{426.89}{425.75}=1.0026\\label{eq:delt_odd}\n",
    "$$\n",
    "\n",
    "- Puesto que esta ecuación es mayor a 1, esto indica que la probabilidad\n",
    "de la variable dependiente incrementa. \n",
    "- Una persona con edad de 0 años a 22 años que tiene ébola, tener sangrado, afecta positivamente su probabilidad de morir.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
